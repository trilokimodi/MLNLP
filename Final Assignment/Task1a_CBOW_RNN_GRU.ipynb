{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Task1a_CBOW_RNN_GRU.ipynb","provenance":[{"file_id":"1EE90LDluI81Q5hNrcihW5Q-lMoKERLop","timestamp":1606790375321}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gndHokXsXj7G"},"source":["**Name: Trilokinath Modi**"]},{"cell_type":"markdown","metadata":{"id":"vk2BdXsiYk-5"},"source":["# Basic Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aUApflSMB6I","executionInfo":{"status":"ok","timestamp":1610660097053,"user_tz":-60,"elapsed":20309,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"e1fec713-06b0-46bb-e48c-e06068fc27c7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qUbi5mZrYsM8","executionInfo":{"status":"ok","timestamp":1610660107024,"user_tz":-60,"elapsed":7595,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["import torch\n","import pandas\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","\n","import time\n","import csv\n","\n","from collections import defaultdict, Counter\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from spacy.lang.en import English\n","\n","%config InlineBackend.figure_format = 'svg' \n","plt.style.use('seaborn')\n","\n","nlp = English()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JX7ggGSTMNuw","executionInfo":{"status":"ok","timestamp":1610660107848,"user_tz":-60,"elapsed":805,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["filePath = \"/content/drive/My Drive/MLNLP/FinalAssignment/train.csv\"\n","filePathTest = \"/content/drive/My Drive/MLNLP/FinalAssignment/test.csv\"\n","filePathResult = \"/content/drive/My Drive/MLNLP/FinalAssignment/\""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zrZBszyMMblY","executionInfo":{"status":"ok","timestamp":1610660112493,"user_tz":-60,"elapsed":614,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["def readData(fileName):\n","    # colnames = ['id', 'text', 'is_humor', 'humor_rating', 'humor_controversy', 'offense_rating']\n","    train_data = pandas.read_csv(fileName)\n","    X = train_data.text.tolist()\n","    Y = train_data.is_humor.tolist()\n","    return X, Y\n","\n","def readDataTest(fileName):\n","    test_data = pandas.read_csv(fileName)\n","    xTest = test_data.text.tolist()\n","    return xTest  \n","  \n","def writeData(fileName, testData, resultList):\n","  fileHandler = open(fileName, 'w')\n","  with fileHandler:\n","    headings = ['text', 'is_humor']\n","    writer = csv.writer(fileHandler)\n","    writer.writerows(zip(testData, resultList))\n","\n","def evaluateTest(y_true, y_pred):\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    accuracy = (tp + tn)/(tp+tn+fp+fn)\n","    f1score = tp / (tp + 0.5*(fp + fn))\n","    return accuracy, f1score"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"czj10hFdZBUM"},"source":["# Setup classes used by all methods"]},{"cell_type":"markdown","metadata":{"id":"mi_rZj5karcU"},"source":["The vocabulary class is modified to add 2 special cases used in continuous bag of words approach. The special cases are discussed under the CBOW title. Specifically, the build method is modified."]},{"cell_type":"code","metadata":{"id":"IX_UG9A9_8H7","executionInfo":{"status":"ok","timestamp":1610660114600,"user_tz":-60,"elapsed":742,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["PAD = '___PAD___'\n","UNKNOWN = '___UNKNOWN___'\n","\n","class Vocabulary:\n","    \"\"\"Manages the numerical encoding of the vocabulary.\"\"\"\n","    \n","    def __init__(self, tokenizer=None, max_voc_size=None):\n","\n","        # String-to-integer mapping\n","        self.stoi = None\n","\n","        # Integer-to-string mapping\n","        self.itos = None\n","\n","        # Tokenizer that will be used to split document strings into words.\n","        if tokenizer:\n","            self.tokenizer = tokenizer\n","        else:\n","            self.tokenizer = lambda s: s.split()\n","\n","        # Maximally allowed vocabulary size.\n","        self.max_voc_size = max_voc_size\n","        \n","    def build(self, docs, position = None, ngrams = None, flagNoStop = None):\n","        \"\"\"Builds the vocabulary, based on a set of documents.\"\"\"\n","        \n","        if ngrams == None:\n","          # Sort all words by frequency\n","          word_freqs = Counter(w for doc in docs for w in self.tokenizer(doc))\n","          word_freqs = sorted(((f, w) for w, f in word_freqs.items()), reverse=True)\n","        \n","        elif flagNoStop == None:\n","          # Sort all words by frequency\n","          positionIndex = 0\n","          word_freqs = Counter()\n","          for doc in docs:\n","            currentDoc = self.tokenizer(doc)\n","            if int(position[positionIndex]) + ngrams < len(currentDoc) and int(position[positionIndex]) - ngrams >= 0:\n","              for words in range(int(position[positionIndex]) - ngrams, int(position[positionIndex]) + ngrams + 1):        \n","                word_freqs.update([currentDoc[words]])\n","            elif int(position[positionIndex]) + ngrams < len(currentDoc):\n","              for words in range(int(position[positionIndex]), int(position[positionIndex]) + ngrams + 1):\n","                word_freqs.update([currentDoc[words]])\n","            elif int(position[positionIndex]) - ngrams >= 0:\n","              for words in range(int(position[positionIndex]) - ngrams, int(position[positionIndex]) + 1):\n","                word_freqs.update([currentDoc[words]])\n","            positionIndex += 1\n","          word_freqs = sorted(((f, w) for w, f in word_freqs.items()), reverse=True)\n","\n","        elif flagNoStop == 1:\n","          # Sort all words by frequency\n","          positionIndex = 0\n","          word_freqs = Counter()\n","          for doc in docs:\n","            currentDoc = self.tokenizer(doc)\n","            currentDocNoStop = []\n","            for iToken in range(len(currentDoc)):\n","              if not nlp.vocab[currentDoc[iToken]].is_stop and iToken not in ['.', ',', \"?\"] and not currentDoc[iToken].isdigit() and iToken != int(position[positionIndex]):\n","                currentDocNoStop.append(currentDoc[iToken])\n","              if iToken == int(position[positionIndex]):\n","                currentDocNoStop.append(currentDoc[iToken])\n","                newPosition = len(currentDocNoStop) - 1\n","            if newPosition + ngrams < len(currentDocNoStop) and newPosition - ngrams >= 0:\n","              for words in range(newPosition - ngrams, newPosition + ngrams + 1):\n","                word_freqs.update([currentDocNoStop[words]])\n","            elif newPosition + ngrams < len(currentDocNoStop):\n","              for words in range(newPosition, newPosition + ngrams + 1):\n","                word_freqs.update([currentDocNoStop[words]])\n","            elif newPosition - ngrams >= 0:\n","              for words in range(newPosition - ngrams, newPosition + 1):\n","                word_freqs.update([currentDocNoStop[words]])\n","            positionIndex += 1\n","          word_freqs = sorted(((f, w) for w, f in word_freqs.items()), reverse=True)\n","\n","        # Build the integer-to-string mapping. The vocabulary starts with the two dummy symbols,\n","        # and then all words, sorted by frequency. Optionally, limit the vocabulary size.\n","        if self.max_voc_size:\n","            self.itos = [PAD, UNKNOWN] + [ w for _, w in word_freqs[:self.max_voc_size-2] ]\n","        else:\n","            self.itos = [PAD, UNKNOWN] + [ w for _, w in word_freqs ]\n","\n","        # Build the string-to-integer map by just inverting the aforementioned map.\n","        self.stoi = { w: i for i, w in enumerate(self.itos) }\n","        \n","    def encode(self, docs):\n","        \"\"\"Encodes a set of documents.\"\"\"\n","        unkn_index = self.stoi[UNKNOWN]\n","        return [[self.stoi.get(w, unkn_index) for w in self.tokenizer(doc)] for doc in docs]\n","\n","    def get_unknown_idx(self):\n","        \"\"\"Returns the integer index of the special dummy word representing unknown words.\"\"\"\n","        return self.stoi[UNKNOWN]\n","    \n","    def get_pad_idx(self):\n","        \"\"\"Returns the integer index of the special padding dummy word.\"\"\"\n","        return self.stoi[PAD]\n","    \n","    def __len__(self):\n","        return len(self.itos)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z38GaHZxbNGk"},"source":["Class used to store document identities and create batches"]},{"cell_type":"code","metadata":{"id":"IyNLQOpi_8II","executionInfo":{"status":"ok","timestamp":1610660116933,"user_tz":-60,"elapsed":722,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["class DocumentDataset(Dataset):\n","    \"\"\"A Dataset that stores a list of documents and their corresponding category labels.\"\"\"\n","    def __init__(self, X, Y):\n","        self.X = X\n","        self.Y = Y\n","        \n","    def __getitem__(self, idx):\n","        return self.X[idx], self.Y[idx]\n","        \n","    def __len__(self):\n","        return len(self.X)\n","\n","class DocumentBatcher:\n","    \"\"\"A collator that builds a batch from a number of documents.\"\"\"\n","    \n","    def __init__(self, voc):\n","        # Find the integer index of the dummy padding word.\n","        self.pad = voc.get_pad_idx()\n","    \n","    def __call__(self, XY):\n","        \"\"\"Build a batch from a number of documents. Returns two tensors X and Y, where\n","        X is the document tensor, of shape [n_docs, max_doc_length]\n","\n","        and \n","        \n","        Y is the label tensor, of shape [n_docs].\n","        \"\"\"\n","        \n","        # How long is the longest document in this batch?\n","        max_len = max(len(x) for x, _ in XY)\n","\n","        # Build the document tensor. We pad the shorter documents so that all documents\n","        # have the same length.\n","        Xpadded = torch.as_tensor([x + [self.pad]*(max_len-len(x)) for x, _ in XY])\n","\n","        # Build the label tensor.\n","        Y = torch.as_tensor([y for _, y in XY])\n","\n","        return Xpadded, Y"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f3W_-CKCbci3"},"source":["Text classifier class which performs the preprocessing, training and prediction for each model. This class is inshort the heart of the program. The class is modified to accomodate changes made in Vocabulary class. Specifically, the preprocess method is modified and simple early stopping criteria is included i.e. the model stops training if for any 3 epochs in previous 5 epochs the validation loss has increased. This early stopping criteria is used for all models."]},{"cell_type":"code","metadata":{"id":"8mGtJHNCHVAl","executionInfo":{"status":"ok","timestamp":1610660119170,"user_tz":-60,"elapsed":756,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["class TextClassifier:\n","    \"\"\"A text classifier based on a neural network.\"\"\"\n","    \n","    def __init__(self, params):\n","        self.params = params\n","        self.flagEpoch = 0\n","        \n","    def epoch(self, batches, optimizer=None):\n","        \"\"\"Runs the neural network for one epoch, using the given batches.\n","        If an optimizer is provided, this is training data and we will update the model\n","        after each batch. Otherwise, this is assumed to be validation data.\n","        \n","        Returns the loss and accuracy over the epoch.\"\"\"\n","        n_correct = 0\n","        n_instances = 0\n","        total_loss = 0\n","        TP = 0\n","        TN = 0\n","        FP = 0\n","        FN = 0\n","        \n","        for Xbatch, Ybatch in batches:\n","            Xbatch = Xbatch.to(self.params.device)\n","            Ybatch = Ybatch.to(self.params.device)\n","            scores = self.model(Xbatch)\n","            loss = self.loss(scores, Ybatch)\n","\n","            total_loss += loss.item()\n","            n_instances += Ybatch.shape[0]\n","            guesses = scores.argmax(dim=1)\n","            n_correct += (guesses == Ybatch).sum().item()\n","            for iY in Ybatch:\n","              if Ybatch[iY] == 1 and guesses[iY] == Ybatch[iY]:\n","                TP += 1\n","              elif Ybatch[iY] == 1:\n","                FN += 1\n","              elif Ybatch[iY] == 0 and guesses[iY] == Ybatch[iY]:\n","                TN += 1\n","              elif Ybatch[iY] == 0:\n","                FP += 1\n","            if optimizer:\n","                optimizer.zero_grad()                \n","                loss.backward()\n","                optimizer.step()\n","           \n","        return total_loss/len(batches), n_correct/n_instances, TP/(TP + 0.5*(FP + FN))\n","    \n","    def preprocess(self, X, Y, position = None, ngrams = None, flagNoStop = None):\n","        \"\"\"Carry out the document preprocessing, then build `DataLoader`s for the training and validation sets.\"\"\"\n","\n","        if ngrams == None:\n","          Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.2, random_state=0)\n","          self.voc = Vocabulary(max_voc_size=self.params.max_voc_size)\n","          self.voc.build(Xtrain)\n","        elif flagNoStop == None:\n","          Xtrain, Xval, Ytrain, Yval = train_test_split(np.column_stack((X, position)), Y, test_size=0.2, random_state=0)\n","          position = Xtrain[:,1]\n","          Xtrain = list(Xtrain[:,0])\n","          Xval = list(Xval[:,0])\n","          self.voc = Vocabulary(max_voc_size=self.params.max_voc_size)\n","          self.voc.build(Xtrain, position, ngrams)\n","        elif flagNoStop == 1:\n","          Xtrain, Xval, Ytrain, Yval = train_test_split(np.column_stack((X, position)), Y, test_size=0.2, random_state=0)\n","          position = Xtrain[:,1]\n","          Xtrain = list(Xtrain[:,0])\n","          Xval = list(Xval[:,0])\n","          self.voc = Vocabulary(max_voc_size=self.params.max_voc_size)\n","          self.voc.build(Xtrain, position, ngrams, flagNoStop)\n","\n","        self.lbl_enc = LabelEncoder()\n","        self.lbl_enc.fit(Ytrain)\n","\n","        self.voc_size = len(self.voc)\n","        self.n_classes = len(self.lbl_enc.classes_)\n","        \n","        batcher = DocumentBatcher(self.voc)\n","        \n","        train_dataset = DocumentDataset(self.voc.encode(Xtrain), self.lbl_enc.transform(Ytrain))\n","        self.train_loader = DataLoader(train_dataset, self.params.batch_size, shuffle=True,\n","                                  collate_fn=batcher)\n","        val_dataset = DocumentDataset(self.voc.encode(Xval), self.lbl_enc.transform(Yval))\n","        self.val_loader = DataLoader(val_dataset, self.params.batch_size, shuffle=True,\n","                                collate_fn=batcher)\n","    \n","    def set_model(self, model):\n","        \"\"\"Provide a neural network model for this document classifier.\"\"\"\n","        self.model = model\n","    \n","    def train(self):\n","        \"\"\"Train the model. We assume that a dataset and a model have already been provided.\"\"\"\n","        par = self.params\n","        \n","        # If we're using a GPU, put the model there.\n","        self.model.to(par.device)\n","    \n","        # Declare a loss function, in this case the cross-entropy.\n","        self.loss = torch.nn.CrossEntropyLoss()\n","\n","        # An optimizer for updating the neural network. We use the Adam optimizer.\n","        optimizer = torch.optim.Adam(self.model.parameters(), lr=par.eta, weight_decay=par.decay)\n","\n","        # We'll log the loss and accuracy scores encountered during training.\n","        self.history = defaultdict(list)\n","        epoch = 0\n","        while epoch < par.n_epochs+1 and self.flagEpoch == 0:\n","            epoch += 1\n","            \n","            t0 = time.time()\n","            \n","            # Set the model in training mode, enabling dropout modules.\n","            self.model.train()\n","            \n","            # Run the model on the training data.\n","            train_loss, train_acc, train_f1_score = self.epoch(self.train_loader, optimizer)\n","            \n","            # Set the model in evaluation mode, disabling dropout modules.\n","            self.model.eval()\n","\n","            # Run the model on the validation data.            \n","            val_loss, val_acc, val_f1_score = self.epoch(self.val_loader)\n","            \n","            t1 = time.time()\n","\n","            self.history['train_loss'].append(train_loss)\n","            self.history['train_acc'].append(train_acc)\n","            self.history['val_loss'].append(val_loss)\n","            self.history['val_acc'].append(val_acc)\n","            self.history['train_f1'].append(train_f1_score)\n","            self.history['val_f1'].append(val_f1_score)\n","            self.history['time'].append(t1-t0)\n","            \n","            if epoch % 5 == 0:\n","                print(f'Epoch {epoch}: train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, '\n","                      + f'val loss: {val_loss:.4f}, val acc: {val_acc:.4f}, time: {t1-t0:.4f}')\n","\n","            flagEpochArray = np.zeros(5, dtype = int)\n","            if epoch > 6:\n","              for iEpoch in range(1,6):\n","                if self.history['val_loss'][epoch - iEpoch] - self.history['val_loss'][epoch - (iEpoch + 1)] > 0:\n","                  flagEpochArray[iEpoch - 1] = 1\n","            if np.sum(flagEpochArray) >= 4:\n","              self.flagEpoch = 1\n","        \n","    def predict(self, X):\n","        \"\"\"Run a trained document classifier on a set of documents and return the predictions.\"\"\"\n","        batcher = DocumentBatcher(self.voc)\n","        \n","        # Build a DataLoader to generate the batches, as above.\n","        dummy_labels = [self.lbl_enc.classes_[0] for x in X]        \n","        dataset = DocumentDataset(self.voc.encode(X), self.lbl_enc.transform(dummy_labels))\n","        loader = DataLoader(dataset, self.params.batch_size, collate_fn=batcher)\n","\n","        # Apply the model to all the batches and aggregate the predictions.\n","        self.model.eval()\n","        output = []\n","        for Xbatch, Ybatch in loader:\n","            Xbatch = Xbatch.to(self.params.device)\n","            Ybatch = Ybatch.to(self.params.device)\n","            scores = self.model(Xbatch)\n","            guesses = scores.argmax(dim=1)\n","            output.extend(self.lbl_enc.inverse_transform(guesses.cpu().numpy()))\n","        return output"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oNefW6WxeVkc"},"source":["# Training Model CBOW"]},{"cell_type":"markdown","metadata":{"id":"p1i1AsSOeatD"},"source":["Class that provides the embedded input tensor."]},{"cell_type":"code","metadata":{"id":"xNlst1tR_8I9","executionInfo":{"status":"ok","timestamp":1610660122201,"user_tz":-60,"elapsed":609,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["class CBoWRepresentation(nn.Module):\n","    \n","    def __init__(self, voc_size, emb_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(voc_size, emb_dim)\n","\n","    def forward(self, X):        \n","        embedded = self.embedding(X)        \n","        return embedded.mean(dim=1)\n","    \n","        # final shape: (n_docs, emb_dim)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k49ibM0Qgwep"},"source":["Class to define the hyperparameters for CBOW model and performs the operations done by main i.e. calling the right functions from Text Classifier class to perform the training."]},{"cell_type":"code","metadata":{"id":"u35KsQwr_8JI","executionInfo":{"status":"ok","timestamp":1610660124795,"user_tz":-60,"elapsed":606,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["class TextClassifierParameters:\n","    device = 'cuda'\n","    \n","    max_voc_size = None\n","    \n","    n_epochs = 50\n","    batch_size = 64\n","    \n","    eta = 3e-3\n","    decay = 0 #1e-6\n","    dropout = 0 #0.2\n","    \n","    emb_dim = 32\n","\n","def main_cbow(caseNumber):    \n","    #torch.manual_seed(0)\n","\n","    X, Y = readData(filePath)\n","    \n","    params = TextClassifierParameters()\n","    \n","    clf = TextClassifier(params)\n","    \n","    if caseNumber == 1:\n","      clf.preprocess(X, Y, ngrams = None, flagNoStop = None)\n","    elif caseNumber == 2:\n","      clf.preprocess(X, Y, posVector, ngrams = 3, flagNoStop = None)\n","    elif caseNumber == 3:\n","      clf.preprocess(X, Y, posVector, ngrams = 3, flagNoStop = 1)\n","    \n","    # Create a classification model: a continuous bag-of-words representation with a linear classifier \n","    # on top, and dropout to reduce overfitting.\n","    clf.set_model(nn.Sequential(\n","            CBoWRepresentation(clf.voc_size, params.emb_dim),\n","            nn.Dropout(params.dropout),\n","            nn.Linear(in_features=params.emb_dim, out_features=clf.n_classes)\n","    ))\n","\n","    clf.train()\n","  \n","    return clf"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VA3hY36Ag1F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610660215798,"user_tz":-60,"elapsed":87464,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"bc63080d-0b40-464b-9372-b35a802e6ab6"},"source":["maxIter = 3\n","finalAccCBOWVal = list()\n","finalAccCBOWTrain = list()\n","finalF1CBOWVal = list()\n","finalF1CBOWTrain = list()\n","cbow_classifier = list()\n","for icase in range(1):\n","  cbow_classifier.append(list())\n","  finalAccCBOWVal.append(np.zeros(maxIter))\n","  finalAccCBOWTrain.append(np.zeros(maxIter))\n","  finalF1CBOWVal.append(np.zeros(maxIter))\n","  finalF1CBOWTrain.append(np.zeros(maxIter))\n","  for iterations in range(maxIter):\n","    cbow_classifier[icase].append(main_cbow(icase + 1))\n","    finalAccCBOWVal[icase][iterations] = cbow_classifier[icase][iterations].history['val_acc'][len(cbow_classifier[icase][iterations].history['val_acc']) - 1]\n","    finalAccCBOWTrain[icase][iterations] = cbow_classifier[icase][iterations].history['train_acc'][len(cbow_classifier[icase][iterations].history['train_acc']) - 1]\n","    finalF1CBOWVal[icase][iterations] = cbow_classifier[icase][iterations].history['val_f1'][len(cbow_classifier[icase][iterations].history['val_f1']) - 1]\n","    finalF1CBOWTrain[icase][iterations] = cbow_classifier[icase][iterations].history['train_f1'][len(cbow_classifier[icase][iterations].history['train_f1']) - 1]\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 5: train loss: 0.3156, train acc: 0.8870, val loss: 0.3586, val acc: 0.8471, time: 1.4460\n","Epoch 10: train loss: 0.1673, train acc: 0.9457, val loss: 0.3149, val acc: 0.8693, time: 1.4452\n","Epoch 15: train loss: 0.0958, train acc: 0.9755, val loss: 0.3230, val acc: 0.8671, time: 1.4122\n","Epoch 5: train loss: 0.3298, train acc: 0.8746, val loss: 0.3803, val acc: 0.8386, time: 1.4637\n","Epoch 10: train loss: 0.1708, train acc: 0.9487, val loss: 0.3429, val acc: 0.8536, time: 1.4193\n","Epoch 15: train loss: 0.0974, train acc: 0.9754, val loss: 0.3367, val acc: 0.8621, time: 1.4553\n","Epoch 20: train loss: 0.0596, train acc: 0.9893, val loss: 0.3719, val acc: 0.8600, time: 1.4137\n","Epoch 5: train loss: 0.3179, train acc: 0.8821, val loss: 0.3641, val acc: 0.8436, time: 1.4414\n","Epoch 10: train loss: 0.1629, train acc: 0.9498, val loss: 0.3237, val acc: 0.8600, time: 1.4632\n","Epoch 15: train loss: 0.0887, train acc: 0.9793, val loss: 0.3159, val acc: 0.8729, time: 1.4357\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SWB5tBxwvejx","executionInfo":{"status":"ok","timestamp":1610660215801,"user_tz":-60,"elapsed":84621,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["# Plot losses and accuracies for the training and validation sets.\n","def plotit():\n","  iterationNumber = np.asscalar(np.random.randint(0, maxIter, 1))\n","  for icase in range(1):\n","    plt.figure(figsize=(15, 12))\n","    plt.subplot(2,2,1)\n","    plt.plot(cbow_classifier[icase][iterationNumber].history['train_loss'], label = \"TrainLoss\")\n","    plt.plot(cbow_classifier[icase][iterationNumber].history['val_loss'], label = \"ValLoss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"CNN Loss-Epoch Plot, case = \" + str(icase + 1))\n","    plt.legend()\n","\n","    plt.subplot(2,2,2)\n","    plt.plot(cbow_classifier[icase][iterationNumber].history['train_acc'], label = \"TrainAcc\")\n","    plt.plot(cbow_classifier[icase][iterationNumber].history['val_acc'], label = \"ValAcc\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.title(f\"CNN Accuracy-Epoch plot, case = {icase + 1} ,Avg Val Acc = {np.mean(finalAccCBOWVal[icase]):.2f}, Avg Train Acc = {np.mean(finalAccCBOWTrain[icase]):.2f}\")\n","    plt.legend()\n","\n","    plt.subplot(2,2,3)\n","    plt.plot(cbow_classifier[icase][iterationNumber].history['train_f1'], label = \"trainF1\")\n","    plt.plot(cbow_classifier[icase][iterationNumber].history['val_f1'], label = \"ValF1\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"F1-score\")\n","    plt.title(f\"CNN F1score-Epoch Plot, case = {icase + 1} ,Avg Val F1 = {np.mean(finalF1CBOWVal[icase]):.2f}, Avg Train F1 = {np.mean(finalF1CBOWTrain[icase]):.2f}\")\n","    plt.legend()\n","\n","    print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccCBOWVal[icase])}, Avg Train Accuracy = {np.mean(finalAccCBOWTrain[icase])}\")\n","    print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1CBOWVal[icase])}, Avg Train F1 = {np.mean(finalF1CBOWTrain[icase])}\")"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6DXCdFoxk1u"},"source":["**Performance on test dataset**"]},{"cell_type":"code","metadata":{"id":"1v3tp3FCxjmv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610660216571,"user_tz":-60,"elapsed":82774,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"26c70bd3-c16a-4b80-8e8d-cf83b1b17f70"},"source":["randomModel = np.asscalar(np.random.randint(0, maxIter, 1))\n","XX, YY = readData(filePathTest)\n","resultList = cbow_classifier[icase][randomModel].predict(XX)\n","fileNameRes = \"CBOW_classification_\" + str(icase+1) + \".txt\"\n","fileName = filePathResult + fileNameRes\n","writeData(fileName, XX, resultList)\n","testAcc, testF1 = evaluateTest(YY, resultList)\n","print(\"Test accuracy = \", testAcc)\n","print(\"Test F1 score = \", testF1)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"stream","text":["Test accuracy =  0.857\n","Test F1 score =  0.8885424785658612\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H_7T8tOXirLz"},"source":["# Design cases in CBOW model"]},{"cell_type":"markdown","metadata":{"id":"0PSu3d9figzq"},"source":["# Results and Inferences CBOW Model"]},{"cell_type":"code","metadata":{"id":"0Rbwt_kFvVej"},"source":["plotit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g4xV9kpfKZci"},"source":["# RNN"]},{"cell_type":"markdown","metadata":{"id":"sui366qbzBe9"},"source":["# Training RNN models"]},{"cell_type":"markdown","metadata":{"id":"gLIuorulzE_B"},"source":["Class that provides the embedded input tensor i.e. final states of input and output layer."]},{"cell_type":"code","metadata":{"id":"08gbwHKq_8KW","executionInfo":{"status":"ok","timestamp":1610660244638,"user_tz":-60,"elapsed":629,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["class RNNRepresentation(nn.Module):\n","\n","    def __init__(self, voc_size, emb_dim, rnn_size, icase):\n","        super().__init__()\n","        self.embedding = nn.Embedding(voc_size, emb_dim)\n","        self.icase = icase\n","\n","        # The RNN module: either a basic RNN, LSTM, or a GRU.\n","        if icase == 1:\n","          self.rnn = nn.RNN(input_size=emb_dim, hidden_size=rnn_size, bidirectional=True, num_layers=1, batch_first=True)\n","        elif icase == 2:\n","          self.rnn = nn.LSTM(input_size=emb_dim, hidden_size=rnn_size, bidirectional=True, num_layers=1, batch_first=True)\n","        elif icase == 3:\n","          self.rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_size, bidirectional=True, num_layers=1, batch_first=True)\n","\n","\n","    def forward(self, X):\n","        # X is a document tensor with shape (n_docs, n_words)\n","\n","        embedded = self.embedding(X)\n","\n","        # Shape of embedded: (n_docs, n_words, emb_dim)\n","\n","        # The RNNs return two tensors: one representing the outputs at all positions\n","        # of the final layer, and another representing the final states of each layer.\n","        # In this example, we'll use just the final states.\n","        # NB: for a bidirectional RNN, the final state corresponds to the *last* token\n","        # in the forward direction and the *first* token in the backward direction.\n","        if self.icase == 1 or self.icase == 3:\n","          rnn_out, final_state = self.rnn(embedded)\n","        elif self.icase == 2:\n","          # use the following instead if you're using an LSTM:\n","          rnn_out, (final_state, _) = self.rnn(embedded)\n","\n","        # For a GRU or simple RNN, final_state is a single tensor\n","        # of the shape (n_layers, n_docs, 2*rnn_size)\n","\n","        top_forward = final_state[-2]\n","        top_backward = final_state[-1]\n","        top_both = torch.cat([top_forward, top_backward], dim=1)\n","\n","        return top_both"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9zvfzfPzP4q"},"source":["Class to define the hyperparameters for RNN model and performs the operations done by main i.e. calling the right functions from Text Classifier class to perform the training."]},{"cell_type":"code","metadata":{"id":"BF3CBWq8njSI","executionInfo":{"status":"ok","timestamp":1610675123917,"user_tz":-60,"elapsed":649,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["class TextClassifierParameters():\n","    \"\"\"Container class to store the hyperparameters that control the training process.\"\"\"\n","\n","    # Computation device: 'cuda' or 'cpu'\n","    device = 'cuda'\n","\n","    # Maximal vocabulary size: by increasing, the system will probably be slower but more accurate.\n","    max_voc_size = 1000\n","\n","    # Number of training epochs.\n","    n_epochs = 50\n","\n","    # Size of batches: how many documents to process in parallel.\n","    batch_size = 64\n","\n","    # Learning rate in the Adam optimizer.\n","    eta = 2e-3\n","\n","    # Weight decay (L2 regularization) in the Adam optimizer.\n","    decay = 1e-5\n","\n","    # Dropout probability.\n","    dropout = 0.2\n","\n","    # Word embedding dimensionality.\n","    emb_dim = 64\n","\n","    # RNN size\n","    rnn_size = 128  # 128\n","\n","\n","def main_rnn(icase, jcase):\n","\n","    # Read the data.\n","    X, Y = readData(filePath)\n","\n","    print(f'Loaded {len(Y)} documents.')\n","\n","    # Initialize the text classifier\n","    params = TextClassifierParameters()\n","    clf = TextClassifier(params)\n","    if jcase == 1:\n","      clf.params.emb_dim = 64\n","    elif jcase == 2:\n","      clf.params.emb_dim = 128\n","    elif jcase == 3:\n","      clf.params.emb_dim = 32\n","\n","    # Preprocess the data.\n","    clf.preprocess(X, Y, ngrams = None, flagNoStop = None)\n","\n","    # Create a classification model: a bag-of-words representation with a linear classifier on top,\n","    # and dropout to reduce overfitting.\n","\n","    clf.set_model(nn.Sequential(\n","        RNNRepresentation(voc_size=clf.voc_size, emb_dim=params.emb_dim,\n","                          rnn_size=params.rnn_size, icase = icase),\n","        nn.Dropout(params.dropout),\n","        nn.Linear(in_features=2 * params.rnn_size, out_features=clf.n_classes)\n","    ))\n","\n","    # Train the classifier.\n","    clf.train()\n","\n","    return clf"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ocr4x-qnoJMs","executionInfo":{"status":"ok","timestamp":1610675417740,"user_tz":-60,"elapsed":286448,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"3416d809-fbb8-45be-a92f-0c1467dd1d09"},"source":["# Dropout = 0.2, 64 embedding\n","maxIter = 5\n","finalAccRNNVal = list()\n","finalAccRNNTrain = list()\n","finalF1RNNVal = list()\n","finalF1RNNTrain = list()\n","rnn_classifier = list()\n","for icase in range(3):\n","  print(\"case \", icase + 1)\n","  rnn_classifier.append(list())\n","  finalAccRNNVal.append(np.zeros(maxIter))  \n","  finalAccRNNTrain.append(np.zeros(maxIter))\n","  finalF1RNNVal.append(np.zeros(maxIter))\n","  finalF1RNNTrain.append(np.zeros(maxIter))\n","  for iterations in range(maxIter):\n","    rnn_classifier[icase].append(main_rnn(icase + 1, 1))\n","    finalAccRNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_acc'][len(rnn_classifier[icase][iterations].history['val_acc']) - 1]\n","    finalAccRNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_acc'][len(rnn_classifier[icase][iterations].history['train_acc']) - 1]\n","    finalF1RNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_f1'][len(rnn_classifier[icase][iterations].history['train_f1']) - 1]\n","    finalF1RNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_f1'][len(rnn_classifier[icase][iterations].history['val_f1']) - 1]\n","\n","  print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\n","  print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")"],"execution_count":80,"outputs":[{"output_type":"stream","text":["case  1\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3211, train acc: 0.8654, val loss: 0.4035, val acc: 0.8236, time: 1.9222\n","Epoch 10: train loss: 0.1610, train acc: 0.9420, val loss: 0.4539, val acc: 0.8529, time: 1.9981\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3040, train acc: 0.8727, val loss: 0.3812, val acc: 0.8221, time: 1.9960\n","Epoch 10: train loss: 0.1607, train acc: 0.9414, val loss: 0.4990, val acc: 0.8350, time: 1.9975\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3041, train acc: 0.8734, val loss: 0.3745, val acc: 0.8314, time: 2.0567\n","Epoch 10: train loss: 0.1334, train acc: 0.9479, val loss: 0.5120, val acc: 0.8443, time: 2.0934\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3201, train acc: 0.8654, val loss: 0.3988, val acc: 0.8379, time: 1.9748\n","Epoch 10: train loss: 0.1467, train acc: 0.9461, val loss: 0.5278, val acc: 0.8229, time: 2.1358\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3062, train acc: 0.8714, val loss: 0.4430, val acc: 0.7986, time: 2.1117\n","Average accuracy over multiple iterations, case = 1, Avg Val Accuracy = 0.8292857142857143, Avg Train Accuracy = 0.9509642857142857\n","Average F1 over multiple iterations, case = 1, Avg Val F1 = 0.857007169764362, Avg Train F1 = 0.9667854824825696\n","case  2\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1887, train acc: 0.9275, val loss: 0.3761, val acc: 0.8521, time: 2.1506\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1877, train acc: 0.9271, val loss: 0.3350, val acc: 0.8643, time: 2.1996\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1931, train acc: 0.9257, val loss: 0.3509, val acc: 0.8621, time: 2.2190\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1947, train acc: 0.9216, val loss: 0.3077, val acc: 0.8700, time: 2.1838\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1955, train acc: 0.9239, val loss: 0.3711, val acc: 0.8664, time: 2.1449\n","Average accuracy over multiple iterations, case = 2, Avg Val Accuracy = 0.8625714285714287, Avg Train Accuracy = 0.9749285714285716\n","Average F1 over multiple iterations, case = 2, Avg Val F1 = 0.9090770529708635, Avg Train F1 = 0.9823545964679941\n","case  3\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1582, train acc: 0.9375, val loss: 0.3119, val acc: 0.8679, time: 2.0915\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1553, train acc: 0.9413, val loss: 0.3471, val acc: 0.8650, time: 2.1199\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1652, train acc: 0.9366, val loss: 0.3350, val acc: 0.8586, time: 2.0876\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1472, train acc: 0.9425, val loss: 0.3510, val acc: 0.8714, time: 2.0996\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1587, train acc: 0.9409, val loss: 0.3521, val acc: 0.8621, time: 2.1166\n","Average accuracy over multiple iterations, case = 3, Avg Val Accuracy = 0.8675714285714285, Avg Train Accuracy = 0.9857857142857143\n","Average F1 over multiple iterations, case = 3, Avg Val F1 = 0.8554428457389663, Avg Train F1 = 0.9864489610870484\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knpOjE5muKUt","executionInfo":{"status":"ok","timestamp":1610675438544,"user_tz":-60,"elapsed":743,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"55c02305-2304-4438-82c3-583a86c4e06f"},"source":["# LSTM test\r\n","randomModel = np.asscalar(np.random.randint(0, maxIter, 1))\r\n","XX, YY = readData(filePathTest)\r\n","resultList = rnn_classifier[1][randomModel].predict(XX)\r\n","fileNameRes = \"LSTM_classification.csv\"\r\n","fileName = filePathResult + fileNameRes\r\n","writeData(fileName, XX, resultList)\r\n","testAcc, testF1 = evaluateTest(YY, resultList)\r\n","print(\"LSTM Test accuracy = \", testAcc)\r\n","print(\"LSTM Test F1 score = \", testF1)\r\n","\r\n","# GRU test\r\n","randomModel = np.asscalar(np.random.randint(0, maxIter, 1))\r\n","XX, YY = readData(filePathTest)\r\n","resultList = rnn_classifier[2][randomModel].predict(XX)\r\n","fileNameRes = \"LSTM_classification.csv\"\r\n","fileName = filePathResult + fileNameRes\r\n","writeData(fileName, XX, resultList)\r\n","testAcc, testF1 = evaluateTest(YY, resultList)\r\n","print(\"GRU Test accuracy = \", testAcc)\r\n","print(\"GRU Test F1 score = \", testF1)\r\n"],"execution_count":81,"outputs":[{"output_type":"stream","text":["LSTM Test accuracy =  0.864\n","LSTM Test F1 score =  0.8904991948470209\n","GRU Test accuracy =  0.875\n","GRU Test F1 score =  0.8966087675765095\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n","  del sys.path[0]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHYQYLxaBM19","executionInfo":{"status":"ok","timestamp":1610664270011,"user_tz":-60,"elapsed":246368,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"81dfbbf3-4a58-476c-e970-a83540b79efe"},"source":["# Dropout = 0.2, 128 embedding\r\n","maxIter = 5\r\n","finalAccRNNVal = list()\r\n","finalAccRNNTrain = list()\r\n","finalF1RNNVal = list()\r\n","finalF1RNNTrain = list()\r\n","rnn_classifier = list()\r\n","for icase in range(3):\r\n","  print(\"case \", icase + 1)\r\n","  rnn_classifier.append(list())\r\n","  finalAccRNNVal.append(np.zeros(maxIter))  \r\n","  finalAccRNNTrain.append(np.zeros(maxIter))\r\n","  finalF1RNNVal.append(np.zeros(maxIter))\r\n","  finalF1RNNTrain.append(np.zeros(maxIter))\r\n","  for iterations in range(maxIter):\r\n","    rnn_classifier[icase].append(main_rnn(icase + 1, 2))\r\n","    finalAccRNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_acc'][len(rnn_classifier[icase][iterations].history['val_acc']) - 1]\r\n","    finalAccRNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_acc'][len(rnn_classifier[icase][iterations].history['train_acc']) - 1]\r\n","    finalF1RNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_f1'][len(rnn_classifier[icase][iterations].history['train_f1']) - 1]\r\n","    finalF1RNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_f1'][len(rnn_classifier[icase][iterations].history['val_f1']) - 1]\r\n","\r\n","  print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\r\n","  print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["case  1\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2904, train acc: 0.8821, val loss: 0.3917, val acc: 0.8336, time: 1.9434\n","Epoch 10: train loss: 0.1366, train acc: 0.9491, val loss: 0.5390, val acc: 0.8257, time: 1.9555\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2819, train acc: 0.8825, val loss: 0.4052, val acc: 0.8171, time: 1.9821\n","Epoch 10: train loss: 0.1256, train acc: 0.9566, val loss: 0.5960, val acc: 0.7779, time: 1.9787\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2565, train acc: 0.8966, val loss: 0.4307, val acc: 0.8271, time: 1.9457\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2790, train acc: 0.8904, val loss: 0.4009, val acc: 0.8364, time: 2.0231\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2974, train acc: 0.8775, val loss: 0.3947, val acc: 0.8314, time: 1.9709\n","Average accuracy over multiple iterations, case = 1, Avg Val Accuracy = 0.8112857142857143, Avg Train Accuracy = 0.9380714285714286\n","Average F1 over multiple iterations, case = 1, Avg Val F1 = 0.8027908166686399, Avg Train F1 = 0.9514207020793389\n","case  2\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1383, train acc: 0.9495, val loss: 0.4616, val acc: 0.8586, time: 2.0867\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1136, train acc: 0.9586, val loss: 0.3771, val acc: 0.8700, time: 2.0928\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1409, train acc: 0.9464, val loss: 0.3476, val acc: 0.8736, time: 2.1565\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1279, train acc: 0.9516, val loss: 0.4057, val acc: 0.8636, time: 2.0933\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1338, train acc: 0.9514, val loss: 0.3260, val acc: 0.8793, time: 2.0858\n","Epoch 10: train loss: 0.0164, train acc: 0.9957, val loss: 0.6420, val acc: 0.8729, time: 2.0719\n","Average accuracy over multiple iterations, case = 2, Avg Val Accuracy = 0.8702857142857143, Avg Train Accuracy = 0.9890000000000001\n","Average F1 over multiple iterations, case = 2, Avg Val F1 = 0.8828850297035068, Avg Train F1 = 0.9868504739648566\n","case  3\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0907, train acc: 0.9648, val loss: 0.4627, val acc: 0.8543, time: 2.0243\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0774, train acc: 0.9745, val loss: 0.4465, val acc: 0.8729, time: 2.0648\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1109, train acc: 0.9584, val loss: 0.3883, val acc: 0.8721, time: 2.0399\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0926, train acc: 0.9645, val loss: 0.4375, val acc: 0.8671, time: 2.1025\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0751, train acc: 0.9736, val loss: 0.4191, val acc: 0.8736, time: 2.0628\n","Average accuracy over multiple iterations, case = 3, Avg Val Accuracy = 0.8682857142857143, Avg Train Accuracy = 0.9936071428571427\n","Average F1 over multiple iterations, case = 3, Avg Val F1 = 0.9098713666844143, Avg Train F1 = 0.9923726405840643\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q09lumZ1BRj8","executionInfo":{"status":"ok","timestamp":1610664498967,"user_tz":-60,"elapsed":475301,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"5de7cc34-35e4-40ff-ae59-8a1e36c879a5"},"source":["# Dropout = 0.2, 32 embedding\r\n","maxIter = 5\r\n","finalAccRNNVal = list()\r\n","finalAccRNNTrain = list()\r\n","finalF1RNNVal = list()\r\n","finalF1RNNTrain = list()\r\n","rnn_classifier = list()\r\n","for icase in range(3):\r\n","  print(\"case \", icase + 1)\r\n","  rnn_classifier.append(list())\r\n","  finalAccRNNVal.append(np.zeros(maxIter))  \r\n","  finalAccRNNTrain.append(np.zeros(maxIter))\r\n","  finalF1RNNVal.append(np.zeros(maxIter))\r\n","  finalF1RNNTrain.append(np.zeros(maxIter))\r\n","  for iterations in range(maxIter):\r\n","    rnn_classifier[icase].append(main_rnn(icase + 1, 3))\r\n","    finalAccRNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_acc'][len(rnn_classifier[icase][iterations].history['val_acc']) - 1]\r\n","    finalAccRNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_acc'][len(rnn_classifier[icase][iterations].history['train_acc']) - 1]\r\n","    finalF1RNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_f1'][len(rnn_classifier[icase][iterations].history['train_f1']) - 1]\r\n","    finalF1RNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_f1'][len(rnn_classifier[icase][iterations].history['val_f1']) - 1]\r\n","\r\n","  print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\r\n","  print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")"],"execution_count":37,"outputs":[{"output_type":"stream","text":["case  1\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2678, train acc: 0.8927, val loss: 0.3903, val acc: 0.8343, time: 1.9808\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2908, train acc: 0.8802, val loss: 0.4469, val acc: 0.8050, time: 2.0005\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2681, train acc: 0.8868, val loss: 0.4058, val acc: 0.8350, time: 1.9770\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2662, train acc: 0.8905, val loss: 0.4271, val acc: 0.8229, time: 2.0360\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2614, train acc: 0.8954, val loss: 0.3908, val acc: 0.8250, time: 2.0335\n","Average accuracy over multiple iterations, case = 1, Avg Val Accuracy = 0.8277142857142857, Avg Train Accuracy = 0.9322142857142858\n","Average F1 over multiple iterations, case = 1, Avg Val F1 = 0.8667481003885898, Avg Train F1 = 0.9529272440066838\n","case  2\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1366, train acc: 0.9514, val loss: 0.3631, val acc: 0.8736, time: 2.0784\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1185, train acc: 0.9559, val loss: 0.3833, val acc: 0.8579, time: 2.0538\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1395, train acc: 0.9504, val loss: 0.3763, val acc: 0.8700, time: 2.0581\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1331, train acc: 0.9516, val loss: 0.3497, val acc: 0.8743, time: 2.0883\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1469, train acc: 0.9452, val loss: 0.3621, val acc: 0.8714, time: 2.0845\n","Average accuracy over multiple iterations, case = 2, Avg Val Accuracy = 0.870857142857143, Avg Train Accuracy = 0.9857142857142858\n","Average F1 over multiple iterations, case = 2, Avg Val F1 = 0.909269166402958, Avg Train F1 = 0.9908795911563597\n","case  3\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0951, train acc: 0.9639, val loss: 0.3904, val acc: 0.8643, time: 2.0502\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0935, train acc: 0.9646, val loss: 0.4432, val acc: 0.8614, time: 2.0576\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0827, train acc: 0.9712, val loss: 0.4170, val acc: 0.8636, time: 2.0616\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1019, train acc: 0.9627, val loss: 0.4203, val acc: 0.8564, time: 2.1028\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0995, train acc: 0.9652, val loss: 0.4076, val acc: 0.8629, time: 2.0537\n","Average accuracy over multiple iterations, case = 3, Avg Val Accuracy = 0.8684285714285714, Avg Train Accuracy = 0.9931428571428571\n","Average F1 over multiple iterations, case = 3, Avg Val F1 = 0.8806723376826344, Avg Train F1 = 0.9950296049587724\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_gL2fexrUZTF"},"source":["class TextClassifierParameters():\r\n","    \"\"\"Container class to store the hyperparameters that control the training process.\"\"\"\r\n","\r\n","    # Computation device: 'cuda' or 'cpu'\r\n","    device = 'cuda'\r\n","\r\n","    # Maximal vocabulary size: by increasing, the system will probably be slower but more accurate.\r\n","    max_voc_size = 1000\r\n","\r\n","    # Number of training epochs.\r\n","    n_epochs = 50\r\n","\r\n","    # Size of batches: how many documents to process in parallel.\r\n","    batch_size = 64\r\n","\r\n","    # Learning rate in the Adam optimizer.\r\n","    eta = 2e-3\r\n","\r\n","    # Weight decay (L2 regularization) in the Adam optimizer.\r\n","    decay = 1e-5\r\n","\r\n","    # Dropout probability.\r\n","    dropout = 0.01\r\n","\r\n","    # Word embedding dimensionality.\r\n","    emb_dim = 64\r\n","\r\n","    # RNN size\r\n","    rnn_size = 128  # 128"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFRzXBfU2XfB","executionInfo":{"status":"ok","timestamp":1610665008331,"user_tz":-60,"elapsed":265163,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"80346b34-193d-4431-a6e9-265e6b76b9c6"},"source":["# Dropout = 0.01, 64 embedding\r\n","maxIter = 5\r\n","finalAccRNNVal = list()\r\n","finalAccRNNTrain = list()\r\n","finalF1RNNVal = list()\r\n","finalF1RNNTrain = list()\r\n","rnn_classifier = list()\r\n","for icase in range(3):\r\n","  print(\"case \", icase + 1)\r\n","  rnn_classifier.append(list())\r\n","  finalAccRNNVal.append(np.zeros(maxIter))  \r\n","  finalAccRNNTrain.append(np.zeros(maxIter))\r\n","  finalF1RNNVal.append(np.zeros(maxIter))\r\n","  finalF1RNNTrain.append(np.zeros(maxIter))\r\n","  for iterations in range(maxIter):\r\n","    rnn_classifier[icase].append(main_rnn(icase + 1, 1))\r\n","    finalAccRNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_acc'][len(rnn_classifier[icase][iterations].history['val_acc']) - 1]\r\n","    finalAccRNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_acc'][len(rnn_classifier[icase][iterations].history['train_acc']) - 1]\r\n","    finalF1RNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_f1'][len(rnn_classifier[icase][iterations].history['train_f1']) - 1]\r\n","    finalF1RNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_f1'][len(rnn_classifier[icase][iterations].history['val_f1']) - 1]\r\n","\r\n","  print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\r\n","  print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")"],"execution_count":39,"outputs":[{"output_type":"stream","text":["case  1\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3099, train acc: 0.8691, val loss: 0.4244, val acc: 0.8150, time: 2.0478\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2908, train acc: 0.8766, val loss: 0.4009, val acc: 0.8257, time: 2.0217\n","Epoch 10: train loss: 0.0968, train acc: 0.9668, val loss: 0.5844, val acc: 0.8043, time: 2.0720\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3070, train acc: 0.8743, val loss: 0.3836, val acc: 0.8300, time: 1.9785\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2969, train acc: 0.8789, val loss: 0.4460, val acc: 0.8079, time: 2.0095\n","Epoch 10: train loss: 0.1257, train acc: 0.9520, val loss: 0.5437, val acc: 0.8329, time: 2.0089\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3047, train acc: 0.8711, val loss: 0.3852, val acc: 0.8414, time: 1.9943\n","Average accuracy over multiple iterations, case = 1, Avg Val Accuracy = 0.8174285714285714, Avg Train Accuracy = 0.9476428571428572\n","Average F1 over multiple iterations, case = 1, Avg Val F1 = 0.8737882580183856, Avg Train F1 = 0.9610644905200273\n","case  2\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1857, train acc: 0.9257, val loss: 0.3489, val acc: 0.8571, time: 2.1372\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1853, train acc: 0.9284, val loss: 0.3650, val acc: 0.8543, time: 2.1782\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1979, train acc: 0.9177, val loss: 0.3439, val acc: 0.8629, time: 2.1846\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1952, train acc: 0.9264, val loss: 0.3572, val acc: 0.8636, time: 2.1256\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1805, train acc: 0.9302, val loss: 0.3393, val acc: 0.8657, time: 2.1012\n","Average accuracy over multiple iterations, case = 2, Avg Val Accuracy = 0.863142857142857, Avg Train Accuracy = 0.9808928571428572\n","Average F1 over multiple iterations, case = 2, Avg Val F1 = 0.8989613216837966, Avg Train F1 = 0.9924036594536542\n","case  3\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1613, train acc: 0.9395, val loss: 0.3414, val acc: 0.8671, time: 2.1659\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1669, train acc: 0.9318, val loss: 0.3303, val acc: 0.8621, time: 2.0621\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1526, train acc: 0.9407, val loss: 0.3259, val acc: 0.8864, time: 2.0881\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1617, train acc: 0.9404, val loss: 0.3410, val acc: 0.8707, time: 2.0749\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1654, train acc: 0.9350, val loss: 0.3080, val acc: 0.8729, time: 2.0640\n","Average accuracy over multiple iterations, case = 3, Avg Val Accuracy = 0.8675714285714285, Avg Train Accuracy = 0.9914642857142857\n","Average F1 over multiple iterations, case = 3, Avg Val F1 = 0.9091565482281455, Avg Train F1 = 0.990198276913981\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLUILtwVBdJ0","executionInfo":{"status":"ok","timestamp":1610665238547,"user_tz":-60,"elapsed":230213,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"4af9ffa4-0aaf-40b1-b851-e0d0800aa971"},"source":["# Dropout = 0.01, 128 embedding\r\n","maxIter = 5\r\n","finalAccRNNVal = list()\r\n","finalAccRNNTrain = list()\r\n","finalF1RNNVal = list()\r\n","finalF1RNNTrain = list()\r\n","rnn_classifier = list()\r\n","for icase in range(3):\r\n","  print(\"case \", icase + 1)\r\n","  rnn_classifier.append(list())\r\n","  finalAccRNNVal.append(np.zeros(maxIter))  \r\n","  finalAccRNNTrain.append(np.zeros(maxIter))\r\n","  finalF1RNNVal.append(np.zeros(maxIter))\r\n","  finalF1RNNTrain.append(np.zeros(maxIter))\r\n","  for iterations in range(maxIter):\r\n","    rnn_classifier[icase].append(main_rnn(icase + 1, 2))\r\n","    finalAccRNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_acc'][len(rnn_classifier[icase][iterations].history['val_acc']) - 1]\r\n","    finalAccRNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_acc'][len(rnn_classifier[icase][iterations].history['train_acc']) - 1]\r\n","    finalF1RNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_f1'][len(rnn_classifier[icase][iterations].history['train_f1']) - 1]\r\n","    finalF1RNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_f1'][len(rnn_classifier[icase][iterations].history['val_f1']) - 1]\r\n","\r\n","  print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\r\n","  print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")"],"execution_count":40,"outputs":[{"output_type":"stream","text":["case  1\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2560, train acc: 0.8964, val loss: 0.3908, val acc: 0.8321, time: 2.0072\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2975, train acc: 0.8754, val loss: 0.3758, val acc: 0.8400, time: 2.0017\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2554, train acc: 0.8945, val loss: 0.3951, val acc: 0.8414, time: 1.9670\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2706, train acc: 0.8904, val loss: 0.4259, val acc: 0.8200, time: 2.0251\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2384, train acc: 0.9068, val loss: 0.4146, val acc: 0.8300, time: 2.0494\n","Average accuracy over multiple iterations, case = 1, Avg Val Accuracy = 0.8300000000000001, Avg Train Accuracy = 0.9391428571428572\n","Average F1 over multiple iterations, case = 1, Avg Val F1 = 0.8606978847168568, Avg Train F1 = 0.9475336836967001\n","case  2\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1131, train acc: 0.9587, val loss: 0.4015, val acc: 0.8493, time: 2.1741\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1163, train acc: 0.9586, val loss: 0.3944, val acc: 0.8564, time: 2.0700\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1166, train acc: 0.9602, val loss: 0.3797, val acc: 0.8714, time: 2.0874\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1173, train acc: 0.9564, val loss: 0.3970, val acc: 0.8693, time: 2.0681\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1247, train acc: 0.9520, val loss: 0.3747, val acc: 0.8750, time: 2.1364\n","Average accuracy over multiple iterations, case = 2, Avg Val Accuracy = 0.8628571428571428, Avg Train Accuracy = 0.9875357142857144\n","Average F1 over multiple iterations, case = 2, Avg Val F1 = 0.8784132540036392, Avg Train F1 = 0.9934821531014265\n","case  3\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0849, train acc: 0.9698, val loss: 0.3925, val acc: 0.8743, time: 2.0423\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0680, train acc: 0.9764, val loss: 0.3988, val acc: 0.8729, time: 2.1562\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0928, train acc: 0.9668, val loss: 0.3858, val acc: 0.8700, time: 2.0868\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0766, train acc: 0.9712, val loss: 0.4326, val acc: 0.8629, time: 2.0629\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.0844, train acc: 0.9702, val loss: 0.4200, val acc: 0.8693, time: 2.1370\n","Average accuracy over multiple iterations, case = 3, Avg Val Accuracy = 0.8668571428571428, Avg Train Accuracy = 0.9949999999999999\n","Average F1 over multiple iterations, case = 3, Avg Val F1 = 0.8424119947738091, Avg Train F1 = 0.9963195900643825\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1h8YTRX-Bhe0","executionInfo":{"status":"ok","timestamp":1610665547099,"user_tz":-60,"elapsed":538758,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"475d5d3a-d545-499e-ae64-db310faaf020"},"source":["# Dropout = 0.01, 32 embedding\r\n","maxIter = 5\r\n","finalAccRNNVal = list()\r\n","finalAccRNNTrain = list()\r\n","finalF1RNNVal = list()\r\n","finalF1RNNTrain = list()\r\n","rnn_classifier = list()\r\n","for icase in range(3):\r\n","  print(\"case \", icase + 1)\r\n","  rnn_classifier.append(list())\r\n","  finalAccRNNVal.append(np.zeros(maxIter))  \r\n","  finalAccRNNTrain.append(np.zeros(maxIter))\r\n","  finalF1RNNVal.append(np.zeros(maxIter))\r\n","  finalF1RNNTrain.append(np.zeros(maxIter))\r\n","  for iterations in range(maxIter):\r\n","    rnn_classifier[icase].append(main_rnn(icase + 1, 3))\r\n","    finalAccRNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_acc'][len(rnn_classifier[icase][iterations].history['val_acc']) - 1]\r\n","    finalAccRNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_acc'][len(rnn_classifier[icase][iterations].history['train_acc']) - 1]\r\n","    finalF1RNNTrain[icase][iterations] = rnn_classifier[icase][iterations].history['train_f1'][len(rnn_classifier[icase][iterations].history['train_f1']) - 1]\r\n","    finalF1RNNVal[icase][iterations] = rnn_classifier[icase][iterations].history['val_f1'][len(rnn_classifier[icase][iterations].history['val_f1']) - 1]\r\n","\r\n","  print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\r\n","  print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")"],"execution_count":41,"outputs":[{"output_type":"stream","text":["case  1\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3595, train acc: 0.8477, val loss: 0.4296, val acc: 0.8200, time: 2.0095\n","Epoch 10: train loss: 0.2272, train acc: 0.9077, val loss: 0.4263, val acc: 0.8229, time: 1.9420\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3742, train acc: 0.8343, val loss: 0.4334, val acc: 0.8079, time: 2.0391\n","Epoch 10: train loss: 0.2351, train acc: 0.9066, val loss: 0.4444, val acc: 0.8129, time: 1.9808\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3415, train acc: 0.8527, val loss: 0.3940, val acc: 0.8307, time: 2.0790\n","Epoch 10: train loss: 0.2485, train acc: 0.9000, val loss: 0.4067, val acc: 0.8379, time: 2.0349\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3490, train acc: 0.8498, val loss: 0.4097, val acc: 0.8236, time: 1.9250\n","Epoch 10: train loss: 0.2334, train acc: 0.9055, val loss: 0.4193, val acc: 0.8329, time: 1.9662\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.3528, train acc: 0.8477, val loss: 0.4308, val acc: 0.8064, time: 1.9983\n","Epoch 10: train loss: 0.2171, train acc: 0.9118, val loss: 0.5408, val acc: 0.7979, time: 1.9823\n","Average accuracy over multiple iterations, case = 1, Avg Val Accuracy = 0.8290000000000001, Avg Train Accuracy = 0.933\n","Average F1 over multiple iterations, case = 1, Avg Val F1 = 0.8757906338107952, Avg Train F1 = 0.9562013374792109\n","case  2\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2505, train acc: 0.8980, val loss: 0.3508, val acc: 0.8450, time: 2.1065\n","Epoch 10: train loss: 0.1441, train acc: 0.9455, val loss: 0.4075, val acc: 0.8471, time: 2.0690\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2432, train acc: 0.8971, val loss: 0.3021, val acc: 0.8621, time: 2.1198\n","Epoch 10: train loss: 0.0910, train acc: 0.9673, val loss: 0.3728, val acc: 0.8750, time: 2.1517\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2266, train acc: 0.9089, val loss: 0.4092, val acc: 0.8407, time: 2.0844\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2475, train acc: 0.8984, val loss: 0.3495, val acc: 0.8486, time: 2.0494\n","Epoch 10: train loss: 0.0817, train acc: 0.9723, val loss: 0.5212, val acc: 0.8557, time: 2.0909\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2372, train acc: 0.9077, val loss: 0.3525, val acc: 0.8693, time: 2.1047\n","Average accuracy over multiple iterations, case = 2, Avg Val Accuracy = 0.8585714285714288, Avg Train Accuracy = 0.9678571428571429\n","Average F1 over multiple iterations, case = 2, Avg Val F1 = 0.8882929377895048, Avg Train F1 = 0.9784901394061747\n","case  3\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2164, train acc: 0.9161, val loss: 0.3105, val acc: 0.8750, time: 2.1016\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2395, train acc: 0.9000, val loss: 0.2986, val acc: 0.8757, time: 2.0826\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2214, train acc: 0.9098, val loss: 0.3363, val acc: 0.8593, time: 2.0467\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2233, train acc: 0.9079, val loss: 0.3127, val acc: 0.8571, time: 2.0796\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.2370, train acc: 0.9004, val loss: 0.3244, val acc: 0.8686, time: 2.0892\n","Average accuracy over multiple iterations, case = 3, Avg Val Accuracy = 0.8617142857142855, Avg Train Accuracy = 0.9713928571428572\n","Average F1 over multiple iterations, case = 3, Avg Val F1 = 0.8905635578993317, Avg Train F1 = 0.9810079695449812\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yXbcYOHSrb8B","executionInfo":{"status":"ok","timestamp":1610671840728,"user_tz":-60,"elapsed":756,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["# Plot losses and accuracies for the training and validation sets.\n","def plotit_RNN():\n","  iterationNumber = np.asscalar(np.random.randint(0, maxIter, 1))\n","  for icase in range(3):\n","    plt.figure(figsize=(15, 12))\n","    plt.subplot(2,2,1)\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_loss'], label = \"TrainLoss\")\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_loss'], label = \"ValLoss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"LSTM Loss-Epoch Plot, case = \" + str(icase + 1))\n","    plt.legend()\n","    figName = \"/content/drive/My Drive/MLNLP/FinalAssignment/LSTM_loss.eps\"\n","    plt.savefig(figName)\n","\n","    plt.subplot(2,2,2)\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_acc'], label = \"TrainAcc\")\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_acc'], label = \"ValAcc\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.title(f\"LSTM Accuracy-Epoch plot, case = {icase + 1} ,Avg Val Acc = {np.mean(finalAccRNNVal[icase]):.2f}, Avg Train Acc = {np.mean(finalAccRNNTrain[icase]):.2f}\")\n","    plt.legend()\n","    figName = \"/content/drive/My Drive/MLNLP/FinalAssignment/LSTM_Acc.eps\"\n","    plt.savefig(figName)\n","\n","    plt.subplot(2,2,3)\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_acc'], label = \"TrainAcc\")\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_acc'], label = \"ValAcc\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"F1 score\")\n","    plt.title(f\"LSTM F1score-Epoch plot, case = {icase + 1} ,Avg Val F1 = {np.mean(finalF1RNNVal[icase]):.2f}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase]):.2f}\")\n","    plt.legend()\n","    figName = \"/content/drive/My Drive/MLNLP/FinalAssignment/LSTM_F1.eps\"\n","    plt.savefig(figName)\n","\n","    print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\n","    print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")\n"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pdtVZgHiTNB","executionInfo":{"status":"ok","timestamp":1610672248316,"user_tz":-60,"elapsed":856,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["# Plot losses and accuracies for the training and validation sets.\r\n","def plotit_RNN():\r\n","  iterationNumber = np.asscalar(np.random.randint(0, maxIter, 1))\r\n","  for icase in range(3):\r\n","    plt.figure(figsize=(15, 12))\r\n","    plt.subplot(2,2,1)\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_loss'], label = \"TrainLoss\")\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_loss'], label = \"ValLoss\")\r\n","    plt.xlabel(\"Epoch\")\r\n","    plt.ylabel(\"Loss\")\r\n","    plt.title(\"RNN Loss-Epoch Plot, case = \" + str(icase + 1))\r\n","    plt.legend()\r\n","\r\n","    plt.subplot(2,2,2)\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_acc'], label = \"TrainAcc\")\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_acc'], label = \"ValAcc\")\r\n","    plt.xlabel(\"Epoch\")\r\n","    plt.ylabel(\"Accuracy\")\r\n","    plt.title(f\"RNN Accuracy-Epoch plot, case = {icase + 1} ,Avg Val Acc = {np.mean(finalAccRNNVal[icase]):.2f}, Avg Train Acc = {np.mean(finalAccRNNTrain[icase]):.2f}\")\r\n","    plt.legend()\r\n","\r\n","    plt.subplot(2,2,3)\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_f1'], label = \"TrainF1\")\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_f1'], label = \"ValF1\")\r\n","    plt.xlabel(\"Epoch\")\r\n","    plt.ylabel(\"F1 score\")\r\n","    plt.title(f\"RNN F1score-Epoch plot, case = {icase + 1} ,Avg Val F1 = {np.mean(finalF1RNNVal[icase]):.2f}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase]):.2f}\")\r\n","    plt.legend()\r\n","\r\n","    print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\r\n","    print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")\r\n"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"id":"I2mUM5ZziadB","executionInfo":{"status":"ok","timestamp":1610672249433,"user_tz":-60,"elapsed":651,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["# Plot losses and accuracies for the training and validation sets.\r\n","def plotit_LSTM():\r\n","  iterationNumber = np.asscalar(np.random.randint(0, maxIter, 1))\r\n","  for icase in [1]:\r\n","    plt.figure()\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_loss'], label = \"TrainLoss\")\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_loss'], label = \"ValLoss\")\r\n","    plt.xlabel(\"Epoch\")\r\n","    plt.ylabel(\"Loss\")\r\n","    plt.title(\"LSTM Loss-Epoch Plot, case = \" + str(icase + 1))\r\n","    plt.legend()\r\n","    figName = \"/content/drive/My Drive/MLNLP/FinalAssignment/LSTM_loss.eps\"\r\n","    plt.savefig(figName)\r\n","\r\n","    plt.figure()\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_acc'], label = \"TrainAcc\")\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_acc'], label = \"ValAcc\")\r\n","    plt.xlabel(\"Epoch\")\r\n","    plt.ylabel(\"Accuracy\")\r\n","    plt.title(f\"LSTM Accuracy-Epoch plot, case = {icase + 1} ,Avg Val Acc = {np.mean(finalAccRNNVal[icase]):.2f}, Avg Train Acc = {np.mean(finalAccRNNTrain[icase]):.2f}\")\r\n","    plt.legend()\r\n","    figName = \"/content/drive/My Drive/MLNLP/FinalAssignment/LSTM_Acc.eps\"\r\n","    plt.savefig(figName)\r\n","\r\n","    plt.figure()\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['train_f1'], label = \"TrainF1\")\r\n","    plt.plot(rnn_classifier[icase][iterationNumber].history['val_f1'], label = \"ValF1\")\r\n","    plt.xlabel(\"Epoch\")\r\n","    plt.ylabel(\"F1 score\")\r\n","    plt.title(f\"LSTM F1score-Epoch plot, case = {icase + 1} ,Avg Val F1 = {np.mean(finalF1RNNVal[icase]):.2f}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase]):.2f}\")\r\n","    plt.legend()\r\n","    figName = \"/content/drive/My Drive/MLNLP/FinalAssignment/LSTM_F1.eps\"\r\n","    plt.savefig(figName)\r\n","\r\n","    print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccRNNVal[icase])}, Avg Train Accuracy = {np.mean(finalAccRNNTrain[icase])}\")\r\n","    print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1RNNVal[icase])}, Avg Train F1 = {np.mean(finalF1RNNTrain[icase])}\")\r\n"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"aLw3UR9Eim4A","executionInfo":{"status":"ok","timestamp":1610672252738,"user_tz":-60,"elapsed":1477,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"8b3f23c3-ff6b-4fdd-bd19-784c2aa5ec2f"},"source":["plotit_LSTM()"],"execution_count":78,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Average accuracy over multiple iterations, case = 2, Avg Val Accuracy = 0.8585714285714288, Avg Train Accuracy = 0.9678571428571429\n","Average F1 over multiple iterations, case = 2, Avg Val F1 = 0.8882929377895048, Avg Train F1 = 0.9784901394061747\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 576x396 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"358.652187pt\" version=\"1.1\" viewBox=\"0 0 501.515 358.652187\" width=\"501.515pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 358.652187 \nL 501.515 358.652187 \nL 501.515 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 47.915 320.87625 \nL 494.315 320.87625 \nL 494.315 21.89625 \nL 47.915 21.89625 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 68.205909 320.87625 \nL 68.205909 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 51.703125 34.421875 \nQ 51.703125 24.515625 49.828125 17.75 \nQ 47.953125 10.984375 44.703125 6.8125 \nQ 41.453125 2.640625 37.0625 0.828125 \nQ 32.671875 -0.984375 27.6875 -0.984375 \nQ 22.65625 -0.984375 18.3125 0.828125 \nQ 13.96875 2.640625 10.765625 6.78125 \nQ 7.5625 10.9375 5.734375 17.703125 \nQ 3.90625 24.46875 3.90625 34.421875 \nQ 3.90625 44.828125 5.734375 51.640625 \nQ 7.5625 58.453125 10.78125 62.5 \nQ 14.015625 66.546875 18.40625 68.1875 \nQ 22.796875 69.828125 27.984375 69.828125 \nQ 32.90625 69.828125 37.21875 68.1875 \nQ 41.546875 66.546875 44.765625 62.5 \nQ 48 58.453125 49.84375 51.640625 \nQ 51.703125 44.828125 51.703125 34.421875 \nz\nM 42.78125 34.421875 \nQ 42.78125 42.625 41.796875 48.0625 \nQ 40.828125 53.515625 38.921875 56.765625 \nQ 37.015625 60.015625 34.25 61.359375 \nQ 31.5 62.703125 27.984375 62.703125 \nQ 24.265625 62.703125 21.4375 61.328125 \nQ 18.609375 59.96875 16.671875 56.71875 \nQ 14.75 53.46875 13.765625 48.015625 \nQ 12.796875 42.578125 12.796875 34.421875 \nQ 12.796875 26.515625 13.796875 21.09375 \nQ 14.796875 15.671875 16.71875 12.375 \nQ 18.65625 9.078125 21.4375 7.640625 \nQ 24.21875 6.203125 27.78125 6.203125 \nQ 31.25 6.203125 34.03125 7.640625 \nQ 36.8125 9.078125 38.734375 12.375 \nQ 40.671875 15.671875 41.71875 21.09375 \nQ 42.78125 26.515625 42.78125 34.421875 \nz\n\" id=\"LiberationSans-48\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(65.42544 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 149.369545 320.87625 \nL 149.369545 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 5.03125 0 \nL 5.03125 6.203125 \nQ 7.515625 11.921875 11.109375 16.28125 \nQ 14.703125 20.65625 18.65625 24.1875 \nQ 22.609375 27.734375 26.484375 30.765625 \nQ 30.375 33.796875 33.5 36.8125 \nQ 36.625 39.84375 38.546875 43.15625 \nQ 40.484375 46.484375 40.484375 50.6875 \nQ 40.484375 53.609375 39.59375 55.828125 \nQ 38.71875 58.0625 37.0625 59.5625 \nQ 35.40625 61.078125 33.078125 61.828125 \nQ 30.765625 62.59375 27.9375 62.59375 \nQ 25.296875 62.59375 22.96875 61.859375 \nQ 20.65625 61.140625 18.84375 59.671875 \nQ 17.046875 58.203125 15.890625 56.03125 \nQ 14.75 53.859375 14.40625 50.984375 \nL 5.421875 51.8125 \nQ 5.859375 55.515625 7.46875 58.78125 \nQ 9.078125 62.0625 11.90625 64.53125 \nQ 14.75 67 18.71875 68.40625 \nQ 22.703125 69.828125 27.9375 69.828125 \nQ 33.0625 69.828125 37.0625 68.609375 \nQ 41.0625 67.390625 43.8125 64.984375 \nQ 46.578125 62.59375 48.046875 59.078125 \nQ 49.515625 55.5625 49.515625 50.984375 \nQ 49.515625 47.515625 48.265625 44.390625 \nQ 47.015625 41.265625 44.9375 38.421875 \nQ 42.875 35.59375 40.140625 32.953125 \nQ 37.40625 30.328125 34.421875 27.8125 \nQ 31.453125 25.296875 28.421875 22.828125 \nQ 25.390625 20.359375 22.71875 17.859375 \nQ 20.0625 15.375 17.96875 12.8125 \nQ 15.875 10.25 14.703125 7.46875 \nL 50.59375 7.46875 \nL 50.59375 0 \nz\n\" id=\"LiberationSans-50\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(146.589077 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 230.533182 320.87625 \nL 230.533182 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 43.015625 15.578125 \nL 43.015625 0 \nL 34.71875 0 \nL 34.71875 15.578125 \nL 2.296875 15.578125 \nL 2.296875 22.40625 \nL 33.796875 68.796875 \nL 43.015625 68.796875 \nL 43.015625 22.515625 \nL 52.6875 22.515625 \nL 52.6875 15.578125 \nz\nM 34.71875 58.890625 \nQ 34.625 58.640625 34.234375 57.9375 \nQ 33.84375 57.234375 33.34375 56.34375 \nQ 32.859375 55.46875 32.34375 54.5625 \nQ 31.84375 53.65625 31.453125 53.078125 \nL 13.8125 27.09375 \nQ 13.578125 26.703125 13.109375 26.0625 \nQ 12.640625 25.4375 12.15625 24.78125 \nQ 11.671875 24.125 11.171875 23.484375 \nQ 10.6875 22.859375 10.40625 22.515625 \nL 34.71875 22.515625 \nz\n\" id=\"LiberationSans-52\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(227.752713 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 311.696818 320.87625 \nL 311.696818 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 51.21875 22.515625 \nQ 51.21875 17.328125 49.78125 13 \nQ 48.34375 8.6875 45.53125 5.578125 \nQ 42.71875 2.484375 38.5625 0.75 \nQ 34.421875 -0.984375 29 -0.984375 \nQ 23 -0.984375 18.5 1.3125 \nQ 14.015625 3.609375 11.03125 7.921875 \nQ 8.0625 12.25 6.5625 18.53125 \nQ 5.078125 24.8125 5.078125 32.8125 \nQ 5.078125 42 6.765625 48.921875 \nQ 8.453125 55.859375 11.625 60.5 \nQ 14.796875 65.140625 19.359375 67.484375 \nQ 23.921875 69.828125 29.6875 69.828125 \nQ 33.203125 69.828125 36.28125 69.09375 \nQ 39.359375 68.359375 41.875 66.71875 \nQ 44.390625 65.09375 46.28125 62.40625 \nQ 48.1875 59.71875 49.3125 55.8125 \nL 40.921875 54.296875 \nQ 39.546875 58.734375 36.546875 60.71875 \nQ 33.546875 62.703125 29.59375 62.703125 \nQ 25.984375 62.703125 23.046875 60.984375 \nQ 20.125 59.28125 18.0625 55.875 \nQ 16.015625 52.484375 14.90625 47.359375 \nQ 13.8125 42.234375 13.8125 35.40625 \nQ 16.21875 39.84375 20.5625 42.15625 \nQ 24.90625 44.484375 30.515625 44.484375 \nQ 35.203125 44.484375 39.015625 42.96875 \nQ 42.828125 41.453125 45.53125 38.59375 \nQ 48.25 35.75 49.734375 31.671875 \nQ 51.21875 27.59375 51.21875 22.515625 \nz\nM 42.28125 22.125 \nQ 42.28125 25.6875 41.40625 28.5625 \nQ 40.53125 31.453125 38.765625 33.46875 \nQ 37.015625 35.5 34.421875 36.59375 \nQ 31.84375 37.703125 28.421875 37.703125 \nQ 26.03125 37.703125 23.578125 36.984375 \nQ 21.140625 36.28125 19.15625 34.6875 \nQ 17.1875 33.109375 15.9375 30.515625 \nQ 14.703125 27.9375 14.703125 24.21875 \nQ 14.703125 20.40625 15.671875 17.109375 \nQ 16.65625 13.8125 18.484375 11.375 \nQ 20.3125 8.9375 22.890625 7.515625 \nQ 25.484375 6.109375 28.71875 6.109375 \nQ 31.890625 6.109375 34.40625 7.203125 \nQ 36.921875 8.296875 38.671875 10.375 \nQ 40.4375 12.453125 41.359375 15.421875 \nQ 42.28125 18.40625 42.28125 22.125 \nz\n\" id=\"LiberationSans-54\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(308.916349 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 392.860455 320.87625 \nL 392.860455 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 51.265625 19.1875 \nQ 51.265625 14.796875 49.875 11.109375 \nQ 48.484375 7.421875 45.625 4.734375 \nQ 42.78125 2.046875 38.328125 0.53125 \nQ 33.890625 -0.984375 27.828125 -0.984375 \nQ 21.78125 -0.984375 17.359375 0.53125 \nQ 12.9375 2.046875 10.03125 4.703125 \nQ 7.125 7.375 5.734375 11.0625 \nQ 4.34375 14.75 4.34375 19.09375 \nQ 4.34375 22.859375 5.484375 25.78125 \nQ 6.640625 28.71875 8.5625 30.828125 \nQ 10.5 32.953125 12.96875 34.25 \nQ 15.4375 35.546875 18.0625 35.984375 \nL 18.0625 36.1875 \nQ 15.1875 36.859375 12.90625 38.375 \nQ 10.640625 39.890625 9.09375 42.015625 \nQ 7.5625 44.140625 6.75 46.71875 \nQ 5.953125 49.3125 5.953125 52.203125 \nQ 5.953125 55.8125 7.34375 59 \nQ 8.734375 62.203125 11.46875 64.625 \nQ 14.203125 67.046875 18.25 68.4375 \nQ 22.3125 69.828125 27.640625 69.828125 \nQ 33.25 69.828125 37.375 68.40625 \nQ 41.5 67 44.203125 64.578125 \nQ 46.921875 62.15625 48.234375 58.9375 \nQ 49.5625 55.71875 49.5625 52.09375 \nQ 49.5625 49.265625 48.75 46.671875 \nQ 47.953125 44.09375 46.40625 41.96875 \nQ 44.875 39.84375 42.59375 38.34375 \nQ 40.328125 36.859375 37.359375 36.28125 \nL 37.359375 36.078125 \nQ 40.328125 35.59375 42.859375 34.296875 \nQ 45.40625 33.015625 47.265625 30.890625 \nQ 49.125 28.765625 50.1875 25.828125 \nQ 51.265625 22.90625 51.265625 19.1875 \nz\nM 40.4375 51.609375 \nQ 40.4375 54.203125 39.765625 56.34375 \nQ 39.109375 58.5 37.59375 60.03125 \nQ 36.078125 61.578125 33.640625 62.421875 \nQ 31.203125 63.28125 27.640625 63.28125 \nQ 24.171875 63.28125 21.78125 62.421875 \nQ 19.390625 61.578125 17.84375 60.03125 \nQ 16.3125 58.5 15.625 56.34375 \nQ 14.9375 54.203125 14.9375 51.609375 \nQ 14.9375 49.5625 15.46875 47.40625 \nQ 16.015625 45.265625 17.421875 43.5 \nQ 18.84375 41.75 21.328125 40.625 \nQ 23.828125 39.5 27.734375 39.5 \nQ 31.890625 39.5 34.40625 40.625 \nQ 36.921875 41.75 38.25 43.5 \nQ 39.59375 45.265625 40.015625 47.40625 \nQ 40.4375 49.5625 40.4375 51.609375 \nz\nM 42.140625 20.015625 \nQ 42.140625 22.515625 41.453125 24.828125 \nQ 40.765625 27.15625 39.109375 28.9375 \nQ 37.453125 30.71875 34.640625 31.8125 \nQ 31.84375 32.90625 27.640625 32.90625 \nQ 23.78125 32.90625 21.0625 31.8125 \nQ 18.359375 30.71875 16.671875 28.90625 \nQ 14.984375 27.09375 14.203125 24.71875 \nQ 13.421875 22.359375 13.421875 19.828125 \nQ 13.421875 16.65625 14.203125 14.03125 \nQ 14.984375 11.421875 16.6875 9.546875 \nQ 18.40625 7.671875 21.1875 6.640625 \nQ 23.96875 5.609375 27.9375 5.609375 \nQ 31.9375 5.609375 34.671875 6.640625 \nQ 37.40625 7.671875 39.0625 9.546875 \nQ 40.71875 11.421875 41.421875 14.078125 \nQ 42.140625 16.75 42.140625 20.015625 \nz\n\" id=\"LiberationSans-56\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(390.079986 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 474.024091 320.87625 \nL 474.024091 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 7.625 0 \nL 7.625 7.46875 \nL 25.140625 7.46875 \nL 25.140625 60.40625 \nL 9.625 49.3125 \nL 9.625 57.625 \nL 25.875 68.796875 \nL 33.984375 68.796875 \nL 33.984375 7.46875 \nL 50.734375 7.46875 \nL 50.734375 0 \nz\n\" id=\"LiberationSans-49\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(468.463153 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-49\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 8.203125 0 \nL 8.203125 68.796875 \nL 60.40625 68.796875 \nL 60.40625 61.1875 \nL 17.53125 61.1875 \nL 17.53125 39.109375 \nL 57.46875 39.109375 \nL 57.46875 31.59375 \nL 17.53125 31.59375 \nL 17.53125 7.625 \nL 62.40625 7.625 \nL 62.40625 0 \nz\n\" id=\"LiberationSans-69\"/>\n      <path d=\"M 51.421875 26.65625 \nQ 51.421875 20.65625 50.4375 15.578125 \nQ 49.46875 10.5 47.1875 6.828125 \nQ 44.921875 3.171875 41.1875 1.09375 \nQ 37.453125 -0.984375 31.984375 -0.984375 \nQ 26.3125 -0.984375 22.0625 1.171875 \nQ 17.828125 3.328125 15.578125 8.203125 \nL 15.328125 8.203125 \nQ 15.375 8.109375 15.40625 7.328125 \nQ 15.4375 6.546875 15.453125 5.375 \nQ 15.484375 4.203125 15.5 2.75 \nQ 15.53125 1.3125 15.53125 -0.09375 \nL 15.53125 -20.75 \nL 6.734375 -20.75 \nL 6.734375 42.046875 \nQ 6.734375 43.953125 6.703125 45.703125 \nQ 6.6875 47.46875 6.640625 48.90625 \nQ 6.59375 50.34375 6.546875 51.359375 \nQ 6.5 52.390625 6.453125 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.6875 15.0625 51.796875 \nQ 15.140625 50.921875 15.203125 49.671875 \nQ 15.28125 48.4375 15.359375 47.015625 \nQ 15.4375 45.609375 15.4375 44.34375 \nL 15.625 44.34375 \nQ 16.84375 46.875 18.40625 48.65625 \nQ 19.96875 50.4375 21.96875 51.578125 \nQ 23.96875 52.734375 26.4375 53.25 \nQ 28.90625 53.765625 31.984375 53.765625 \nQ 37.453125 53.765625 41.1875 51.8125 \nQ 44.921875 49.859375 47.1875 46.3125 \nQ 49.46875 42.78125 50.4375 37.765625 \nQ 51.421875 32.765625 51.421875 26.65625 \nz\nM 42.1875 26.46875 \nQ 42.1875 31.34375 41.59375 35.15625 \nQ 41.015625 38.96875 39.578125 41.59375 \nQ 38.140625 44.234375 35.734375 45.59375 \nQ 33.34375 46.96875 29.734375 46.96875 \nQ 26.8125 46.96875 24.21875 46.140625 \nQ 21.625 45.3125 19.703125 42.96875 \nQ 17.78125 40.625 16.65625 36.5 \nQ 15.53125 32.375 15.53125 25.78125 \nQ 15.53125 20.171875 16.453125 16.28125 \nQ 17.390625 12.40625 19.171875 10.015625 \nQ 20.953125 7.625 23.578125 6.5625 \nQ 26.21875 5.515625 29.640625 5.515625 \nQ 33.296875 5.515625 35.71875 6.921875 \nQ 38.140625 8.34375 39.578125 11.03125 \nQ 41.015625 13.71875 41.59375 17.59375 \nQ 42.1875 21.484375 42.1875 26.46875 \nz\n\" id=\"LiberationSans-112\"/>\n      <path d=\"M 51.421875 26.46875 \nQ 51.421875 12.59375 45.3125 5.796875 \nQ 39.203125 -0.984375 27.59375 -0.984375 \nQ 22.078125 -0.984375 17.71875 0.671875 \nQ 13.375 2.34375 10.375 5.765625 \nQ 7.375 9.1875 5.78125 14.328125 \nQ 4.203125 19.484375 4.203125 26.46875 \nQ 4.203125 53.8125 27.875 53.8125 \nQ 34.03125 53.8125 38.5 52.09375 \nQ 42.96875 50.390625 45.828125 46.96875 \nQ 48.6875 43.5625 50.046875 38.421875 \nQ 51.421875 33.296875 51.421875 26.46875 \nz\nM 42.1875 26.46875 \nQ 42.1875 32.625 41.234375 36.625 \nQ 40.28125 40.625 38.453125 43.015625 \nQ 36.625 45.40625 33.984375 46.359375 \nQ 31.34375 47.3125 28.03125 47.3125 \nQ 24.65625 47.3125 21.9375 46.3125 \nQ 19.234375 45.3125 17.328125 42.890625 \nQ 15.4375 40.484375 14.421875 36.46875 \nQ 13.421875 32.46875 13.421875 26.46875 \nQ 13.421875 20.3125 14.5 16.28125 \nQ 15.578125 12.25 17.453125 9.859375 \nQ 19.34375 7.46875 21.90625 6.484375 \nQ 24.46875 5.515625 27.484375 5.515625 \nQ 30.859375 5.515625 33.59375 6.46875 \nQ 36.328125 7.421875 38.234375 9.8125 \nQ 40.140625 12.203125 41.15625 16.25 \nQ 42.1875 20.3125 42.1875 26.46875 \nz\n\" id=\"LiberationSans-111\"/>\n      <path d=\"M 13.421875 26.65625 \nQ 13.421875 22.125 14.078125 18.3125 \nQ 14.75 14.5 16.3125 11.734375 \nQ 17.875 8.984375 20.4375 7.46875 \nQ 23 5.953125 26.765625 5.953125 \nQ 31.453125 5.953125 34.59375 8.484375 \nQ 37.75 11.03125 38.484375 16.3125 \nL 47.359375 15.71875 \nQ 46.921875 12.453125 45.453125 9.421875 \nQ 44 6.390625 41.484375 4.09375 \nQ 38.96875 1.8125 35.34375 0.40625 \nQ 31.734375 -0.984375 27 -0.984375 \nQ 20.796875 -0.984375 16.453125 1.109375 \nQ 12.109375 3.21875 9.390625 6.90625 \nQ 6.6875 10.59375 5.46875 15.59375 \nQ 4.25 20.609375 4.25 26.46875 \nQ 4.25 31.78125 5.125 35.859375 \nQ 6 39.9375 7.59375 42.984375 \nQ 9.1875 46.046875 11.328125 48.125 \nQ 13.484375 50.203125 15.984375 51.4375 \nQ 18.5 52.6875 21.28125 53.25 \nQ 24.078125 53.8125 26.90625 53.8125 \nQ 31.34375 53.8125 34.8125 52.59375 \nQ 38.28125 51.375 40.796875 49.25 \nQ 43.3125 47.125 44.875 44.234375 \nQ 46.4375 41.359375 47.078125 38.03125 \nL 38.03125 37.359375 \nQ 37.359375 41.75 34.5625 44.328125 \nQ 31.78125 46.921875 26.65625 46.921875 \nQ 22.90625 46.921875 20.390625 45.671875 \nQ 17.875 44.4375 16.3125 41.921875 \nQ 14.75 39.40625 14.078125 35.59375 \nQ 13.421875 31.78125 13.421875 26.65625 \nz\n\" id=\"LiberationSans-99\"/>\n      <path d=\"M 15.484375 43.796875 \nQ 16.9375 46.484375 18.640625 48.359375 \nQ 20.359375 50.25 22.40625 51.46875 \nQ 24.46875 52.6875 26.90625 53.25 \nQ 29.34375 53.8125 32.375 53.8125 \nQ 37.453125 53.8125 40.703125 52.4375 \nQ 43.953125 51.078125 45.828125 48.609375 \nQ 47.703125 46.140625 48.40625 42.71875 \nQ 49.125 39.3125 49.125 35.203125 \nL 49.125 0 \nL 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 36.859375 39.859375 39.390625 \nQ 39.453125 41.9375 38.28125 43.625 \nQ 37.109375 45.3125 34.953125 46.15625 \nQ 32.8125 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.890625 \nQ 21.234375 44.78125 19.453125 42.71875 \nQ 17.671875 40.671875 16.6875 37.734375 \nQ 15.71875 34.8125 15.71875 31.15625 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 72.46875 \nL 15.71875 72.46875 \nL 15.71875 53.609375 \nQ 15.71875 52 15.671875 50.390625 \nQ 15.625 48.78125 15.546875 47.40625 \nQ 15.484375 46.046875 15.421875 45.09375 \nQ 15.375 44.140625 15.328125 43.796875 \nz\n\" id=\"LiberationSans-104\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(255.520781 349.169687)scale(0.11 -0.11)\">\n      <use xlink:href=\"#LiberationSans-69\"/>\n      <use x=\"66.699219\" xlink:href=\"#LiberationSans-112\"/>\n      <use x=\"122.314453\" xlink:href=\"#LiberationSans-111\"/>\n      <use x=\"177.929688\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"227.929688\" xlink:href=\"#LiberationSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 305.370074 \nL 494.315 305.370074 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_8\">\n      <!-- 0.10 -->\n      <defs>\n       <path d=\"M 9.125 0 \nL 9.125 10.6875 \nL 18.65625 10.6875 \nL 18.65625 0 \nz\n\" id=\"LiberationSans-46\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 308.993511)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-49\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 271.483614 \nL 494.315 271.483614 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_9\">\n      <!-- 0.15 -->\n      <defs>\n       <path d=\"M 51.421875 22.40625 \nQ 51.421875 17.234375 49.859375 12.9375 \nQ 48.296875 8.640625 45.21875 5.53125 \nQ 42.140625 2.4375 37.578125 0.71875 \nQ 33.015625 -0.984375 27 -0.984375 \nQ 21.578125 -0.984375 17.546875 0.28125 \nQ 13.53125 1.5625 10.734375 3.78125 \nQ 7.953125 6 6.3125 8.984375 \nQ 4.6875 11.96875 4 15.375 \nL 12.890625 16.40625 \nQ 13.421875 14.453125 14.390625 12.625 \nQ 15.375 10.796875 17.0625 9.34375 \nQ 18.75 7.90625 21.21875 7.046875 \nQ 23.6875 6.203125 27.203125 6.203125 \nQ 30.609375 6.203125 33.390625 7.25 \nQ 36.1875 8.296875 38.15625 10.34375 \nQ 40.140625 12.40625 41.203125 15.375 \nQ 42.28125 18.359375 42.28125 22.21875 \nQ 42.28125 25.390625 41.25 28.046875 \nQ 40.234375 30.71875 38.328125 32.640625 \nQ 36.421875 34.578125 33.65625 35.640625 \nQ 30.90625 36.71875 27.390625 36.71875 \nQ 25.203125 36.71875 23.34375 36.328125 \nQ 21.484375 35.9375 19.890625 35.25 \nQ 18.3125 34.578125 17.015625 33.671875 \nQ 15.71875 32.765625 14.59375 31.78125 \nL 6 31.78125 \nL 8.296875 68.796875 \nL 47.40625 68.796875 \nL 47.40625 61.328125 \nL 16.3125 61.328125 \nL 14.984375 39.5 \nQ 17.328125 41.3125 20.84375 42.59375 \nQ 24.359375 43.890625 29.203125 43.890625 \nQ 34.328125 43.890625 38.421875 42.328125 \nQ 42.53125 40.765625 45.40625 37.90625 \nQ 48.296875 35.0625 49.859375 31.109375 \nQ 51.421875 27.15625 51.421875 22.40625 \nz\n\" id=\"LiberationSans-53\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 275.107052)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-49\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 237.597155 \nL 494.315 237.597155 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_10\">\n      <!-- 0.20 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 241.220593)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-50\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 203.710696 \nL 494.315 203.710696 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_11\">\n      <!-- 0.25 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 207.334134)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-50\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 169.824237 \nL 494.315 169.824237 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_22\"/>\n     <g id=\"text_12\">\n      <!-- 0.30 -->\n      <defs>\n       <path d=\"M 51.21875 19 \nQ 51.21875 14.265625 49.671875 10.546875 \nQ 48.140625 6.84375 45.1875 4.265625 \nQ 42.234375 1.703125 37.859375 0.359375 \nQ 33.5 -0.984375 27.875 -0.984375 \nQ 21.484375 -0.984375 17.109375 0.609375 \nQ 12.75 2.203125 9.90625 4.8125 \nQ 7.078125 7.421875 5.65625 10.765625 \nQ 4.25 14.109375 3.8125 17.671875 \nL 12.890625 18.5 \nQ 13.28125 15.765625 14.328125 13.515625 \nQ 15.375 11.28125 17.1875 9.671875 \nQ 19 8.0625 21.625 7.171875 \nQ 24.265625 6.296875 27.875 6.296875 \nQ 34.515625 6.296875 38.296875 9.5625 \nQ 42.09375 12.84375 42.09375 19.28125 \nQ 42.09375 23.09375 40.40625 25.40625 \nQ 38.71875 27.734375 36.203125 29.03125 \nQ 33.6875 30.328125 30.734375 30.765625 \nQ 27.78125 31.203125 25.296875 31.203125 \nL 20.3125 31.203125 \nL 20.3125 38.8125 \nL 25.09375 38.8125 \nQ 27.59375 38.8125 30.265625 39.328125 \nQ 32.953125 39.84375 35.171875 41.1875 \nQ 37.40625 42.53125 38.84375 44.828125 \nQ 40.28125 47.125 40.28125 50.6875 \nQ 40.28125 56.203125 37.03125 59.390625 \nQ 33.796875 62.59375 27.390625 62.59375 \nQ 21.578125 62.59375 17.984375 59.609375 \nQ 14.40625 56.640625 13.8125 51.21875 \nL 4.984375 51.90625 \nQ 5.515625 56.453125 7.46875 59.8125 \nQ 9.421875 63.1875 12.421875 65.40625 \nQ 15.4375 67.625 19.28125 68.71875 \nQ 23.140625 69.828125 27.484375 69.828125 \nQ 33.25 69.828125 37.390625 68.375 \nQ 41.546875 66.9375 44.1875 64.46875 \nQ 46.828125 62.015625 48.0625 58.6875 \nQ 49.3125 55.375 49.3125 51.609375 \nQ 49.3125 48.578125 48.484375 45.9375 \nQ 47.65625 43.3125 45.890625 41.203125 \nQ 44.140625 39.109375 41.421875 37.59375 \nQ 38.71875 36.078125 34.90625 35.296875 \nL 34.90625 35.109375 \nQ 39.0625 34.671875 42.140625 33.21875 \nQ 45.21875 31.78125 47.21875 29.625 \nQ 49.21875 27.484375 50.21875 24.75 \nQ 51.21875 22.015625 51.21875 19 \nz\n\" id=\"LiberationSans-51\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 173.447674)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-51\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 135.937778 \nL 494.315 135.937778 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_24\"/>\n     <g id=\"text_13\">\n      <!-- 0.35 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 139.561215)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-51\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 102.051319 \nL 494.315 102.051319 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_26\"/>\n     <g id=\"text_14\">\n      <!-- 0.40 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 105.674756)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-52\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 68.164859 \nL 494.315 68.164859 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_28\"/>\n     <g id=\"text_15\">\n      <!-- 0.45 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 71.788297)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-52\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_29\">\n      <path clip-path=\"url(#pe50a750b6a)\" d=\"M 47.915 34.2784 \nL 494.315 34.2784 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_30\"/>\n     <g id=\"text_16\">\n      <!-- 0.50 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 37.901838)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-53\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- Loss -->\n     <defs>\n      <path d=\"M 8.203125 0 \nL 8.203125 68.796875 \nL 17.53125 68.796875 \nL 17.53125 7.625 \nL 52.296875 7.625 \nL 52.296875 0 \nz\n\" id=\"LiberationSans-76\"/>\n      <path d=\"M 46.390625 14.59375 \nQ 46.390625 10.890625 44.9375 7.984375 \nQ 43.5 5.078125 40.765625 3.09375 \nQ 38.03125 1.125 34.046875 0.0625 \nQ 30.078125 -0.984375 24.953125 -0.984375 \nQ 20.359375 -0.984375 16.671875 -0.265625 \nQ 12.984375 0.4375 10.203125 2 \nQ 7.421875 3.5625 5.53125 6.125 \nQ 3.65625 8.6875 2.78125 12.40625 \nL 10.546875 13.921875 \nQ 11.671875 9.671875 15.1875 7.6875 \nQ 18.703125 5.71875 24.953125 5.71875 \nQ 27.78125 5.71875 30.140625 6.109375 \nQ 32.515625 6.5 34.21875 7.453125 \nQ 35.9375 8.40625 36.890625 9.984375 \nQ 37.84375 11.578125 37.84375 13.921875 \nQ 37.84375 16.3125 36.71875 17.84375 \nQ 35.59375 19.390625 33.59375 20.40625 \nQ 31.59375 21.4375 28.734375 22.1875 \nQ 25.875 22.953125 22.46875 23.875 \nQ 19.28125 24.703125 16.15625 25.734375 \nQ 13.03125 26.765625 10.515625 28.4375 \nQ 8.015625 30.125 6.453125 32.609375 \nQ 4.890625 35.109375 4.890625 38.875 \nQ 4.890625 46.09375 10.03125 49.875 \nQ 15.1875 53.65625 25.046875 53.65625 \nQ 33.796875 53.65625 38.9375 50.578125 \nQ 44.09375 47.515625 45.453125 40.71875 \nL 37.546875 39.75 \nQ 37.109375 41.796875 35.9375 43.1875 \nQ 34.765625 44.578125 33.109375 45.4375 \nQ 31.453125 46.296875 29.375 46.65625 \nQ 27.296875 47.015625 25.046875 47.015625 \nQ 19.09375 47.015625 16.25 45.203125 \nQ 13.421875 43.40625 13.421875 39.75 \nQ 13.421875 37.59375 14.46875 36.203125 \nQ 15.53125 34.8125 17.40625 33.859375 \nQ 19.28125 32.90625 21.921875 32.203125 \nQ 24.5625 31.5 27.734375 30.71875 \nQ 29.828125 30.171875 32.03125 29.5625 \nQ 34.234375 28.953125 36.296875 28.09375 \nQ 38.375 27.25 40.203125 26.09375 \nQ 42.046875 24.953125 43.40625 23.34375 \nQ 44.78125 21.734375 45.578125 19.578125 \nQ 46.390625 17.4375 46.390625 14.59375 \nz\n\" id=\"LiberationSans-115\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(15.171562 183.003281)rotate(-90)scale(0.11 -0.11)\">\n      <use xlink:href=\"#LiberationSans-76\"/>\n      <use x=\"55.615234\" xlink:href=\"#LiberationSans-111\"/>\n      <use x=\"111.230469\" xlink:href=\"#LiberationSans-115\"/>\n      <use x=\"161.230469\" xlink:href=\"#LiberationSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path clip-path=\"url(#pe50a750b6a)\" d=\"M 68.205909 35.48625 \nL 108.787727 117.535453 \nL 149.369545 148.4666 \nL 189.951364 177.097587 \nL 230.533182 203.366704 \nL 271.115 227.112388 \nL 311.696818 250.179881 \nL 352.278636 271.727359 \nL 392.860455 235.099668 \nL 433.442273 275.47216 \nL 474.024091 307.28625 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.75;\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#pe50a750b6a)\" d=\"M 68.205909 92.993732 \nL 108.787727 121.984977 \nL 149.369545 130.579546 \nL 189.951364 138.149591 \nL 230.533182 135.376003 \nL 271.115 144.416741 \nL 311.696818 120.100931 \nL 352.278636 104.770852 \nL 392.860455 131.467228 \nL 433.442273 96.954884 \nL 474.024091 76.871047 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.75;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 47.915 320.87625 \nL 47.915 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 494.315 320.87625 \nL 494.315 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 47.915 320.87625 \nL 494.315 320.87625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 47.915 21.89625 \nL 494.315 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- LSTM Loss-Epoch Plot, case = 2 -->\n    <defs>\n     <path d=\"M 62.109375 19 \nQ 62.109375 14.65625 60.421875 10.984375 \nQ 58.734375 7.328125 55.21875 4.65625 \nQ 51.703125 2 46.359375 0.5 \nQ 41.015625 -0.984375 33.6875 -0.984375 \nQ 20.84375 -0.984375 13.671875 3.515625 \nQ 6.5 8.015625 4.546875 16.5 \nL 13.578125 18.3125 \nQ 14.265625 15.625 15.671875 13.421875 \nQ 17.09375 11.234375 19.5 9.640625 \nQ 21.921875 8.0625 25.484375 7.171875 \nQ 29.046875 6.296875 34.03125 6.296875 \nQ 38.1875 6.296875 41.65625 7 \nQ 45.125 7.71875 47.609375 9.171875 \nQ 50.09375 10.640625 51.484375 12.953125 \nQ 52.875 15.28125 52.875 18.5 \nQ 52.875 21.875 51.34375 23.96875 \nQ 49.8125 26.078125 47.015625 27.4375 \nQ 44.234375 28.8125 40.375 29.734375 \nQ 36.53125 30.671875 31.84375 31.734375 \nQ 28.953125 32.375 26.046875 33.125 \nQ 23.140625 33.890625 20.484375 34.9375 \nQ 17.828125 35.984375 15.484375 37.390625 \nQ 13.140625 38.8125 11.421875 40.796875 \nQ 9.71875 42.78125 8.734375 45.390625 \nQ 7.765625 48 7.765625 51.421875 \nQ 7.765625 56.296875 9.734375 59.78125 \nQ 11.71875 63.28125 15.234375 65.53125 \nQ 18.75 67.78125 23.53125 68.796875 \nQ 28.328125 69.828125 33.890625 69.828125 \nQ 40.28125 69.828125 44.8125 68.828125 \nQ 49.359375 67.828125 52.484375 65.8125 \nQ 55.609375 63.8125 57.484375 60.859375 \nQ 59.375 57.90625 60.5 54 \nL 51.3125 52.390625 \nQ 50.640625 54.890625 49.34375 56.84375 \nQ 48.046875 58.796875 45.9375 60.109375 \nQ 43.84375 61.421875 40.84375 62.109375 \nQ 37.84375 62.796875 33.796875 62.796875 \nQ 29 62.796875 25.75 61.9375 \nQ 22.515625 61.078125 20.53125 59.609375 \nQ 18.5625 58.15625 17.703125 56.171875 \nQ 16.84375 54.203125 16.84375 51.90625 \nQ 16.84375 48.828125 18.375 46.84375 \nQ 19.921875 44.875 22.5625 43.546875 \nQ 25.203125 42.234375 28.65625 41.359375 \nQ 32.125 40.484375 36.03125 39.59375 \nQ 39.203125 38.875 42.359375 38.109375 \nQ 45.515625 37.359375 48.390625 36.296875 \nQ 51.265625 35.25 53.78125 33.828125 \nQ 56.296875 32.421875 58.15625 30.375 \nQ 60.015625 28.328125 61.0625 25.53125 \nQ 62.109375 22.75 62.109375 19 \nz\n\" id=\"LiberationSans-83\"/>\n     <path d=\"M 35.15625 61.1875 \nL 35.15625 0 \nL 25.875 0 \nL 25.875 61.1875 \nL 2.25 61.1875 \nL 2.25 68.796875 \nL 58.796875 68.796875 \nL 58.796875 61.1875 \nz\n\" id=\"LiberationSans-84\"/>\n     <path d=\"M 66.703125 0 \nL 66.703125 45.90625 \nQ 66.703125 48.390625 66.75 50.96875 \nQ 66.796875 53.5625 66.890625 55.71875 \nQ 67 58.203125 67.140625 60.546875 \nQ 66.453125 58.0625 65.71875 55.609375 \nQ 65.09375 53.515625 64.328125 51.140625 \nQ 63.578125 48.78125 62.84375 46.875 \nL 45.0625 0 \nL 38.53125 0 \nL 20.515625 46.875 \nQ 20.21875 47.609375 19.890625 48.578125 \nQ 19.578125 49.5625 19.203125 50.65625 \nQ 18.84375 51.765625 18.46875 52.90625 \nQ 18.109375 54.046875 17.78125 55.171875 \nQ 16.9375 57.765625 16.15625 60.546875 \nQ 16.21875 57.8125 16.3125 55.125 \nQ 16.40625 52.828125 16.453125 50.3125 \nQ 16.5 47.796875 16.5 45.90625 \nL 16.5 0 \nL 8.203125 0 \nL 8.203125 68.796875 \nL 20.453125 68.796875 \nL 38.765625 21.09375 \nQ 39.109375 20.125 39.59375 18.578125 \nQ 40.09375 17.046875 40.53125 15.421875 \nQ 40.96875 13.8125 41.328125 12.375 \nQ 41.703125 10.9375 41.84375 10.15625 \nQ 42 10.9375 42.390625 12.40625 \nQ 42.78125 13.875 43.28125 15.484375 \nQ 43.796875 17.09375 44.28125 18.609375 \nQ 44.78125 20.125 45.171875 21.09375 \nL 63.140625 68.796875 \nL 75.09375 68.796875 \nL 75.09375 0 \nz\n\" id=\"LiberationSans-77\"/>\n     <path id=\"LiberationSans-32\"/>\n     <path d=\"M 4.4375 22.65625 \nL 4.4375 30.46875 \nL 28.859375 30.46875 \nL 28.859375 22.65625 \nz\n\" id=\"LiberationSans-45\"/>\n     <path d=\"M 61.421875 48.09375 \nQ 61.421875 43.609375 59.9375 39.71875 \nQ 58.453125 35.84375 55.5 32.984375 \nQ 52.546875 30.125 48.09375 28.46875 \nQ 43.65625 26.8125 37.75 26.8125 \nL 17.53125 26.8125 \nL 17.53125 0 \nL 8.203125 0 \nL 8.203125 68.796875 \nL 37.15625 68.796875 \nQ 43.265625 68.796875 47.796875 67.3125 \nQ 52.34375 65.828125 55.375 63.109375 \nQ 58.40625 60.40625 59.90625 56.5625 \nQ 61.421875 52.734375 61.421875 48.09375 \nz\nM 52.046875 48 \nQ 52.046875 54.546875 48.046875 57.9375 \nQ 44.046875 61.328125 36.03125 61.328125 \nL 17.53125 61.328125 \nL 17.53125 34.1875 \nL 36.421875 34.1875 \nQ 44.484375 34.1875 48.265625 37.75 \nQ 52.046875 41.3125 52.046875 48 \nz\n\" id=\"LiberationSans-80\"/>\n     <path d=\"M 6.734375 0 \nL 6.734375 72.46875 \nL 15.53125 72.46875 \nL 15.53125 0 \nz\n\" id=\"LiberationSans-108\"/>\n     <path d=\"M 27.046875 0.390625 \nQ 25.046875 -0.140625 22.96875 -0.453125 \nQ 20.90625 -0.78125 18.171875 -0.78125 \nQ 7.625 -0.78125 7.625 11.1875 \nL 7.625 46.4375 \nL 1.515625 46.4375 \nL 1.515625 52.828125 \nL 7.953125 52.828125 \nL 10.546875 64.65625 \nL 16.40625 64.65625 \nL 16.40625 52.828125 \nL 26.171875 52.828125 \nL 26.171875 46.4375 \nL 16.40625 46.4375 \nL 16.40625 13.09375 \nQ 16.40625 9.28125 17.640625 7.734375 \nQ 18.890625 6.203125 21.96875 6.203125 \nQ 23.25 6.203125 24.4375 6.390625 \nQ 25.640625 6.59375 27.046875 6.890625 \nz\n\" id=\"LiberationSans-116\"/>\n     <path d=\"M 18.796875 10.6875 \nL 18.796875 2.484375 \nQ 18.796875 -0.09375 18.578125 -2.21875 \nQ 18.359375 -4.34375 17.875 -6.171875 \nQ 17.390625 -8.015625 16.671875 -9.625 \nQ 15.96875 -11.234375 14.984375 -12.796875 \nL 8.984375 -12.796875 \nQ 11.1875 -9.625 12.375 -6.390625 \nQ 13.578125 -3.171875 13.578125 0 \nL 9.28125 0 \nL 9.28125 10.6875 \nz\n\" id=\"LiberationSans-44\"/>\n     <path d=\"M 20.21875 -0.984375 \nQ 12.25 -0.984375 8.25 3.21875 \nQ 4.25 7.421875 4.25 14.75 \nQ 4.25 19.96875 6.21875 23.3125 \nQ 8.203125 26.65625 11.390625 28.5625 \nQ 14.59375 30.46875 18.6875 31.203125 \nQ 22.796875 31.9375 27.046875 32.03125 \nL 38.921875 32.234375 \nL 38.921875 35.109375 \nQ 38.921875 38.375 38.234375 40.671875 \nQ 37.546875 42.96875 36.125 44.375 \nQ 34.71875 45.796875 32.59375 46.453125 \nQ 30.46875 47.125 27.59375 47.125 \nQ 25.046875 47.125 23 46.75 \nQ 20.953125 46.390625 19.4375 45.4375 \nQ 17.921875 44.484375 16.984375 42.84375 \nQ 16.0625 41.21875 15.765625 38.71875 \nL 6.59375 39.546875 \nQ 7.078125 42.671875 8.4375 45.28125 \nQ 9.8125 47.90625 12.328125 49.796875 \nQ 14.84375 51.703125 18.625 52.75 \nQ 22.40625 53.8125 27.78125 53.8125 \nQ 37.75 53.8125 42.765625 49.234375 \nQ 47.796875 44.671875 47.796875 36.03125 \nL 47.796875 13.28125 \nQ 47.796875 9.375 48.828125 7.390625 \nQ 49.859375 5.421875 52.734375 5.421875 \nQ 53.46875 5.421875 54.203125 5.515625 \nQ 54.9375 5.609375 55.609375 5.765625 \nL 55.609375 0.296875 \nQ 53.953125 -0.09375 52.3125 -0.28125 \nQ 50.6875 -0.484375 48.828125 -0.484375 \nQ 46.34375 -0.484375 44.5625 0.171875 \nQ 42.78125 0.828125 41.65625 2.171875 \nQ 40.53125 3.515625 39.9375 5.484375 \nQ 39.359375 7.46875 39.203125 10.109375 \nL 38.921875 10.109375 \nQ 37.5 7.5625 35.8125 5.515625 \nQ 34.125 3.46875 31.875 2.03125 \nQ 29.640625 0.59375 26.78125 -0.1875 \nQ 23.921875 -0.984375 20.21875 -0.984375 \nz\nM 22.21875 5.609375 \nQ 26.421875 5.609375 29.5625 7.140625 \nQ 32.71875 8.6875 34.78125 11.078125 \nQ 36.859375 13.484375 37.890625 16.3125 \nQ 38.921875 19.140625 38.921875 21.734375 \nL 38.921875 26.078125 \nL 29.296875 25.875 \nQ 26.078125 25.828125 23.171875 25.40625 \nQ 20.265625 25 18.0625 23.78125 \nQ 15.875 22.5625 14.578125 20.359375 \nQ 13.28125 18.171875 13.28125 14.59375 \nQ 13.28125 10.296875 15.59375 7.953125 \nQ 17.921875 5.609375 22.21875 5.609375 \nz\n\" id=\"LiberationSans-97\"/>\n     <path d=\"M 13.484375 24.5625 \nQ 13.484375 20.40625 14.328125 16.90625 \nQ 15.1875 13.421875 16.96875 10.90625 \nQ 18.75 8.40625 21.53125 7 \nQ 24.3125 5.609375 28.21875 5.609375 \nQ 33.9375 5.609375 37.375 7.90625 \nQ 40.828125 10.203125 42.046875 13.71875 \nL 49.75 11.53125 \nQ 48.921875 9.328125 47.4375 7.109375 \nQ 45.953125 4.890625 43.453125 3.09375 \nQ 40.96875 1.3125 37.234375 0.15625 \nQ 33.5 -0.984375 28.21875 -0.984375 \nQ 16.5 -0.984375 10.375 6 \nQ 4.25 12.984375 4.25 26.765625 \nQ 4.25 34.1875 6.09375 39.328125 \nQ 7.953125 44.484375 11.171875 47.703125 \nQ 14.40625 50.921875 18.703125 52.359375 \nQ 23 53.8125 27.875 53.8125 \nQ 34.515625 53.8125 38.984375 51.65625 \nQ 43.453125 49.515625 46.15625 45.71875 \nQ 48.875 41.9375 50.015625 36.8125 \nQ 51.171875 31.6875 51.171875 25.734375 \nL 51.171875 24.5625 \nz\nM 42.09375 31.296875 \nQ 41.359375 39.65625 37.84375 43.484375 \nQ 34.328125 47.3125 27.734375 47.3125 \nQ 25.53125 47.3125 23.109375 46.609375 \nQ 20.703125 45.90625 18.65625 44.09375 \nQ 16.609375 42.28125 15.1875 39.171875 \nQ 13.765625 36.078125 13.578125 31.296875 \nz\n\" id=\"LiberationSans-101\"/>\n     <path d=\"M 4.890625 41.796875 \nL 4.890625 49.03125 \nL 53.46875 49.03125 \nL 53.46875 41.796875 \nz\nM 4.890625 16.796875 \nL 4.890625 24.03125 \nL 53.46875 24.03125 \nL 53.46875 16.796875 \nz\n\" id=\"LiberationSans-61\"/>\n    </defs>\n    <g style=\"fill:#262626;\" transform=\"translate(183.576875 15.89625)scale(0.12 -0.12)\">\n     <use xlink:href=\"#LiberationSans-76\"/>\n     <use x=\"55.615234\" xlink:href=\"#LiberationSans-83\"/>\n     <use x=\"122.314453\" xlink:href=\"#LiberationSans-84\"/>\n     <use x=\"183.398438\" xlink:href=\"#LiberationSans-77\"/>\n     <use x=\"266.699219\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"294.482422\" xlink:href=\"#LiberationSans-76\"/>\n     <use x=\"350.097656\" xlink:href=\"#LiberationSans-111\"/>\n     <use x=\"405.712891\" xlink:href=\"#LiberationSans-115\"/>\n     <use x=\"455.712891\" xlink:href=\"#LiberationSans-115\"/>\n     <use x=\"505.712891\" xlink:href=\"#LiberationSans-45\"/>\n     <use x=\"539.013672\" xlink:href=\"#LiberationSans-69\"/>\n     <use x=\"605.712891\" xlink:href=\"#LiberationSans-112\"/>\n     <use x=\"661.328125\" xlink:href=\"#LiberationSans-111\"/>\n     <use x=\"716.943359\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"766.943359\" xlink:href=\"#LiberationSans-104\"/>\n     <use x=\"822.558594\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"850.341797\" xlink:href=\"#LiberationSans-80\"/>\n     <use x=\"917.041016\" xlink:href=\"#LiberationSans-108\"/>\n     <use x=\"939.257812\" xlink:href=\"#LiberationSans-111\"/>\n     <use x=\"994.873047\" xlink:href=\"#LiberationSans-116\"/>\n     <use x=\"1022.65625\" xlink:href=\"#LiberationSans-44\"/>\n     <use x=\"1050.439453\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1078.222656\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"1128.222656\" xlink:href=\"#LiberationSans-97\"/>\n     <use x=\"1183.837891\" xlink:href=\"#LiberationSans-115\"/>\n     <use x=\"1233.837891\" xlink:href=\"#LiberationSans-101\"/>\n     <use x=\"1289.453125\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1317.236328\" xlink:href=\"#LiberationSans-61\"/>\n     <use x=\"1375.634766\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1403.417969\" xlink:href=\"#LiberationSans-50\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"line2d_33\">\n     <path d=\"M 413.786875 34.643125 \nL 433.786875 34.643125 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.75;\"/>\n    </g>\n    <g id=\"line2d_34\"/>\n    <g id=\"text_19\">\n     <!-- TrainLoss -->\n     <defs>\n      <path d=\"M 6.9375 0 \nL 6.9375 40.53125 \nQ 6.9375 42.1875 6.90625 43.921875 \nQ 6.890625 45.65625 6.828125 47.265625 \nQ 6.78125 48.875 6.734375 50.28125 \nQ 6.6875 51.703125 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 51.703125 15.0625 50.265625 \nQ 15.140625 48.828125 15.203125 47.3125 \nQ 15.28125 45.796875 15.296875 44.40625 \nQ 15.328125 43.015625 15.328125 42.046875 \nL 15.53125 42.046875 \nQ 16.453125 45.0625 17.5 47.28125 \nQ 18.5625 49.515625 19.96875 50.953125 \nQ 21.390625 52.390625 23.34375 53.09375 \nQ 25.296875 53.8125 28.078125 53.8125 \nQ 29.15625 53.8125 30.125 53.640625 \nQ 31.109375 53.46875 31.640625 53.328125 \nL 31.640625 45.265625 \nQ 30.765625 45.515625 29.59375 45.625 \nQ 28.421875 45.75 26.953125 45.75 \nQ 23.921875 45.75 21.796875 44.375 \nQ 19.671875 43.015625 18.328125 40.59375 \nQ 17 38.1875 16.359375 34.84375 \nQ 15.71875 31.5 15.71875 27.546875 \nL 15.71875 0 \nz\n\" id=\"LiberationSans-114\"/>\n      <path d=\"M 6.6875 64.0625 \nL 6.6875 72.46875 \nL 15.484375 72.46875 \nL 15.484375 64.0625 \nz\nM 6.6875 0 \nL 6.6875 52.828125 \nL 15.484375 52.828125 \nL 15.484375 0 \nz\n\" id=\"LiberationSans-105\"/>\n      <path d=\"M 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 37.359375 39.71875 39.9375 \nQ 39.15625 42.53125 37.890625 44.109375 \nQ 36.625 45.703125 34.546875 46.359375 \nQ 32.46875 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.921875 \nQ 21.234375 44.828125 19.453125 42.75 \nQ 17.671875 40.671875 16.6875 37.625 \nQ 15.71875 34.578125 15.71875 30.609375 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 41.546875 \nQ 6.9375 43.21875 6.90625 45.046875 \nQ 6.890625 46.875 6.828125 48.5 \nQ 6.78125 50.140625 6.734375 51.3125 \nQ 6.6875 52.484375 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.59375 15.03125 51.515625 \nQ 15.09375 50.4375 15.15625 49.046875 \nQ 15.234375 47.65625 15.28125 46.21875 \nQ 15.328125 44.78125 15.328125 43.796875 \nL 15.484375 43.796875 \nQ 16.75 46.09375 18.265625 47.953125 \nQ 19.78125 49.8125 21.78125 51.09375 \nQ 23.78125 52.390625 26.359375 53.09375 \nQ 28.953125 53.8125 32.375 53.8125 \nQ 36.765625 53.8125 39.9375 52.734375 \nQ 43.109375 51.65625 45.15625 49.40625 \nQ 47.21875 47.171875 48.171875 43.625 \nQ 49.125 40.09375 49.125 35.203125 \nL 49.125 0 \nz\n\" id=\"LiberationSans-110\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(441.786875 38.143125)scale(0.1 -0.1)\">\n      <use xlink:href=\"#LiberationSans-84\"/>\n      <use x=\"57.333984\" xlink:href=\"#LiberationSans-114\"/>\n      <use x=\"90.634766\" xlink:href=\"#LiberationSans-97\"/>\n      <use x=\"146.25\" xlink:href=\"#LiberationSans-105\"/>\n      <use x=\"168.466797\" xlink:href=\"#LiberationSans-110\"/>\n      <use x=\"224.082031\" xlink:href=\"#LiberationSans-76\"/>\n      <use x=\"279.697266\" xlink:href=\"#LiberationSans-111\"/>\n      <use x=\"335.3125\" xlink:href=\"#LiberationSans-115\"/>\n      <use x=\"385.3125\" xlink:href=\"#LiberationSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_35\">\n     <path d=\"M 413.786875 48.965 \nL 433.786875 48.965 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.75;\"/>\n    </g>\n    <g id=\"line2d_36\"/>\n    <g id=\"text_20\">\n     <!-- ValLoss -->\n     <defs>\n      <path d=\"M 38.1875 0 \nL 28.515625 0 \nL 0.4375 68.796875 \nL 10.25 68.796875 \nL 29.296875 20.359375 \nQ 30.03125 18.171875 30.765625 15.984375 \nQ 31.5 13.8125 32.078125 12.109375 \nQ 32.765625 10.109375 33.40625 8.203125 \nQ 33.984375 10.015625 34.671875 12.015625 \nQ 35.25 13.71875 35.953125 15.859375 \nQ 36.671875 18.015625 37.5 20.359375 \nL 56.453125 68.796875 \nL 66.265625 68.796875 \nz\n\" id=\"LiberationSans-86\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(441.786875 52.465)scale(0.1 -0.1)\">\n      <use xlink:href=\"#LiberationSans-86\"/>\n      <use x=\"59.324219\" xlink:href=\"#LiberationSans-97\"/>\n      <use x=\"114.939453\" xlink:href=\"#LiberationSans-108\"/>\n      <use x=\"137.15625\" xlink:href=\"#LiberationSans-76\"/>\n      <use x=\"192.771484\" xlink:href=\"#LiberationSans-111\"/>\n      <use x=\"248.386719\" xlink:href=\"#LiberationSans-115\"/>\n      <use x=\"298.386719\" xlink:href=\"#LiberationSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe50a750b6a\">\n   <rect height=\"298.98\" width=\"446.4\" x=\"47.915\" y=\"21.89625\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["<Figure size 576x396 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"358.652187pt\" version=\"1.1\" viewBox=\"0 0 501.515 358.652187\" width=\"501.515pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 358.652187 \nL 501.515 358.652187 \nL 501.515 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 47.915 320.87625 \nL 494.315 320.87625 \nL 494.315 21.89625 \nL 47.915 21.89625 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 68.205909 320.87625 \nL 68.205909 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 51.703125 34.421875 \nQ 51.703125 24.515625 49.828125 17.75 \nQ 47.953125 10.984375 44.703125 6.8125 \nQ 41.453125 2.640625 37.0625 0.828125 \nQ 32.671875 -0.984375 27.6875 -0.984375 \nQ 22.65625 -0.984375 18.3125 0.828125 \nQ 13.96875 2.640625 10.765625 6.78125 \nQ 7.5625 10.9375 5.734375 17.703125 \nQ 3.90625 24.46875 3.90625 34.421875 \nQ 3.90625 44.828125 5.734375 51.640625 \nQ 7.5625 58.453125 10.78125 62.5 \nQ 14.015625 66.546875 18.40625 68.1875 \nQ 22.796875 69.828125 27.984375 69.828125 \nQ 32.90625 69.828125 37.21875 68.1875 \nQ 41.546875 66.546875 44.765625 62.5 \nQ 48 58.453125 49.84375 51.640625 \nQ 51.703125 44.828125 51.703125 34.421875 \nz\nM 42.78125 34.421875 \nQ 42.78125 42.625 41.796875 48.0625 \nQ 40.828125 53.515625 38.921875 56.765625 \nQ 37.015625 60.015625 34.25 61.359375 \nQ 31.5 62.703125 27.984375 62.703125 \nQ 24.265625 62.703125 21.4375 61.328125 \nQ 18.609375 59.96875 16.671875 56.71875 \nQ 14.75 53.46875 13.765625 48.015625 \nQ 12.796875 42.578125 12.796875 34.421875 \nQ 12.796875 26.515625 13.796875 21.09375 \nQ 14.796875 15.671875 16.71875 12.375 \nQ 18.65625 9.078125 21.4375 7.640625 \nQ 24.21875 6.203125 27.78125 6.203125 \nQ 31.25 6.203125 34.03125 7.640625 \nQ 36.8125 9.078125 38.734375 12.375 \nQ 40.671875 15.671875 41.71875 21.09375 \nQ 42.78125 26.515625 42.78125 34.421875 \nz\n\" id=\"LiberationSans-48\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(65.42544 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 149.369545 320.87625 \nL 149.369545 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 5.03125 0 \nL 5.03125 6.203125 \nQ 7.515625 11.921875 11.109375 16.28125 \nQ 14.703125 20.65625 18.65625 24.1875 \nQ 22.609375 27.734375 26.484375 30.765625 \nQ 30.375 33.796875 33.5 36.8125 \nQ 36.625 39.84375 38.546875 43.15625 \nQ 40.484375 46.484375 40.484375 50.6875 \nQ 40.484375 53.609375 39.59375 55.828125 \nQ 38.71875 58.0625 37.0625 59.5625 \nQ 35.40625 61.078125 33.078125 61.828125 \nQ 30.765625 62.59375 27.9375 62.59375 \nQ 25.296875 62.59375 22.96875 61.859375 \nQ 20.65625 61.140625 18.84375 59.671875 \nQ 17.046875 58.203125 15.890625 56.03125 \nQ 14.75 53.859375 14.40625 50.984375 \nL 5.421875 51.8125 \nQ 5.859375 55.515625 7.46875 58.78125 \nQ 9.078125 62.0625 11.90625 64.53125 \nQ 14.75 67 18.71875 68.40625 \nQ 22.703125 69.828125 27.9375 69.828125 \nQ 33.0625 69.828125 37.0625 68.609375 \nQ 41.0625 67.390625 43.8125 64.984375 \nQ 46.578125 62.59375 48.046875 59.078125 \nQ 49.515625 55.5625 49.515625 50.984375 \nQ 49.515625 47.515625 48.265625 44.390625 \nQ 47.015625 41.265625 44.9375 38.421875 \nQ 42.875 35.59375 40.140625 32.953125 \nQ 37.40625 30.328125 34.421875 27.8125 \nQ 31.453125 25.296875 28.421875 22.828125 \nQ 25.390625 20.359375 22.71875 17.859375 \nQ 20.0625 15.375 17.96875 12.8125 \nQ 15.875 10.25 14.703125 7.46875 \nL 50.59375 7.46875 \nL 50.59375 0 \nz\n\" id=\"LiberationSans-50\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(146.589077 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 230.533182 320.87625 \nL 230.533182 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 43.015625 15.578125 \nL 43.015625 0 \nL 34.71875 0 \nL 34.71875 15.578125 \nL 2.296875 15.578125 \nL 2.296875 22.40625 \nL 33.796875 68.796875 \nL 43.015625 68.796875 \nL 43.015625 22.515625 \nL 52.6875 22.515625 \nL 52.6875 15.578125 \nz\nM 34.71875 58.890625 \nQ 34.625 58.640625 34.234375 57.9375 \nQ 33.84375 57.234375 33.34375 56.34375 \nQ 32.859375 55.46875 32.34375 54.5625 \nQ 31.84375 53.65625 31.453125 53.078125 \nL 13.8125 27.09375 \nQ 13.578125 26.703125 13.109375 26.0625 \nQ 12.640625 25.4375 12.15625 24.78125 \nQ 11.671875 24.125 11.171875 23.484375 \nQ 10.6875 22.859375 10.40625 22.515625 \nL 34.71875 22.515625 \nz\n\" id=\"LiberationSans-52\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(227.752713 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 311.696818 320.87625 \nL 311.696818 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 51.21875 22.515625 \nQ 51.21875 17.328125 49.78125 13 \nQ 48.34375 8.6875 45.53125 5.578125 \nQ 42.71875 2.484375 38.5625 0.75 \nQ 34.421875 -0.984375 29 -0.984375 \nQ 23 -0.984375 18.5 1.3125 \nQ 14.015625 3.609375 11.03125 7.921875 \nQ 8.0625 12.25 6.5625 18.53125 \nQ 5.078125 24.8125 5.078125 32.8125 \nQ 5.078125 42 6.765625 48.921875 \nQ 8.453125 55.859375 11.625 60.5 \nQ 14.796875 65.140625 19.359375 67.484375 \nQ 23.921875 69.828125 29.6875 69.828125 \nQ 33.203125 69.828125 36.28125 69.09375 \nQ 39.359375 68.359375 41.875 66.71875 \nQ 44.390625 65.09375 46.28125 62.40625 \nQ 48.1875 59.71875 49.3125 55.8125 \nL 40.921875 54.296875 \nQ 39.546875 58.734375 36.546875 60.71875 \nQ 33.546875 62.703125 29.59375 62.703125 \nQ 25.984375 62.703125 23.046875 60.984375 \nQ 20.125 59.28125 18.0625 55.875 \nQ 16.015625 52.484375 14.90625 47.359375 \nQ 13.8125 42.234375 13.8125 35.40625 \nQ 16.21875 39.84375 20.5625 42.15625 \nQ 24.90625 44.484375 30.515625 44.484375 \nQ 35.203125 44.484375 39.015625 42.96875 \nQ 42.828125 41.453125 45.53125 38.59375 \nQ 48.25 35.75 49.734375 31.671875 \nQ 51.21875 27.59375 51.21875 22.515625 \nz\nM 42.28125 22.125 \nQ 42.28125 25.6875 41.40625 28.5625 \nQ 40.53125 31.453125 38.765625 33.46875 \nQ 37.015625 35.5 34.421875 36.59375 \nQ 31.84375 37.703125 28.421875 37.703125 \nQ 26.03125 37.703125 23.578125 36.984375 \nQ 21.140625 36.28125 19.15625 34.6875 \nQ 17.1875 33.109375 15.9375 30.515625 \nQ 14.703125 27.9375 14.703125 24.21875 \nQ 14.703125 20.40625 15.671875 17.109375 \nQ 16.65625 13.8125 18.484375 11.375 \nQ 20.3125 8.9375 22.890625 7.515625 \nQ 25.484375 6.109375 28.71875 6.109375 \nQ 31.890625 6.109375 34.40625 7.203125 \nQ 36.921875 8.296875 38.671875 10.375 \nQ 40.4375 12.453125 41.359375 15.421875 \nQ 42.28125 18.40625 42.28125 22.125 \nz\n\" id=\"LiberationSans-54\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(308.916349 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 392.860455 320.87625 \nL 392.860455 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 51.265625 19.1875 \nQ 51.265625 14.796875 49.875 11.109375 \nQ 48.484375 7.421875 45.625 4.734375 \nQ 42.78125 2.046875 38.328125 0.53125 \nQ 33.890625 -0.984375 27.828125 -0.984375 \nQ 21.78125 -0.984375 17.359375 0.53125 \nQ 12.9375 2.046875 10.03125 4.703125 \nQ 7.125 7.375 5.734375 11.0625 \nQ 4.34375 14.75 4.34375 19.09375 \nQ 4.34375 22.859375 5.484375 25.78125 \nQ 6.640625 28.71875 8.5625 30.828125 \nQ 10.5 32.953125 12.96875 34.25 \nQ 15.4375 35.546875 18.0625 35.984375 \nL 18.0625 36.1875 \nQ 15.1875 36.859375 12.90625 38.375 \nQ 10.640625 39.890625 9.09375 42.015625 \nQ 7.5625 44.140625 6.75 46.71875 \nQ 5.953125 49.3125 5.953125 52.203125 \nQ 5.953125 55.8125 7.34375 59 \nQ 8.734375 62.203125 11.46875 64.625 \nQ 14.203125 67.046875 18.25 68.4375 \nQ 22.3125 69.828125 27.640625 69.828125 \nQ 33.25 69.828125 37.375 68.40625 \nQ 41.5 67 44.203125 64.578125 \nQ 46.921875 62.15625 48.234375 58.9375 \nQ 49.5625 55.71875 49.5625 52.09375 \nQ 49.5625 49.265625 48.75 46.671875 \nQ 47.953125 44.09375 46.40625 41.96875 \nQ 44.875 39.84375 42.59375 38.34375 \nQ 40.328125 36.859375 37.359375 36.28125 \nL 37.359375 36.078125 \nQ 40.328125 35.59375 42.859375 34.296875 \nQ 45.40625 33.015625 47.265625 30.890625 \nQ 49.125 28.765625 50.1875 25.828125 \nQ 51.265625 22.90625 51.265625 19.1875 \nz\nM 40.4375 51.609375 \nQ 40.4375 54.203125 39.765625 56.34375 \nQ 39.109375 58.5 37.59375 60.03125 \nQ 36.078125 61.578125 33.640625 62.421875 \nQ 31.203125 63.28125 27.640625 63.28125 \nQ 24.171875 63.28125 21.78125 62.421875 \nQ 19.390625 61.578125 17.84375 60.03125 \nQ 16.3125 58.5 15.625 56.34375 \nQ 14.9375 54.203125 14.9375 51.609375 \nQ 14.9375 49.5625 15.46875 47.40625 \nQ 16.015625 45.265625 17.421875 43.5 \nQ 18.84375 41.75 21.328125 40.625 \nQ 23.828125 39.5 27.734375 39.5 \nQ 31.890625 39.5 34.40625 40.625 \nQ 36.921875 41.75 38.25 43.5 \nQ 39.59375 45.265625 40.015625 47.40625 \nQ 40.4375 49.5625 40.4375 51.609375 \nz\nM 42.140625 20.015625 \nQ 42.140625 22.515625 41.453125 24.828125 \nQ 40.765625 27.15625 39.109375 28.9375 \nQ 37.453125 30.71875 34.640625 31.8125 \nQ 31.84375 32.90625 27.640625 32.90625 \nQ 23.78125 32.90625 21.0625 31.8125 \nQ 18.359375 30.71875 16.671875 28.90625 \nQ 14.984375 27.09375 14.203125 24.71875 \nQ 13.421875 22.359375 13.421875 19.828125 \nQ 13.421875 16.65625 14.203125 14.03125 \nQ 14.984375 11.421875 16.6875 9.546875 \nQ 18.40625 7.671875 21.1875 6.640625 \nQ 23.96875 5.609375 27.9375 5.609375 \nQ 31.9375 5.609375 34.671875 6.640625 \nQ 37.40625 7.671875 39.0625 9.546875 \nQ 40.71875 11.421875 41.421875 14.078125 \nQ 42.140625 16.75 42.140625 20.015625 \nz\n\" id=\"LiberationSans-56\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(390.079986 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 474.024091 320.87625 \nL 474.024091 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 7.625 0 \nL 7.625 7.46875 \nL 25.140625 7.46875 \nL 25.140625 60.40625 \nL 9.625 49.3125 \nL 9.625 57.625 \nL 25.875 68.796875 \nL 33.984375 68.796875 \nL 33.984375 7.46875 \nL 50.734375 7.46875 \nL 50.734375 0 \nz\n\" id=\"LiberationSans-49\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(468.463153 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-49\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 8.203125 0 \nL 8.203125 68.796875 \nL 60.40625 68.796875 \nL 60.40625 61.1875 \nL 17.53125 61.1875 \nL 17.53125 39.109375 \nL 57.46875 39.109375 \nL 57.46875 31.59375 \nL 17.53125 31.59375 \nL 17.53125 7.625 \nL 62.40625 7.625 \nL 62.40625 0 \nz\n\" id=\"LiberationSans-69\"/>\n      <path d=\"M 51.421875 26.65625 \nQ 51.421875 20.65625 50.4375 15.578125 \nQ 49.46875 10.5 47.1875 6.828125 \nQ 44.921875 3.171875 41.1875 1.09375 \nQ 37.453125 -0.984375 31.984375 -0.984375 \nQ 26.3125 -0.984375 22.0625 1.171875 \nQ 17.828125 3.328125 15.578125 8.203125 \nL 15.328125 8.203125 \nQ 15.375 8.109375 15.40625 7.328125 \nQ 15.4375 6.546875 15.453125 5.375 \nQ 15.484375 4.203125 15.5 2.75 \nQ 15.53125 1.3125 15.53125 -0.09375 \nL 15.53125 -20.75 \nL 6.734375 -20.75 \nL 6.734375 42.046875 \nQ 6.734375 43.953125 6.703125 45.703125 \nQ 6.6875 47.46875 6.640625 48.90625 \nQ 6.59375 50.34375 6.546875 51.359375 \nQ 6.5 52.390625 6.453125 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.6875 15.0625 51.796875 \nQ 15.140625 50.921875 15.203125 49.671875 \nQ 15.28125 48.4375 15.359375 47.015625 \nQ 15.4375 45.609375 15.4375 44.34375 \nL 15.625 44.34375 \nQ 16.84375 46.875 18.40625 48.65625 \nQ 19.96875 50.4375 21.96875 51.578125 \nQ 23.96875 52.734375 26.4375 53.25 \nQ 28.90625 53.765625 31.984375 53.765625 \nQ 37.453125 53.765625 41.1875 51.8125 \nQ 44.921875 49.859375 47.1875 46.3125 \nQ 49.46875 42.78125 50.4375 37.765625 \nQ 51.421875 32.765625 51.421875 26.65625 \nz\nM 42.1875 26.46875 \nQ 42.1875 31.34375 41.59375 35.15625 \nQ 41.015625 38.96875 39.578125 41.59375 \nQ 38.140625 44.234375 35.734375 45.59375 \nQ 33.34375 46.96875 29.734375 46.96875 \nQ 26.8125 46.96875 24.21875 46.140625 \nQ 21.625 45.3125 19.703125 42.96875 \nQ 17.78125 40.625 16.65625 36.5 \nQ 15.53125 32.375 15.53125 25.78125 \nQ 15.53125 20.171875 16.453125 16.28125 \nQ 17.390625 12.40625 19.171875 10.015625 \nQ 20.953125 7.625 23.578125 6.5625 \nQ 26.21875 5.515625 29.640625 5.515625 \nQ 33.296875 5.515625 35.71875 6.921875 \nQ 38.140625 8.34375 39.578125 11.03125 \nQ 41.015625 13.71875 41.59375 17.59375 \nQ 42.1875 21.484375 42.1875 26.46875 \nz\n\" id=\"LiberationSans-112\"/>\n      <path d=\"M 51.421875 26.46875 \nQ 51.421875 12.59375 45.3125 5.796875 \nQ 39.203125 -0.984375 27.59375 -0.984375 \nQ 22.078125 -0.984375 17.71875 0.671875 \nQ 13.375 2.34375 10.375 5.765625 \nQ 7.375 9.1875 5.78125 14.328125 \nQ 4.203125 19.484375 4.203125 26.46875 \nQ 4.203125 53.8125 27.875 53.8125 \nQ 34.03125 53.8125 38.5 52.09375 \nQ 42.96875 50.390625 45.828125 46.96875 \nQ 48.6875 43.5625 50.046875 38.421875 \nQ 51.421875 33.296875 51.421875 26.46875 \nz\nM 42.1875 26.46875 \nQ 42.1875 32.625 41.234375 36.625 \nQ 40.28125 40.625 38.453125 43.015625 \nQ 36.625 45.40625 33.984375 46.359375 \nQ 31.34375 47.3125 28.03125 47.3125 \nQ 24.65625 47.3125 21.9375 46.3125 \nQ 19.234375 45.3125 17.328125 42.890625 \nQ 15.4375 40.484375 14.421875 36.46875 \nQ 13.421875 32.46875 13.421875 26.46875 \nQ 13.421875 20.3125 14.5 16.28125 \nQ 15.578125 12.25 17.453125 9.859375 \nQ 19.34375 7.46875 21.90625 6.484375 \nQ 24.46875 5.515625 27.484375 5.515625 \nQ 30.859375 5.515625 33.59375 6.46875 \nQ 36.328125 7.421875 38.234375 9.8125 \nQ 40.140625 12.203125 41.15625 16.25 \nQ 42.1875 20.3125 42.1875 26.46875 \nz\n\" id=\"LiberationSans-111\"/>\n      <path d=\"M 13.421875 26.65625 \nQ 13.421875 22.125 14.078125 18.3125 \nQ 14.75 14.5 16.3125 11.734375 \nQ 17.875 8.984375 20.4375 7.46875 \nQ 23 5.953125 26.765625 5.953125 \nQ 31.453125 5.953125 34.59375 8.484375 \nQ 37.75 11.03125 38.484375 16.3125 \nL 47.359375 15.71875 \nQ 46.921875 12.453125 45.453125 9.421875 \nQ 44 6.390625 41.484375 4.09375 \nQ 38.96875 1.8125 35.34375 0.40625 \nQ 31.734375 -0.984375 27 -0.984375 \nQ 20.796875 -0.984375 16.453125 1.109375 \nQ 12.109375 3.21875 9.390625 6.90625 \nQ 6.6875 10.59375 5.46875 15.59375 \nQ 4.25 20.609375 4.25 26.46875 \nQ 4.25 31.78125 5.125 35.859375 \nQ 6 39.9375 7.59375 42.984375 \nQ 9.1875 46.046875 11.328125 48.125 \nQ 13.484375 50.203125 15.984375 51.4375 \nQ 18.5 52.6875 21.28125 53.25 \nQ 24.078125 53.8125 26.90625 53.8125 \nQ 31.34375 53.8125 34.8125 52.59375 \nQ 38.28125 51.375 40.796875 49.25 \nQ 43.3125 47.125 44.875 44.234375 \nQ 46.4375 41.359375 47.078125 38.03125 \nL 38.03125 37.359375 \nQ 37.359375 41.75 34.5625 44.328125 \nQ 31.78125 46.921875 26.65625 46.921875 \nQ 22.90625 46.921875 20.390625 45.671875 \nQ 17.875 44.4375 16.3125 41.921875 \nQ 14.75 39.40625 14.078125 35.59375 \nQ 13.421875 31.78125 13.421875 26.65625 \nz\n\" id=\"LiberationSans-99\"/>\n      <path d=\"M 15.484375 43.796875 \nQ 16.9375 46.484375 18.640625 48.359375 \nQ 20.359375 50.25 22.40625 51.46875 \nQ 24.46875 52.6875 26.90625 53.25 \nQ 29.34375 53.8125 32.375 53.8125 \nQ 37.453125 53.8125 40.703125 52.4375 \nQ 43.953125 51.078125 45.828125 48.609375 \nQ 47.703125 46.140625 48.40625 42.71875 \nQ 49.125 39.3125 49.125 35.203125 \nL 49.125 0 \nL 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 36.859375 39.859375 39.390625 \nQ 39.453125 41.9375 38.28125 43.625 \nQ 37.109375 45.3125 34.953125 46.15625 \nQ 32.8125 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.890625 \nQ 21.234375 44.78125 19.453125 42.71875 \nQ 17.671875 40.671875 16.6875 37.734375 \nQ 15.71875 34.8125 15.71875 31.15625 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 72.46875 \nL 15.71875 72.46875 \nL 15.71875 53.609375 \nQ 15.71875 52 15.671875 50.390625 \nQ 15.625 48.78125 15.546875 47.40625 \nQ 15.484375 46.046875 15.421875 45.09375 \nQ 15.375 44.140625 15.328125 43.796875 \nz\n\" id=\"LiberationSans-104\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(255.520781 349.169687)scale(0.11 -0.11)\">\n      <use xlink:href=\"#LiberationSans-69\"/>\n      <use x=\"66.699219\" xlink:href=\"#LiberationSans-112\"/>\n      <use x=\"122.314453\" xlink:href=\"#LiberationSans-111\"/>\n      <use x=\"177.929688\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"227.929688\" xlink:href=\"#LiberationSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 47.915 307.058612 \nL 494.315 307.058612 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_8\">\n      <!-- 0.75 -->\n      <defs>\n       <path d=\"M 9.125 0 \nL 9.125 10.6875 \nL 18.65625 10.6875 \nL 18.65625 0 \nz\n\" id=\"LiberationSans-46\"/>\n       <path d=\"M 50.59375 61.671875 \nQ 45.40625 53.765625 41.0625 46.453125 \nQ 36.71875 39.15625 33.59375 31.75 \nQ 30.46875 24.359375 28.734375 16.578125 \nQ 27 8.796875 27 0 \nL 17.828125 0 \nQ 17.828125 8.25 19.78125 16.1875 \nQ 21.734375 24.125 25.046875 31.765625 \nQ 28.375 39.40625 32.765625 46.78125 \nQ 37.15625 54.15625 42.09375 61.328125 \nL 5.125 61.328125 \nL 5.125 68.796875 \nL 50.59375 68.796875 \nz\n\" id=\"LiberationSans-55\"/>\n       <path d=\"M 51.421875 22.40625 \nQ 51.421875 17.234375 49.859375 12.9375 \nQ 48.296875 8.640625 45.21875 5.53125 \nQ 42.140625 2.4375 37.578125 0.71875 \nQ 33.015625 -0.984375 27 -0.984375 \nQ 21.578125 -0.984375 17.546875 0.28125 \nQ 13.53125 1.5625 10.734375 3.78125 \nQ 7.953125 6 6.3125 8.984375 \nQ 4.6875 11.96875 4 15.375 \nL 12.890625 16.40625 \nQ 13.421875 14.453125 14.390625 12.625 \nQ 15.375 10.796875 17.0625 9.34375 \nQ 18.75 7.90625 21.21875 7.046875 \nQ 23.6875 6.203125 27.203125 6.203125 \nQ 30.609375 6.203125 33.390625 7.25 \nQ 36.1875 8.296875 38.15625 10.34375 \nQ 40.140625 12.40625 41.203125 15.375 \nQ 42.28125 18.359375 42.28125 22.21875 \nQ 42.28125 25.390625 41.25 28.046875 \nQ 40.234375 30.71875 38.328125 32.640625 \nQ 36.421875 34.578125 33.65625 35.640625 \nQ 30.90625 36.71875 27.390625 36.71875 \nQ 25.203125 36.71875 23.34375 36.328125 \nQ 21.484375 35.9375 19.890625 35.25 \nQ 18.3125 34.578125 17.015625 33.671875 \nQ 15.71875 32.765625 14.59375 31.78125 \nL 6 31.78125 \nL 8.296875 68.796875 \nL 47.40625 68.796875 \nL 47.40625 61.328125 \nL 16.3125 61.328125 \nL 14.984375 39.5 \nQ 17.328125 41.3125 20.84375 42.59375 \nQ 24.359375 43.890625 29.203125 43.890625 \nQ 34.328125 43.890625 38.421875 42.328125 \nQ 42.53125 40.765625 45.40625 37.90625 \nQ 48.296875 35.0625 49.859375 31.109375 \nQ 51.421875 27.15625 51.421875 22.40625 \nz\n\" id=\"LiberationSans-53\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(21.454063 310.682049)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-55\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 47.915 243.319918 \nL 494.315 243.319918 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_9\">\n      <!-- 0.80 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454063 246.943356)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-56\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 47.915 179.581225 \nL 494.315 179.581225 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_10\">\n      <!-- 0.85 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454063 183.204662)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-56\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 47.915 115.842531 \nL 494.315 115.842531 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_11\">\n      <!-- 0.90 -->\n      <defs>\n       <path d=\"M 50.875 35.796875 \nQ 50.875 26.609375 49.140625 19.703125 \nQ 47.40625 12.796875 44.1875 8.203125 \nQ 40.96875 3.609375 36.34375 1.3125 \nQ 31.734375 -0.984375 25.984375 -0.984375 \nQ 22.015625 -0.984375 18.84375 -0.171875 \nQ 15.671875 0.640625 13.171875 2.34375 \nQ 10.6875 4.046875 8.921875 6.78125 \nQ 7.171875 9.515625 6.109375 13.375 \nL 14.5 14.703125 \nQ 15.875 10.25 18.78125 8.171875 \nQ 21.6875 6.109375 26.125 6.109375 \nQ 29.6875 6.109375 32.640625 7.78125 \nQ 35.59375 9.46875 37.671875 12.84375 \nQ 39.75 16.21875 40.921875 21.296875 \nQ 42.09375 26.375 42.1875 33.203125 \nQ 41.15625 30.90625 39.375 29.09375 \nQ 37.59375 27.296875 35.328125 26.046875 \nQ 33.0625 24.8125 30.421875 24.140625 \nQ 27.78125 23.484375 25.09375 23.484375 \nQ 20.40625 23.484375 16.625 25.171875 \nQ 12.84375 26.859375 10.203125 29.875 \nQ 7.5625 32.90625 6.125 37.171875 \nQ 4.6875 41.453125 4.6875 46.6875 \nQ 4.6875 52 6.21875 56.296875 \nQ 7.765625 60.59375 10.6875 63.59375 \nQ 13.625 66.609375 17.890625 68.21875 \nQ 22.171875 69.828125 27.59375 69.828125 \nQ 39.0625 69.828125 44.96875 61.328125 \nQ 50.875 52.828125 50.875 35.796875 \nz\nM 41.3125 44.28125 \nQ 41.3125 48.09375 40.40625 51.453125 \nQ 39.5 54.828125 37.71875 57.3125 \nQ 35.9375 59.8125 33.328125 61.25 \nQ 30.71875 62.703125 27.296875 62.703125 \nQ 24.125 62.703125 21.578125 61.578125 \nQ 19.046875 60.453125 17.28125 58.375 \nQ 15.53125 56.296875 14.578125 53.3125 \nQ 13.625 50.34375 13.625 46.6875 \nQ 13.625 43.21875 14.46875 40.234375 \nQ 15.328125 37.25 17.03125 35.078125 \nQ 18.75 32.90625 21.28125 31.65625 \nQ 23.828125 30.421875 27.203125 30.421875 \nQ 29.640625 30.421875 32.15625 31.25 \nQ 34.671875 32.078125 36.6875 33.78125 \nQ 38.71875 35.5 40.015625 38.109375 \nQ 41.3125 40.71875 41.3125 44.28125 \nz\n\" id=\"LiberationSans-57\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(21.454063 119.465969)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-57\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p0484a9ba28)\" d=\"M 47.915 52.103838 \nL 494.315 52.103838 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_22\"/>\n     <g id=\"text_12\">\n      <!-- 0.95 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454063 55.727275)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-57\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- Accuracy -->\n     <defs>\n      <path d=\"M 56.984375 0 \nL 49.125 20.125 \nL 17.78125 20.125 \nL 9.859375 0 \nL 0.203125 0 \nL 28.265625 68.796875 \nL 38.875 68.796875 \nL 66.5 0 \nz\nM 37.5 50.09375 \nQ 36.71875 52.046875 36 54.046875 \nQ 35.296875 56.0625 34.765625 57.6875 \nQ 34.234375 59.328125 33.859375 60.421875 \nQ 33.5 61.53125 33.453125 61.765625 \nQ 33.34375 61.53125 33 60.40625 \nQ 32.671875 59.28125 32.109375 57.609375 \nQ 31.546875 55.953125 30.828125 53.953125 \nQ 30.125 51.953125 29.390625 50 \nL 20.609375 27.390625 \nL 46.34375 27.390625 \nz\n\" id=\"LiberationSans-65\"/>\n      <path d=\"M 15.328125 52.828125 \nL 15.328125 19.34375 \nQ 15.328125 15.484375 15.890625 12.890625 \nQ 16.453125 10.296875 17.71875 8.703125 \nQ 19 7.125 21.0625 6.46875 \nQ 23.140625 5.8125 26.21875 5.8125 \nQ 29.34375 5.8125 31.859375 6.90625 \nQ 34.375 8.015625 36.15625 10.078125 \nQ 37.9375 12.15625 38.90625 15.203125 \nQ 39.890625 18.265625 39.890625 22.21875 \nL 39.890625 52.828125 \nL 48.6875 52.828125 \nL 48.6875 11.28125 \nQ 48.6875 9.625 48.703125 7.78125 \nQ 48.734375 5.953125 48.78125 4.3125 \nQ 48.828125 2.6875 48.875 1.515625 \nQ 48.921875 0.34375 48.96875 0 \nL 40.671875 0 \nQ 40.625 0.25 40.578125 1.3125 \nQ 40.53125 2.390625 40.453125 3.78125 \nQ 40.375 5.171875 40.328125 6.609375 \nQ 40.28125 8.0625 40.28125 9.03125 \nL 40.140625 9.03125 \nQ 38.875 6.734375 37.359375 4.875 \nQ 35.84375 3.03125 33.84375 1.734375 \nQ 31.84375 0.4375 29.25 -0.265625 \nQ 26.65625 -0.984375 23.25 -0.984375 \nQ 18.84375 -0.984375 15.671875 0.09375 \nQ 12.5 1.171875 10.453125 3.421875 \nQ 8.40625 5.671875 7.453125 9.1875 \nQ 6.5 12.703125 6.5 17.625 \nL 6.5 52.828125 \nz\n\" id=\"LiberationSans-117\"/>\n      <path d=\"M 6.9375 0 \nL 6.9375 40.53125 \nQ 6.9375 42.1875 6.90625 43.921875 \nQ 6.890625 45.65625 6.828125 47.265625 \nQ 6.78125 48.875 6.734375 50.28125 \nQ 6.6875 51.703125 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 51.703125 15.0625 50.265625 \nQ 15.140625 48.828125 15.203125 47.3125 \nQ 15.28125 45.796875 15.296875 44.40625 \nQ 15.328125 43.015625 15.328125 42.046875 \nL 15.53125 42.046875 \nQ 16.453125 45.0625 17.5 47.28125 \nQ 18.5625 49.515625 19.96875 50.953125 \nQ 21.390625 52.390625 23.34375 53.09375 \nQ 25.296875 53.8125 28.078125 53.8125 \nQ 29.15625 53.8125 30.125 53.640625 \nQ 31.109375 53.46875 31.640625 53.328125 \nL 31.640625 45.265625 \nQ 30.765625 45.515625 29.59375 45.625 \nQ 28.421875 45.75 26.953125 45.75 \nQ 23.921875 45.75 21.796875 44.375 \nQ 19.671875 43.015625 18.328125 40.59375 \nQ 17 38.1875 16.359375 34.84375 \nQ 15.71875 31.5 15.71875 27.546875 \nL 15.71875 0 \nz\n\" id=\"LiberationSans-114\"/>\n      <path d=\"M 20.21875 -0.984375 \nQ 12.25 -0.984375 8.25 3.21875 \nQ 4.25 7.421875 4.25 14.75 \nQ 4.25 19.96875 6.21875 23.3125 \nQ 8.203125 26.65625 11.390625 28.5625 \nQ 14.59375 30.46875 18.6875 31.203125 \nQ 22.796875 31.9375 27.046875 32.03125 \nL 38.921875 32.234375 \nL 38.921875 35.109375 \nQ 38.921875 38.375 38.234375 40.671875 \nQ 37.546875 42.96875 36.125 44.375 \nQ 34.71875 45.796875 32.59375 46.453125 \nQ 30.46875 47.125 27.59375 47.125 \nQ 25.046875 47.125 23 46.75 \nQ 20.953125 46.390625 19.4375 45.4375 \nQ 17.921875 44.484375 16.984375 42.84375 \nQ 16.0625 41.21875 15.765625 38.71875 \nL 6.59375 39.546875 \nQ 7.078125 42.671875 8.4375 45.28125 \nQ 9.8125 47.90625 12.328125 49.796875 \nQ 14.84375 51.703125 18.625 52.75 \nQ 22.40625 53.8125 27.78125 53.8125 \nQ 37.75 53.8125 42.765625 49.234375 \nQ 47.796875 44.671875 47.796875 36.03125 \nL 47.796875 13.28125 \nQ 47.796875 9.375 48.828125 7.390625 \nQ 49.859375 5.421875 52.734375 5.421875 \nQ 53.46875 5.421875 54.203125 5.515625 \nQ 54.9375 5.609375 55.609375 5.765625 \nL 55.609375 0.296875 \nQ 53.953125 -0.09375 52.3125 -0.28125 \nQ 50.6875 -0.484375 48.828125 -0.484375 \nQ 46.34375 -0.484375 44.5625 0.171875 \nQ 42.78125 0.828125 41.65625 2.171875 \nQ 40.53125 3.515625 39.9375 5.484375 \nQ 39.359375 7.46875 39.203125 10.109375 \nL 38.921875 10.109375 \nQ 37.5 7.5625 35.8125 5.515625 \nQ 34.125 3.46875 31.875 2.03125 \nQ 29.640625 0.59375 26.78125 -0.1875 \nQ 23.921875 -0.984375 20.21875 -0.984375 \nz\nM 22.21875 5.609375 \nQ 26.421875 5.609375 29.5625 7.140625 \nQ 32.71875 8.6875 34.78125 11.078125 \nQ 36.859375 13.484375 37.890625 16.3125 \nQ 38.921875 19.140625 38.921875 21.734375 \nL 38.921875 26.078125 \nL 29.296875 25.875 \nQ 26.078125 25.828125 23.171875 25.40625 \nQ 20.265625 25 18.0625 23.78125 \nQ 15.875 22.5625 14.578125 20.359375 \nQ 13.28125 18.171875 13.28125 14.59375 \nQ 13.28125 10.296875 15.59375 7.953125 \nQ 17.921875 5.609375 22.21875 5.609375 \nz\n\" id=\"LiberationSans-97\"/>\n      <path d=\"M 29.5 0 \nQ 27.640625 -4.78125 25.703125 -8.609375 \nQ 23.78125 -12.453125 21.390625 -15.15625 \nQ 19 -17.875 16.0625 -19.3125 \nQ 13.140625 -20.75 9.328125 -20.75 \nQ 7.671875 -20.75 6.25 -20.65625 \nQ 4.828125 -20.5625 3.265625 -20.21875 \nL 3.265625 -13.625 \nQ 4.203125 -13.765625 5.375 -13.84375 \nQ 6.546875 -13.921875 7.375 -13.921875 \nQ 11.234375 -13.921875 14.546875 -11.03125 \nQ 17.875 -8.15625 20.359375 -1.859375 \nL 21.1875 0.25 \nL 0.25 52.828125 \nL 9.625 52.828125 \nL 20.75 23.640625 \nQ 21.234375 22.3125 21.984375 20.109375 \nQ 22.75 17.921875 23.5 15.71875 \nQ 24.265625 13.53125 24.84375 11.765625 \nQ 25.4375 10.015625 25.53125 9.578125 \nQ 25.6875 10.109375 26.25 11.6875 \nQ 26.8125 13.28125 27.515625 15.234375 \nQ 28.21875 17.1875 28.953125 19.1875 \nQ 29.6875 21.1875 30.171875 22.65625 \nL 40.53125 52.828125 \nL 49.8125 52.828125 \nz\n\" id=\"LiberationSans-121\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(15.171563 194.003281)rotate(-90)scale(0.11 -0.11)\">\n      <use xlink:href=\"#LiberationSans-65\"/>\n      <use x=\"66.699219\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"116.699219\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"166.699219\" xlink:href=\"#LiberationSans-117\"/>\n      <use x=\"222.314453\" xlink:href=\"#LiberationSans-114\"/>\n      <use x=\"255.615234\" xlink:href=\"#LiberationSans-97\"/>\n      <use x=\"311.230469\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"361.230469\" xlink:href=\"#LiberationSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#p0484a9ba28)\" d=\"M 68.205909 307.28625 \nL 108.787727 204.166149 \nL 149.369545 165.922933 \nL 189.951364 143.842029 \nL 230.533182 118.346552 \nL 271.115 95.355094 \nL 311.696818 78.28223 \nL 352.278636 59.615898 \nL 392.860455 87.843034 \nL 433.442273 57.794793 \nL 474.024091 35.48625 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.75;\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path clip-path=\"url(#p0484a9ba28)\" d=\"M 68.205909 227.840521 \nL 108.787727 196.881727 \nL 149.369545 193.239516 \nL 189.951364 189.597305 \nL 230.533182 185.955094 \nL 271.115 162.280722 \nL 311.696818 155.906853 \nL 352.278636 178.670672 \nL 392.860455 175.939014 \nL 433.442273 183.223436 \nL 474.024091 172.296803 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.75;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 47.915 320.87625 \nL 47.915 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 494.315 320.87625 \nL 494.315 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 47.915 320.87625 \nL 494.315 320.87625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 47.915 21.89625 \nL 494.315 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"text_14\">\n    <!-- LSTM Accuracy-Epoch plot, case = 2 ,Avg Val Acc = 0.86, Avg Train Acc = 0.97 -->\n    <defs>\n     <path d=\"M 8.203125 0 \nL 8.203125 68.796875 \nL 17.53125 68.796875 \nL 17.53125 7.625 \nL 52.296875 7.625 \nL 52.296875 0 \nz\n\" id=\"LiberationSans-76\"/>\n     <path d=\"M 62.109375 19 \nQ 62.109375 14.65625 60.421875 10.984375 \nQ 58.734375 7.328125 55.21875 4.65625 \nQ 51.703125 2 46.359375 0.5 \nQ 41.015625 -0.984375 33.6875 -0.984375 \nQ 20.84375 -0.984375 13.671875 3.515625 \nQ 6.5 8.015625 4.546875 16.5 \nL 13.578125 18.3125 \nQ 14.265625 15.625 15.671875 13.421875 \nQ 17.09375 11.234375 19.5 9.640625 \nQ 21.921875 8.0625 25.484375 7.171875 \nQ 29.046875 6.296875 34.03125 6.296875 \nQ 38.1875 6.296875 41.65625 7 \nQ 45.125 7.71875 47.609375 9.171875 \nQ 50.09375 10.640625 51.484375 12.953125 \nQ 52.875 15.28125 52.875 18.5 \nQ 52.875 21.875 51.34375 23.96875 \nQ 49.8125 26.078125 47.015625 27.4375 \nQ 44.234375 28.8125 40.375 29.734375 \nQ 36.53125 30.671875 31.84375 31.734375 \nQ 28.953125 32.375 26.046875 33.125 \nQ 23.140625 33.890625 20.484375 34.9375 \nQ 17.828125 35.984375 15.484375 37.390625 \nQ 13.140625 38.8125 11.421875 40.796875 \nQ 9.71875 42.78125 8.734375 45.390625 \nQ 7.765625 48 7.765625 51.421875 \nQ 7.765625 56.296875 9.734375 59.78125 \nQ 11.71875 63.28125 15.234375 65.53125 \nQ 18.75 67.78125 23.53125 68.796875 \nQ 28.328125 69.828125 33.890625 69.828125 \nQ 40.28125 69.828125 44.8125 68.828125 \nQ 49.359375 67.828125 52.484375 65.8125 \nQ 55.609375 63.8125 57.484375 60.859375 \nQ 59.375 57.90625 60.5 54 \nL 51.3125 52.390625 \nQ 50.640625 54.890625 49.34375 56.84375 \nQ 48.046875 58.796875 45.9375 60.109375 \nQ 43.84375 61.421875 40.84375 62.109375 \nQ 37.84375 62.796875 33.796875 62.796875 \nQ 29 62.796875 25.75 61.9375 \nQ 22.515625 61.078125 20.53125 59.609375 \nQ 18.5625 58.15625 17.703125 56.171875 \nQ 16.84375 54.203125 16.84375 51.90625 \nQ 16.84375 48.828125 18.375 46.84375 \nQ 19.921875 44.875 22.5625 43.546875 \nQ 25.203125 42.234375 28.65625 41.359375 \nQ 32.125 40.484375 36.03125 39.59375 \nQ 39.203125 38.875 42.359375 38.109375 \nQ 45.515625 37.359375 48.390625 36.296875 \nQ 51.265625 35.25 53.78125 33.828125 \nQ 56.296875 32.421875 58.15625 30.375 \nQ 60.015625 28.328125 61.0625 25.53125 \nQ 62.109375 22.75 62.109375 19 \nz\n\" id=\"LiberationSans-83\"/>\n     <path d=\"M 35.15625 61.1875 \nL 35.15625 0 \nL 25.875 0 \nL 25.875 61.1875 \nL 2.25 61.1875 \nL 2.25 68.796875 \nL 58.796875 68.796875 \nL 58.796875 61.1875 \nz\n\" id=\"LiberationSans-84\"/>\n     <path d=\"M 66.703125 0 \nL 66.703125 45.90625 \nQ 66.703125 48.390625 66.75 50.96875 \nQ 66.796875 53.5625 66.890625 55.71875 \nQ 67 58.203125 67.140625 60.546875 \nQ 66.453125 58.0625 65.71875 55.609375 \nQ 65.09375 53.515625 64.328125 51.140625 \nQ 63.578125 48.78125 62.84375 46.875 \nL 45.0625 0 \nL 38.53125 0 \nL 20.515625 46.875 \nQ 20.21875 47.609375 19.890625 48.578125 \nQ 19.578125 49.5625 19.203125 50.65625 \nQ 18.84375 51.765625 18.46875 52.90625 \nQ 18.109375 54.046875 17.78125 55.171875 \nQ 16.9375 57.765625 16.15625 60.546875 \nQ 16.21875 57.8125 16.3125 55.125 \nQ 16.40625 52.828125 16.453125 50.3125 \nQ 16.5 47.796875 16.5 45.90625 \nL 16.5 0 \nL 8.203125 0 \nL 8.203125 68.796875 \nL 20.453125 68.796875 \nL 38.765625 21.09375 \nQ 39.109375 20.125 39.59375 18.578125 \nQ 40.09375 17.046875 40.53125 15.421875 \nQ 40.96875 13.8125 41.328125 12.375 \nQ 41.703125 10.9375 41.84375 10.15625 \nQ 42 10.9375 42.390625 12.40625 \nQ 42.78125 13.875 43.28125 15.484375 \nQ 43.796875 17.09375 44.28125 18.609375 \nQ 44.78125 20.125 45.171875 21.09375 \nL 63.140625 68.796875 \nL 75.09375 68.796875 \nL 75.09375 0 \nz\n\" id=\"LiberationSans-77\"/>\n     <path id=\"LiberationSans-32\"/>\n     <path d=\"M 4.4375 22.65625 \nL 4.4375 30.46875 \nL 28.859375 30.46875 \nL 28.859375 22.65625 \nz\n\" id=\"LiberationSans-45\"/>\n     <path d=\"M 6.734375 0 \nL 6.734375 72.46875 \nL 15.53125 72.46875 \nL 15.53125 0 \nz\n\" id=\"LiberationSans-108\"/>\n     <path d=\"M 27.046875 0.390625 \nQ 25.046875 -0.140625 22.96875 -0.453125 \nQ 20.90625 -0.78125 18.171875 -0.78125 \nQ 7.625 -0.78125 7.625 11.1875 \nL 7.625 46.4375 \nL 1.515625 46.4375 \nL 1.515625 52.828125 \nL 7.953125 52.828125 \nL 10.546875 64.65625 \nL 16.40625 64.65625 \nL 16.40625 52.828125 \nL 26.171875 52.828125 \nL 26.171875 46.4375 \nL 16.40625 46.4375 \nL 16.40625 13.09375 \nQ 16.40625 9.28125 17.640625 7.734375 \nQ 18.890625 6.203125 21.96875 6.203125 \nQ 23.25 6.203125 24.4375 6.390625 \nQ 25.640625 6.59375 27.046875 6.890625 \nz\n\" id=\"LiberationSans-116\"/>\n     <path d=\"M 18.796875 10.6875 \nL 18.796875 2.484375 \nQ 18.796875 -0.09375 18.578125 -2.21875 \nQ 18.359375 -4.34375 17.875 -6.171875 \nQ 17.390625 -8.015625 16.671875 -9.625 \nQ 15.96875 -11.234375 14.984375 -12.796875 \nL 8.984375 -12.796875 \nQ 11.1875 -9.625 12.375 -6.390625 \nQ 13.578125 -3.171875 13.578125 0 \nL 9.28125 0 \nL 9.28125 10.6875 \nz\n\" id=\"LiberationSans-44\"/>\n     <path d=\"M 46.390625 14.59375 \nQ 46.390625 10.890625 44.9375 7.984375 \nQ 43.5 5.078125 40.765625 3.09375 \nQ 38.03125 1.125 34.046875 0.0625 \nQ 30.078125 -0.984375 24.953125 -0.984375 \nQ 20.359375 -0.984375 16.671875 -0.265625 \nQ 12.984375 0.4375 10.203125 2 \nQ 7.421875 3.5625 5.53125 6.125 \nQ 3.65625 8.6875 2.78125 12.40625 \nL 10.546875 13.921875 \nQ 11.671875 9.671875 15.1875 7.6875 \nQ 18.703125 5.71875 24.953125 5.71875 \nQ 27.78125 5.71875 30.140625 6.109375 \nQ 32.515625 6.5 34.21875 7.453125 \nQ 35.9375 8.40625 36.890625 9.984375 \nQ 37.84375 11.578125 37.84375 13.921875 \nQ 37.84375 16.3125 36.71875 17.84375 \nQ 35.59375 19.390625 33.59375 20.40625 \nQ 31.59375 21.4375 28.734375 22.1875 \nQ 25.875 22.953125 22.46875 23.875 \nQ 19.28125 24.703125 16.15625 25.734375 \nQ 13.03125 26.765625 10.515625 28.4375 \nQ 8.015625 30.125 6.453125 32.609375 \nQ 4.890625 35.109375 4.890625 38.875 \nQ 4.890625 46.09375 10.03125 49.875 \nQ 15.1875 53.65625 25.046875 53.65625 \nQ 33.796875 53.65625 38.9375 50.578125 \nQ 44.09375 47.515625 45.453125 40.71875 \nL 37.546875 39.75 \nQ 37.109375 41.796875 35.9375 43.1875 \nQ 34.765625 44.578125 33.109375 45.4375 \nQ 31.453125 46.296875 29.375 46.65625 \nQ 27.296875 47.015625 25.046875 47.015625 \nQ 19.09375 47.015625 16.25 45.203125 \nQ 13.421875 43.40625 13.421875 39.75 \nQ 13.421875 37.59375 14.46875 36.203125 \nQ 15.53125 34.8125 17.40625 33.859375 \nQ 19.28125 32.90625 21.921875 32.203125 \nQ 24.5625 31.5 27.734375 30.71875 \nQ 29.828125 30.171875 32.03125 29.5625 \nQ 34.234375 28.953125 36.296875 28.09375 \nQ 38.375 27.25 40.203125 26.09375 \nQ 42.046875 24.953125 43.40625 23.34375 \nQ 44.78125 21.734375 45.578125 19.578125 \nQ 46.390625 17.4375 46.390625 14.59375 \nz\n\" id=\"LiberationSans-115\"/>\n     <path d=\"M 13.484375 24.5625 \nQ 13.484375 20.40625 14.328125 16.90625 \nQ 15.1875 13.421875 16.96875 10.90625 \nQ 18.75 8.40625 21.53125 7 \nQ 24.3125 5.609375 28.21875 5.609375 \nQ 33.9375 5.609375 37.375 7.90625 \nQ 40.828125 10.203125 42.046875 13.71875 \nL 49.75 11.53125 \nQ 48.921875 9.328125 47.4375 7.109375 \nQ 45.953125 4.890625 43.453125 3.09375 \nQ 40.96875 1.3125 37.234375 0.15625 \nQ 33.5 -0.984375 28.21875 -0.984375 \nQ 16.5 -0.984375 10.375 6 \nQ 4.25 12.984375 4.25 26.765625 \nQ 4.25 34.1875 6.09375 39.328125 \nQ 7.953125 44.484375 11.171875 47.703125 \nQ 14.40625 50.921875 18.703125 52.359375 \nQ 23 53.8125 27.875 53.8125 \nQ 34.515625 53.8125 38.984375 51.65625 \nQ 43.453125 49.515625 46.15625 45.71875 \nQ 48.875 41.9375 50.015625 36.8125 \nQ 51.171875 31.6875 51.171875 25.734375 \nL 51.171875 24.5625 \nz\nM 42.09375 31.296875 \nQ 41.359375 39.65625 37.84375 43.484375 \nQ 34.328125 47.3125 27.734375 47.3125 \nQ 25.53125 47.3125 23.109375 46.609375 \nQ 20.703125 45.90625 18.65625 44.09375 \nQ 16.609375 42.28125 15.1875 39.171875 \nQ 13.765625 36.078125 13.578125 31.296875 \nz\n\" id=\"LiberationSans-101\"/>\n     <path d=\"M 4.890625 41.796875 \nL 4.890625 49.03125 \nL 53.46875 49.03125 \nL 53.46875 41.796875 \nz\nM 4.890625 16.796875 \nL 4.890625 24.03125 \nL 53.46875 24.03125 \nL 53.46875 16.796875 \nz\n\" id=\"LiberationSans-61\"/>\n     <path d=\"M 29.9375 0 \nL 19.53125 0 \nL 0.34375 52.828125 \nL 9.71875 52.828125 \nL 21.34375 18.453125 \nQ 21.6875 17.390625 22.140625 15.84375 \nQ 22.609375 14.3125 23.09375 12.640625 \nQ 23.578125 10.984375 24 9.4375 \nQ 24.421875 7.90625 24.703125 6.890625 \nQ 25 7.90625 25.453125 9.4375 \nQ 25.921875 10.984375 26.40625 12.59375 \nQ 26.90625 14.203125 27.421875 15.734375 \nQ 27.9375 17.28125 28.328125 18.359375 \nL 40.328125 52.828125 \nL 49.65625 52.828125 \nz\n\" id=\"LiberationSans-118\"/>\n     <path d=\"M 26.765625 -20.75 \nQ 22.21875 -20.75 18.703125 -19.8125 \nQ 15.1875 -18.890625 12.6875 -17.15625 \nQ 10.203125 -15.4375 8.640625 -13.03125 \nQ 7.078125 -10.640625 6.390625 -7.71875 \nL 15.234375 -6.453125 \nQ 16.109375 -10.109375 19.109375 -12.078125 \nQ 22.125 -14.0625 27 -14.0625 \nQ 29.984375 -14.0625 32.421875 -13.234375 \nQ 34.859375 -12.40625 36.5625 -10.5625 \nQ 38.28125 -8.734375 39.203125 -5.796875 \nQ 40.140625 -2.875 40.140625 1.3125 \nL 40.140625 9.8125 \nL 40.046875 9.8125 \nQ 39.0625 7.8125 37.625 5.984375 \nQ 36.1875 4.15625 34.109375 2.734375 \nQ 32.03125 1.3125 29.296875 0.453125 \nQ 26.5625 -0.390625 23.046875 -0.390625 \nQ 18.015625 -0.390625 14.421875 1.296875 \nQ 10.84375 2.984375 8.5625 6.34375 \nQ 6.296875 9.71875 5.25 14.71875 \nQ 4.203125 19.734375 4.203125 26.3125 \nQ 4.203125 32.671875 5.25 37.75 \nQ 6.296875 42.828125 8.65625 46.359375 \nQ 11.03125 49.90625 14.8125 51.78125 \nQ 18.609375 53.65625 24.03125 53.65625 \nQ 29.640625 53.65625 33.765625 51.09375 \nQ 37.890625 48.53125 40.140625 43.796875 \nL 40.234375 43.796875 \nQ 40.234375 45.015625 40.296875 46.53125 \nQ 40.375 48.046875 40.453125 49.390625 \nQ 40.53125 50.734375 40.625 51.703125 \nQ 40.71875 52.6875 40.828125 52.828125 \nL 49.171875 52.828125 \nQ 49.125 52.390625 49.078125 51.34375 \nQ 49.03125 50.296875 48.96875 48.828125 \nQ 48.921875 47.359375 48.890625 45.578125 \nQ 48.875 43.796875 48.875 41.890625 \nL 48.875 1.515625 \nQ 48.875 -9.578125 43.421875 -15.15625 \nQ 37.984375 -20.75 26.765625 -20.75 \nz\nM 40.140625 26.421875 \nQ 40.140625 31.9375 38.9375 35.859375 \nQ 37.75 39.796875 35.796875 42.28125 \nQ 33.84375 44.78125 31.328125 45.953125 \nQ 28.8125 47.125 26.171875 47.125 \nQ 22.796875 47.125 20.375 45.953125 \nQ 17.96875 44.78125 16.375 42.265625 \nQ 14.796875 39.75 14.03125 35.8125 \nQ 13.28125 31.890625 13.28125 26.421875 \nQ 13.28125 20.703125 14.03125 16.8125 \nQ 14.796875 12.9375 16.359375 10.546875 \nQ 17.921875 8.15625 20.3125 7.125 \nQ 22.703125 6.109375 26.03125 6.109375 \nQ 28.65625 6.109375 31.171875 7.21875 \nQ 33.6875 8.34375 35.6875 10.78125 \nQ 37.703125 13.234375 38.921875 17.09375 \nQ 40.140625 20.953125 40.140625 26.421875 \nz\n\" id=\"LiberationSans-103\"/>\n     <path d=\"M 38.1875 0 \nL 28.515625 0 \nL 0.4375 68.796875 \nL 10.25 68.796875 \nL 29.296875 20.359375 \nQ 30.03125 18.171875 30.765625 15.984375 \nQ 31.5 13.8125 32.078125 12.109375 \nQ 32.765625 10.109375 33.40625 8.203125 \nQ 33.984375 10.015625 34.671875 12.015625 \nQ 35.25 13.71875 35.953125 15.859375 \nQ 36.671875 18.015625 37.5 20.359375 \nL 56.453125 68.796875 \nL 66.265625 68.796875 \nz\n\" id=\"LiberationSans-86\"/>\n     <path d=\"M 6.6875 64.0625 \nL 6.6875 72.46875 \nL 15.484375 72.46875 \nL 15.484375 64.0625 \nz\nM 6.6875 0 \nL 6.6875 52.828125 \nL 15.484375 52.828125 \nL 15.484375 0 \nz\n\" id=\"LiberationSans-105\"/>\n     <path d=\"M 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 37.359375 39.71875 39.9375 \nQ 39.15625 42.53125 37.890625 44.109375 \nQ 36.625 45.703125 34.546875 46.359375 \nQ 32.46875 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.921875 \nQ 21.234375 44.828125 19.453125 42.75 \nQ 17.671875 40.671875 16.6875 37.625 \nQ 15.71875 34.578125 15.71875 30.609375 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 41.546875 \nQ 6.9375 43.21875 6.90625 45.046875 \nQ 6.890625 46.875 6.828125 48.5 \nQ 6.78125 50.140625 6.734375 51.3125 \nQ 6.6875 52.484375 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.59375 15.03125 51.515625 \nQ 15.09375 50.4375 15.15625 49.046875 \nQ 15.234375 47.65625 15.28125 46.21875 \nQ 15.328125 44.78125 15.328125 43.796875 \nL 15.484375 43.796875 \nQ 16.75 46.09375 18.265625 47.953125 \nQ 19.78125 49.8125 21.78125 51.09375 \nQ 23.78125 52.390625 26.359375 53.09375 \nQ 28.953125 53.8125 32.375 53.8125 \nQ 36.765625 53.8125 39.9375 52.734375 \nQ 43.109375 51.65625 45.15625 49.40625 \nQ 47.21875 47.171875 48.171875 43.625 \nQ 49.125 40.09375 49.125 35.203125 \nL 49.125 0 \nz\n\" id=\"LiberationSans-110\"/>\n    </defs>\n    <g style=\"fill:#262626;\" transform=\"translate(61.158125 15.89625)scale(0.12 -0.12)\">\n     <use xlink:href=\"#LiberationSans-76\"/>\n     <use x=\"55.615234\" xlink:href=\"#LiberationSans-83\"/>\n     <use x=\"122.314453\" xlink:href=\"#LiberationSans-84\"/>\n     <use x=\"183.398438\" xlink:href=\"#LiberationSans-77\"/>\n     <use x=\"266.699219\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"288.982422\" xlink:href=\"#LiberationSans-65\"/>\n     <use x=\"355.681641\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"405.681641\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"455.681641\" xlink:href=\"#LiberationSans-117\"/>\n     <use x=\"511.296875\" xlink:href=\"#LiberationSans-114\"/>\n     <use x=\"544.597656\" xlink:href=\"#LiberationSans-97\"/>\n     <use x=\"600.212891\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"650.212891\" xlink:href=\"#LiberationSans-121\"/>\n     <use x=\"700.212891\" xlink:href=\"#LiberationSans-45\"/>\n     <use x=\"733.513672\" xlink:href=\"#LiberationSans-69\"/>\n     <use x=\"800.212891\" xlink:href=\"#LiberationSans-112\"/>\n     <use x=\"855.828125\" xlink:href=\"#LiberationSans-111\"/>\n     <use x=\"911.443359\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"961.443359\" xlink:href=\"#LiberationSans-104\"/>\n     <use x=\"1017.058594\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1044.841797\" xlink:href=\"#LiberationSans-112\"/>\n     <use x=\"1100.457031\" xlink:href=\"#LiberationSans-108\"/>\n     <use x=\"1122.673828\" xlink:href=\"#LiberationSans-111\"/>\n     <use x=\"1178.289062\" xlink:href=\"#LiberationSans-116\"/>\n     <use x=\"1206.072266\" xlink:href=\"#LiberationSans-44\"/>\n     <use x=\"1233.855469\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1261.638672\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"1311.638672\" xlink:href=\"#LiberationSans-97\"/>\n     <use x=\"1367.253906\" xlink:href=\"#LiberationSans-115\"/>\n     <use x=\"1417.253906\" xlink:href=\"#LiberationSans-101\"/>\n     <use x=\"1472.869141\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1500.652344\" xlink:href=\"#LiberationSans-61\"/>\n     <use x=\"1559.050781\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1586.833984\" xlink:href=\"#LiberationSans-50\"/>\n     <use x=\"1642.449219\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1670.232422\" xlink:href=\"#LiberationSans-44\"/>\n     <use x=\"1698.015625\" xlink:href=\"#LiberationSans-65\"/>\n     <use x=\"1762.964844\" xlink:href=\"#LiberationSans-118\"/>\n     <use x=\"1812.964844\" xlink:href=\"#LiberationSans-103\"/>\n     <use x=\"1868.580078\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1896.363281\" xlink:href=\"#LiberationSans-86\"/>\n     <use x=\"1955.6875\" xlink:href=\"#LiberationSans-97\"/>\n     <use x=\"2011.302734\" xlink:href=\"#LiberationSans-108\"/>\n     <use x=\"2033.519531\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2055.802734\" xlink:href=\"#LiberationSans-65\"/>\n     <use x=\"2122.501953\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"2172.501953\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"2222.501953\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2250.285156\" xlink:href=\"#LiberationSans-61\"/>\n     <use x=\"2308.683594\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2336.466797\" xlink:href=\"#LiberationSans-48\"/>\n     <use x=\"2392.082031\" xlink:href=\"#LiberationSans-46\"/>\n     <use x=\"2419.865234\" xlink:href=\"#LiberationSans-56\"/>\n     <use x=\"2475.480469\" xlink:href=\"#LiberationSans-54\"/>\n     <use x=\"2531.095703\" xlink:href=\"#LiberationSans-44\"/>\n     <use x=\"2558.878906\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2581.162109\" xlink:href=\"#LiberationSans-65\"/>\n     <use x=\"2646.111328\" xlink:href=\"#LiberationSans-118\"/>\n     <use x=\"2696.111328\" xlink:href=\"#LiberationSans-103\"/>\n     <use x=\"2751.726562\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2777.759766\" xlink:href=\"#LiberationSans-84\"/>\n     <use x=\"2835.09375\" xlink:href=\"#LiberationSans-114\"/>\n     <use x=\"2868.394531\" xlink:href=\"#LiberationSans-97\"/>\n     <use x=\"2924.009766\" xlink:href=\"#LiberationSans-105\"/>\n     <use x=\"2946.226562\" xlink:href=\"#LiberationSans-110\"/>\n     <use x=\"3001.841797\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"3024.125\" xlink:href=\"#LiberationSans-65\"/>\n     <use x=\"3090.824219\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"3140.824219\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"3190.824219\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"3218.607422\" xlink:href=\"#LiberationSans-61\"/>\n     <use x=\"3277.005859\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"3304.789062\" xlink:href=\"#LiberationSans-48\"/>\n     <use x=\"3360.404297\" xlink:href=\"#LiberationSans-46\"/>\n     <use x=\"3388.1875\" xlink:href=\"#LiberationSans-57\"/>\n     <use x=\"3443.802734\" xlink:href=\"#LiberationSans-55\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"line2d_25\">\n     <path d=\"M 56.915 34.643125 \nL 76.915 34.643125 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.75;\"/>\n    </g>\n    <g id=\"line2d_26\"/>\n    <g id=\"text_15\">\n     <!-- TrainAcc -->\n     <g style=\"fill:#262626;\" transform=\"translate(84.915 38.143125)scale(0.1 -0.1)\">\n      <use xlink:href=\"#LiberationSans-84\"/>\n      <use x=\"57.333984\" xlink:href=\"#LiberationSans-114\"/>\n      <use x=\"90.634766\" xlink:href=\"#LiberationSans-97\"/>\n      <use x=\"146.25\" xlink:href=\"#LiberationSans-105\"/>\n      <use x=\"168.466797\" xlink:href=\"#LiberationSans-110\"/>\n      <use x=\"224.082031\" xlink:href=\"#LiberationSans-65\"/>\n      <use x=\"290.78125\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"340.78125\" xlink:href=\"#LiberationSans-99\"/>\n     </g>\n    </g>\n    <g id=\"line2d_27\">\n     <path d=\"M 56.915 48.965 \nL 76.915 48.965 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.75;\"/>\n    </g>\n    <g id=\"line2d_28\"/>\n    <g id=\"text_16\">\n     <!-- ValAcc -->\n     <g style=\"fill:#262626;\" transform=\"translate(84.915 52.465)scale(0.1 -0.1)\">\n      <use xlink:href=\"#LiberationSans-86\"/>\n      <use x=\"59.324219\" xlink:href=\"#LiberationSans-97\"/>\n      <use x=\"114.939453\" xlink:href=\"#LiberationSans-108\"/>\n      <use x=\"137.15625\" xlink:href=\"#LiberationSans-65\"/>\n      <use x=\"203.855469\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"253.855469\" xlink:href=\"#LiberationSans-99\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0484a9ba28\">\n   <rect height=\"298.98\" width=\"446.4\" x=\"47.915\" y=\"21.89625\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["<Figure size 576x396 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"358.652187pt\" version=\"1.1\" viewBox=\"0 0 507.075937 358.652187\" width=\"507.075937pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 358.652187 \nL 507.075937 358.652187 \nL 507.075937 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 53.475938 320.87625 \nL 499.875937 320.87625 \nL 499.875937 21.89625 \nL 53.475938 21.89625 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 73.766847 320.87625 \nL 73.766847 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 51.703125 34.421875 \nQ 51.703125 24.515625 49.828125 17.75 \nQ 47.953125 10.984375 44.703125 6.8125 \nQ 41.453125 2.640625 37.0625 0.828125 \nQ 32.671875 -0.984375 27.6875 -0.984375 \nQ 22.65625 -0.984375 18.3125 0.828125 \nQ 13.96875 2.640625 10.765625 6.78125 \nQ 7.5625 10.9375 5.734375 17.703125 \nQ 3.90625 24.46875 3.90625 34.421875 \nQ 3.90625 44.828125 5.734375 51.640625 \nQ 7.5625 58.453125 10.78125 62.5 \nQ 14.015625 66.546875 18.40625 68.1875 \nQ 22.796875 69.828125 27.984375 69.828125 \nQ 32.90625 69.828125 37.21875 68.1875 \nQ 41.546875 66.546875 44.765625 62.5 \nQ 48 58.453125 49.84375 51.640625 \nQ 51.703125 44.828125 51.703125 34.421875 \nz\nM 42.78125 34.421875 \nQ 42.78125 42.625 41.796875 48.0625 \nQ 40.828125 53.515625 38.921875 56.765625 \nQ 37.015625 60.015625 34.25 61.359375 \nQ 31.5 62.703125 27.984375 62.703125 \nQ 24.265625 62.703125 21.4375 61.328125 \nQ 18.609375 59.96875 16.671875 56.71875 \nQ 14.75 53.46875 13.765625 48.015625 \nQ 12.796875 42.578125 12.796875 34.421875 \nQ 12.796875 26.515625 13.796875 21.09375 \nQ 14.796875 15.671875 16.71875 12.375 \nQ 18.65625 9.078125 21.4375 7.640625 \nQ 24.21875 6.203125 27.78125 6.203125 \nQ 31.25 6.203125 34.03125 7.640625 \nQ 36.8125 9.078125 38.734375 12.375 \nQ 40.671875 15.671875 41.71875 21.09375 \nQ 42.78125 26.515625 42.78125 34.421875 \nz\n\" id=\"LiberationSans-48\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(70.986378 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 154.930483 320.87625 \nL 154.930483 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 5.03125 0 \nL 5.03125 6.203125 \nQ 7.515625 11.921875 11.109375 16.28125 \nQ 14.703125 20.65625 18.65625 24.1875 \nQ 22.609375 27.734375 26.484375 30.765625 \nQ 30.375 33.796875 33.5 36.8125 \nQ 36.625 39.84375 38.546875 43.15625 \nQ 40.484375 46.484375 40.484375 50.6875 \nQ 40.484375 53.609375 39.59375 55.828125 \nQ 38.71875 58.0625 37.0625 59.5625 \nQ 35.40625 61.078125 33.078125 61.828125 \nQ 30.765625 62.59375 27.9375 62.59375 \nQ 25.296875 62.59375 22.96875 61.859375 \nQ 20.65625 61.140625 18.84375 59.671875 \nQ 17.046875 58.203125 15.890625 56.03125 \nQ 14.75 53.859375 14.40625 50.984375 \nL 5.421875 51.8125 \nQ 5.859375 55.515625 7.46875 58.78125 \nQ 9.078125 62.0625 11.90625 64.53125 \nQ 14.75 67 18.71875 68.40625 \nQ 22.703125 69.828125 27.9375 69.828125 \nQ 33.0625 69.828125 37.0625 68.609375 \nQ 41.0625 67.390625 43.8125 64.984375 \nQ 46.578125 62.59375 48.046875 59.078125 \nQ 49.515625 55.5625 49.515625 50.984375 \nQ 49.515625 47.515625 48.265625 44.390625 \nQ 47.015625 41.265625 44.9375 38.421875 \nQ 42.875 35.59375 40.140625 32.953125 \nQ 37.40625 30.328125 34.421875 27.8125 \nQ 31.453125 25.296875 28.421875 22.828125 \nQ 25.390625 20.359375 22.71875 17.859375 \nQ 20.0625 15.375 17.96875 12.8125 \nQ 15.875 10.25 14.703125 7.46875 \nL 50.59375 7.46875 \nL 50.59375 0 \nz\n\" id=\"LiberationSans-50\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(152.150014 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 236.094119 320.87625 \nL 236.094119 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 43.015625 15.578125 \nL 43.015625 0 \nL 34.71875 0 \nL 34.71875 15.578125 \nL 2.296875 15.578125 \nL 2.296875 22.40625 \nL 33.796875 68.796875 \nL 43.015625 68.796875 \nL 43.015625 22.515625 \nL 52.6875 22.515625 \nL 52.6875 15.578125 \nz\nM 34.71875 58.890625 \nQ 34.625 58.640625 34.234375 57.9375 \nQ 33.84375 57.234375 33.34375 56.34375 \nQ 32.859375 55.46875 32.34375 54.5625 \nQ 31.84375 53.65625 31.453125 53.078125 \nL 13.8125 27.09375 \nQ 13.578125 26.703125 13.109375 26.0625 \nQ 12.640625 25.4375 12.15625 24.78125 \nQ 11.671875 24.125 11.171875 23.484375 \nQ 10.6875 22.859375 10.40625 22.515625 \nL 34.71875 22.515625 \nz\n\" id=\"LiberationSans-52\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(233.313651 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 317.257756 320.87625 \nL 317.257756 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 51.21875 22.515625 \nQ 51.21875 17.328125 49.78125 13 \nQ 48.34375 8.6875 45.53125 5.578125 \nQ 42.71875 2.484375 38.5625 0.75 \nQ 34.421875 -0.984375 29 -0.984375 \nQ 23 -0.984375 18.5 1.3125 \nQ 14.015625 3.609375 11.03125 7.921875 \nQ 8.0625 12.25 6.5625 18.53125 \nQ 5.078125 24.8125 5.078125 32.8125 \nQ 5.078125 42 6.765625 48.921875 \nQ 8.453125 55.859375 11.625 60.5 \nQ 14.796875 65.140625 19.359375 67.484375 \nQ 23.921875 69.828125 29.6875 69.828125 \nQ 33.203125 69.828125 36.28125 69.09375 \nQ 39.359375 68.359375 41.875 66.71875 \nQ 44.390625 65.09375 46.28125 62.40625 \nQ 48.1875 59.71875 49.3125 55.8125 \nL 40.921875 54.296875 \nQ 39.546875 58.734375 36.546875 60.71875 \nQ 33.546875 62.703125 29.59375 62.703125 \nQ 25.984375 62.703125 23.046875 60.984375 \nQ 20.125 59.28125 18.0625 55.875 \nQ 16.015625 52.484375 14.90625 47.359375 \nQ 13.8125 42.234375 13.8125 35.40625 \nQ 16.21875 39.84375 20.5625 42.15625 \nQ 24.90625 44.484375 30.515625 44.484375 \nQ 35.203125 44.484375 39.015625 42.96875 \nQ 42.828125 41.453125 45.53125 38.59375 \nQ 48.25 35.75 49.734375 31.671875 \nQ 51.21875 27.59375 51.21875 22.515625 \nz\nM 42.28125 22.125 \nQ 42.28125 25.6875 41.40625 28.5625 \nQ 40.53125 31.453125 38.765625 33.46875 \nQ 37.015625 35.5 34.421875 36.59375 \nQ 31.84375 37.703125 28.421875 37.703125 \nQ 26.03125 37.703125 23.578125 36.984375 \nQ 21.140625 36.28125 19.15625 34.6875 \nQ 17.1875 33.109375 15.9375 30.515625 \nQ 14.703125 27.9375 14.703125 24.21875 \nQ 14.703125 20.40625 15.671875 17.109375 \nQ 16.65625 13.8125 18.484375 11.375 \nQ 20.3125 8.9375 22.890625 7.515625 \nQ 25.484375 6.109375 28.71875 6.109375 \nQ 31.890625 6.109375 34.40625 7.203125 \nQ 36.921875 8.296875 38.671875 10.375 \nQ 40.4375 12.453125 41.359375 15.421875 \nQ 42.28125 18.40625 42.28125 22.125 \nz\n\" id=\"LiberationSans-54\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(314.477287 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 398.421392 320.87625 \nL 398.421392 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 51.265625 19.1875 \nQ 51.265625 14.796875 49.875 11.109375 \nQ 48.484375 7.421875 45.625 4.734375 \nQ 42.78125 2.046875 38.328125 0.53125 \nQ 33.890625 -0.984375 27.828125 -0.984375 \nQ 21.78125 -0.984375 17.359375 0.53125 \nQ 12.9375 2.046875 10.03125 4.703125 \nQ 7.125 7.375 5.734375 11.0625 \nQ 4.34375 14.75 4.34375 19.09375 \nQ 4.34375 22.859375 5.484375 25.78125 \nQ 6.640625 28.71875 8.5625 30.828125 \nQ 10.5 32.953125 12.96875 34.25 \nQ 15.4375 35.546875 18.0625 35.984375 \nL 18.0625 36.1875 \nQ 15.1875 36.859375 12.90625 38.375 \nQ 10.640625 39.890625 9.09375 42.015625 \nQ 7.5625 44.140625 6.75 46.71875 \nQ 5.953125 49.3125 5.953125 52.203125 \nQ 5.953125 55.8125 7.34375 59 \nQ 8.734375 62.203125 11.46875 64.625 \nQ 14.203125 67.046875 18.25 68.4375 \nQ 22.3125 69.828125 27.640625 69.828125 \nQ 33.25 69.828125 37.375 68.40625 \nQ 41.5 67 44.203125 64.578125 \nQ 46.921875 62.15625 48.234375 58.9375 \nQ 49.5625 55.71875 49.5625 52.09375 \nQ 49.5625 49.265625 48.75 46.671875 \nQ 47.953125 44.09375 46.40625 41.96875 \nQ 44.875 39.84375 42.59375 38.34375 \nQ 40.328125 36.859375 37.359375 36.28125 \nL 37.359375 36.078125 \nQ 40.328125 35.59375 42.859375 34.296875 \nQ 45.40625 33.015625 47.265625 30.890625 \nQ 49.125 28.765625 50.1875 25.828125 \nQ 51.265625 22.90625 51.265625 19.1875 \nz\nM 40.4375 51.609375 \nQ 40.4375 54.203125 39.765625 56.34375 \nQ 39.109375 58.5 37.59375 60.03125 \nQ 36.078125 61.578125 33.640625 62.421875 \nQ 31.203125 63.28125 27.640625 63.28125 \nQ 24.171875 63.28125 21.78125 62.421875 \nQ 19.390625 61.578125 17.84375 60.03125 \nQ 16.3125 58.5 15.625 56.34375 \nQ 14.9375 54.203125 14.9375 51.609375 \nQ 14.9375 49.5625 15.46875 47.40625 \nQ 16.015625 45.265625 17.421875 43.5 \nQ 18.84375 41.75 21.328125 40.625 \nQ 23.828125 39.5 27.734375 39.5 \nQ 31.890625 39.5 34.40625 40.625 \nQ 36.921875 41.75 38.25 43.5 \nQ 39.59375 45.265625 40.015625 47.40625 \nQ 40.4375 49.5625 40.4375 51.609375 \nz\nM 42.140625 20.015625 \nQ 42.140625 22.515625 41.453125 24.828125 \nQ 40.765625 27.15625 39.109375 28.9375 \nQ 37.453125 30.71875 34.640625 31.8125 \nQ 31.84375 32.90625 27.640625 32.90625 \nQ 23.78125 32.90625 21.0625 31.8125 \nQ 18.359375 30.71875 16.671875 28.90625 \nQ 14.984375 27.09375 14.203125 24.71875 \nQ 13.421875 22.359375 13.421875 19.828125 \nQ 13.421875 16.65625 14.203125 14.03125 \nQ 14.984375 11.421875 16.6875 9.546875 \nQ 18.40625 7.671875 21.1875 6.640625 \nQ 23.96875 5.609375 27.9375 5.609375 \nQ 31.9375 5.609375 34.671875 6.640625 \nQ 37.40625 7.671875 39.0625 9.546875 \nQ 40.71875 11.421875 41.421875 14.078125 \nQ 42.140625 16.75 42.140625 20.015625 \nz\n\" id=\"LiberationSans-56\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(395.640923 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 479.585028 320.87625 \nL 479.585028 21.89625 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 7.625 0 \nL 7.625 7.46875 \nL 25.140625 7.46875 \nL 25.140625 60.40625 \nL 9.625 49.3125 \nL 9.625 57.625 \nL 25.875 68.796875 \nL 33.984375 68.796875 \nL 33.984375 7.46875 \nL 50.734375 7.46875 \nL 50.734375 0 \nz\n\" id=\"LiberationSans-49\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(474.024091 335.123125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-49\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 8.203125 0 \nL 8.203125 68.796875 \nL 60.40625 68.796875 \nL 60.40625 61.1875 \nL 17.53125 61.1875 \nL 17.53125 39.109375 \nL 57.46875 39.109375 \nL 57.46875 31.59375 \nL 17.53125 31.59375 \nL 17.53125 7.625 \nL 62.40625 7.625 \nL 62.40625 0 \nz\n\" id=\"LiberationSans-69\"/>\n      <path d=\"M 51.421875 26.65625 \nQ 51.421875 20.65625 50.4375 15.578125 \nQ 49.46875 10.5 47.1875 6.828125 \nQ 44.921875 3.171875 41.1875 1.09375 \nQ 37.453125 -0.984375 31.984375 -0.984375 \nQ 26.3125 -0.984375 22.0625 1.171875 \nQ 17.828125 3.328125 15.578125 8.203125 \nL 15.328125 8.203125 \nQ 15.375 8.109375 15.40625 7.328125 \nQ 15.4375 6.546875 15.453125 5.375 \nQ 15.484375 4.203125 15.5 2.75 \nQ 15.53125 1.3125 15.53125 -0.09375 \nL 15.53125 -20.75 \nL 6.734375 -20.75 \nL 6.734375 42.046875 \nQ 6.734375 43.953125 6.703125 45.703125 \nQ 6.6875 47.46875 6.640625 48.90625 \nQ 6.59375 50.34375 6.546875 51.359375 \nQ 6.5 52.390625 6.453125 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.6875 15.0625 51.796875 \nQ 15.140625 50.921875 15.203125 49.671875 \nQ 15.28125 48.4375 15.359375 47.015625 \nQ 15.4375 45.609375 15.4375 44.34375 \nL 15.625 44.34375 \nQ 16.84375 46.875 18.40625 48.65625 \nQ 19.96875 50.4375 21.96875 51.578125 \nQ 23.96875 52.734375 26.4375 53.25 \nQ 28.90625 53.765625 31.984375 53.765625 \nQ 37.453125 53.765625 41.1875 51.8125 \nQ 44.921875 49.859375 47.1875 46.3125 \nQ 49.46875 42.78125 50.4375 37.765625 \nQ 51.421875 32.765625 51.421875 26.65625 \nz\nM 42.1875 26.46875 \nQ 42.1875 31.34375 41.59375 35.15625 \nQ 41.015625 38.96875 39.578125 41.59375 \nQ 38.140625 44.234375 35.734375 45.59375 \nQ 33.34375 46.96875 29.734375 46.96875 \nQ 26.8125 46.96875 24.21875 46.140625 \nQ 21.625 45.3125 19.703125 42.96875 \nQ 17.78125 40.625 16.65625 36.5 \nQ 15.53125 32.375 15.53125 25.78125 \nQ 15.53125 20.171875 16.453125 16.28125 \nQ 17.390625 12.40625 19.171875 10.015625 \nQ 20.953125 7.625 23.578125 6.5625 \nQ 26.21875 5.515625 29.640625 5.515625 \nQ 33.296875 5.515625 35.71875 6.921875 \nQ 38.140625 8.34375 39.578125 11.03125 \nQ 41.015625 13.71875 41.59375 17.59375 \nQ 42.1875 21.484375 42.1875 26.46875 \nz\n\" id=\"LiberationSans-112\"/>\n      <path d=\"M 51.421875 26.46875 \nQ 51.421875 12.59375 45.3125 5.796875 \nQ 39.203125 -0.984375 27.59375 -0.984375 \nQ 22.078125 -0.984375 17.71875 0.671875 \nQ 13.375 2.34375 10.375 5.765625 \nQ 7.375 9.1875 5.78125 14.328125 \nQ 4.203125 19.484375 4.203125 26.46875 \nQ 4.203125 53.8125 27.875 53.8125 \nQ 34.03125 53.8125 38.5 52.09375 \nQ 42.96875 50.390625 45.828125 46.96875 \nQ 48.6875 43.5625 50.046875 38.421875 \nQ 51.421875 33.296875 51.421875 26.46875 \nz\nM 42.1875 26.46875 \nQ 42.1875 32.625 41.234375 36.625 \nQ 40.28125 40.625 38.453125 43.015625 \nQ 36.625 45.40625 33.984375 46.359375 \nQ 31.34375 47.3125 28.03125 47.3125 \nQ 24.65625 47.3125 21.9375 46.3125 \nQ 19.234375 45.3125 17.328125 42.890625 \nQ 15.4375 40.484375 14.421875 36.46875 \nQ 13.421875 32.46875 13.421875 26.46875 \nQ 13.421875 20.3125 14.5 16.28125 \nQ 15.578125 12.25 17.453125 9.859375 \nQ 19.34375 7.46875 21.90625 6.484375 \nQ 24.46875 5.515625 27.484375 5.515625 \nQ 30.859375 5.515625 33.59375 6.46875 \nQ 36.328125 7.421875 38.234375 9.8125 \nQ 40.140625 12.203125 41.15625 16.25 \nQ 42.1875 20.3125 42.1875 26.46875 \nz\n\" id=\"LiberationSans-111\"/>\n      <path d=\"M 13.421875 26.65625 \nQ 13.421875 22.125 14.078125 18.3125 \nQ 14.75 14.5 16.3125 11.734375 \nQ 17.875 8.984375 20.4375 7.46875 \nQ 23 5.953125 26.765625 5.953125 \nQ 31.453125 5.953125 34.59375 8.484375 \nQ 37.75 11.03125 38.484375 16.3125 \nL 47.359375 15.71875 \nQ 46.921875 12.453125 45.453125 9.421875 \nQ 44 6.390625 41.484375 4.09375 \nQ 38.96875 1.8125 35.34375 0.40625 \nQ 31.734375 -0.984375 27 -0.984375 \nQ 20.796875 -0.984375 16.453125 1.109375 \nQ 12.109375 3.21875 9.390625 6.90625 \nQ 6.6875 10.59375 5.46875 15.59375 \nQ 4.25 20.609375 4.25 26.46875 \nQ 4.25 31.78125 5.125 35.859375 \nQ 6 39.9375 7.59375 42.984375 \nQ 9.1875 46.046875 11.328125 48.125 \nQ 13.484375 50.203125 15.984375 51.4375 \nQ 18.5 52.6875 21.28125 53.25 \nQ 24.078125 53.8125 26.90625 53.8125 \nQ 31.34375 53.8125 34.8125 52.59375 \nQ 38.28125 51.375 40.796875 49.25 \nQ 43.3125 47.125 44.875 44.234375 \nQ 46.4375 41.359375 47.078125 38.03125 \nL 38.03125 37.359375 \nQ 37.359375 41.75 34.5625 44.328125 \nQ 31.78125 46.921875 26.65625 46.921875 \nQ 22.90625 46.921875 20.390625 45.671875 \nQ 17.875 44.4375 16.3125 41.921875 \nQ 14.75 39.40625 14.078125 35.59375 \nQ 13.421875 31.78125 13.421875 26.65625 \nz\n\" id=\"LiberationSans-99\"/>\n      <path d=\"M 15.484375 43.796875 \nQ 16.9375 46.484375 18.640625 48.359375 \nQ 20.359375 50.25 22.40625 51.46875 \nQ 24.46875 52.6875 26.90625 53.25 \nQ 29.34375 53.8125 32.375 53.8125 \nQ 37.453125 53.8125 40.703125 52.4375 \nQ 43.953125 51.078125 45.828125 48.609375 \nQ 47.703125 46.140625 48.40625 42.71875 \nQ 49.125 39.3125 49.125 35.203125 \nL 49.125 0 \nL 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 36.859375 39.859375 39.390625 \nQ 39.453125 41.9375 38.28125 43.625 \nQ 37.109375 45.3125 34.953125 46.15625 \nQ 32.8125 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.890625 \nQ 21.234375 44.78125 19.453125 42.71875 \nQ 17.671875 40.671875 16.6875 37.734375 \nQ 15.71875 34.8125 15.71875 31.15625 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 72.46875 \nL 15.71875 72.46875 \nL 15.71875 53.609375 \nQ 15.71875 52 15.671875 50.390625 \nQ 15.625 48.78125 15.546875 47.40625 \nQ 15.484375 46.046875 15.421875 45.09375 \nQ 15.375 44.140625 15.328125 43.796875 \nz\n\" id=\"LiberationSans-104\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(261.081719 349.169687)scale(0.11 -0.11)\">\n      <use xlink:href=\"#LiberationSans-69\"/>\n      <use x=\"66.699219\" xlink:href=\"#LiberationSans-112\"/>\n      <use x=\"122.314453\" xlink:href=\"#LiberationSans-111\"/>\n      <use x=\"177.929688\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"227.929688\" xlink:href=\"#LiberationSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 307.189225 \nL 499.875937 307.189225 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_8\">\n      <!-- 0.775 -->\n      <defs>\n       <path d=\"M 9.125 0 \nL 9.125 10.6875 \nL 18.65625 10.6875 \nL 18.65625 0 \nz\n\" id=\"LiberationSans-46\"/>\n       <path d=\"M 50.59375 61.671875 \nQ 45.40625 53.765625 41.0625 46.453125 \nQ 36.71875 39.15625 33.59375 31.75 \nQ 30.46875 24.359375 28.734375 16.578125 \nQ 27 8.796875 27 0 \nL 17.828125 0 \nQ 17.828125 8.25 19.78125 16.1875 \nQ 21.734375 24.125 25.046875 31.765625 \nQ 28.375 39.40625 32.765625 46.78125 \nQ 37.15625 54.15625 42.09375 61.328125 \nL 5.125 61.328125 \nL 5.125 68.796875 \nL 50.59375 68.796875 \nz\n\" id=\"LiberationSans-55\"/>\n       <path d=\"M 51.421875 22.40625 \nQ 51.421875 17.234375 49.859375 12.9375 \nQ 48.296875 8.640625 45.21875 5.53125 \nQ 42.140625 2.4375 37.578125 0.71875 \nQ 33.015625 -0.984375 27 -0.984375 \nQ 21.578125 -0.984375 17.546875 0.28125 \nQ 13.53125 1.5625 10.734375 3.78125 \nQ 7.953125 6 6.3125 8.984375 \nQ 4.6875 11.96875 4 15.375 \nL 12.890625 16.40625 \nQ 13.421875 14.453125 14.390625 12.625 \nQ 15.375 10.796875 17.0625 9.34375 \nQ 18.75 7.90625 21.21875 7.046875 \nQ 23.6875 6.203125 27.203125 6.203125 \nQ 30.609375 6.203125 33.390625 7.25 \nQ 36.1875 8.296875 38.15625 10.34375 \nQ 40.140625 12.40625 41.203125 15.375 \nQ 42.28125 18.359375 42.28125 22.21875 \nQ 42.28125 25.390625 41.25 28.046875 \nQ 40.234375 30.71875 38.328125 32.640625 \nQ 36.421875 34.578125 33.65625 35.640625 \nQ 30.90625 36.71875 27.390625 36.71875 \nQ 25.203125 36.71875 23.34375 36.328125 \nQ 21.484375 35.9375 19.890625 35.25 \nQ 18.3125 34.578125 17.015625 33.671875 \nQ 15.71875 32.765625 14.59375 31.78125 \nL 6 31.78125 \nL 8.296875 68.796875 \nL 47.40625 68.796875 \nL 47.40625 61.328125 \nL 16.3125 61.328125 \nL 14.984375 39.5 \nQ 17.328125 41.3125 20.84375 42.59375 \nQ 24.359375 43.890625 29.203125 43.890625 \nQ 34.328125 43.890625 38.421875 42.328125 \nQ 42.53125 40.765625 45.40625 37.90625 \nQ 48.296875 35.0625 49.859375 31.109375 \nQ 51.421875 27.15625 51.421875 22.40625 \nz\n\" id=\"LiberationSans-53\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 310.812662)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-55\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-55\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 273.133401 \nL 499.875937 273.133401 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_9\">\n      <!-- 0.800 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 276.756838)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-56\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 239.077576 \nL 499.875937 239.077576 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_10\">\n      <!-- 0.825 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 242.701014)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-56\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-50\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 205.021752 \nL 499.875937 205.021752 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_11\">\n      <!-- 0.850 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 208.64519)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-56\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 170.965928 \nL 499.875937 170.965928 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_22\"/>\n     <g id=\"text_12\">\n      <!-- 0.875 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 174.589365)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-56\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-55\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 136.910103 \nL 499.875937 136.910103 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_24\"/>\n     <g id=\"text_13\">\n      <!-- 0.900 -->\n      <defs>\n       <path d=\"M 50.875 35.796875 \nQ 50.875 26.609375 49.140625 19.703125 \nQ 47.40625 12.796875 44.1875 8.203125 \nQ 40.96875 3.609375 36.34375 1.3125 \nQ 31.734375 -0.984375 25.984375 -0.984375 \nQ 22.015625 -0.984375 18.84375 -0.171875 \nQ 15.671875 0.640625 13.171875 2.34375 \nQ 10.6875 4.046875 8.921875 6.78125 \nQ 7.171875 9.515625 6.109375 13.375 \nL 14.5 14.703125 \nQ 15.875 10.25 18.78125 8.171875 \nQ 21.6875 6.109375 26.125 6.109375 \nQ 29.6875 6.109375 32.640625 7.78125 \nQ 35.59375 9.46875 37.671875 12.84375 \nQ 39.75 16.21875 40.921875 21.296875 \nQ 42.09375 26.375 42.1875 33.203125 \nQ 41.15625 30.90625 39.375 29.09375 \nQ 37.59375 27.296875 35.328125 26.046875 \nQ 33.0625 24.8125 30.421875 24.140625 \nQ 27.78125 23.484375 25.09375 23.484375 \nQ 20.40625 23.484375 16.625 25.171875 \nQ 12.84375 26.859375 10.203125 29.875 \nQ 7.5625 32.90625 6.125 37.171875 \nQ 4.6875 41.453125 4.6875 46.6875 \nQ 4.6875 52 6.21875 56.296875 \nQ 7.765625 60.59375 10.6875 63.59375 \nQ 13.625 66.609375 17.890625 68.21875 \nQ 22.171875 69.828125 27.59375 69.828125 \nQ 39.0625 69.828125 44.96875 61.328125 \nQ 50.875 52.828125 50.875 35.796875 \nz\nM 41.3125 44.28125 \nQ 41.3125 48.09375 40.40625 51.453125 \nQ 39.5 54.828125 37.71875 57.3125 \nQ 35.9375 59.8125 33.328125 61.25 \nQ 30.71875 62.703125 27.296875 62.703125 \nQ 24.125 62.703125 21.578125 61.578125 \nQ 19.046875 60.453125 17.28125 58.375 \nQ 15.53125 56.296875 14.578125 53.3125 \nQ 13.625 50.34375 13.625 46.6875 \nQ 13.625 43.21875 14.46875 40.234375 \nQ 15.328125 37.25 17.03125 35.078125 \nQ 18.75 32.90625 21.28125 31.65625 \nQ 23.828125 30.421875 27.203125 30.421875 \nQ 29.640625 30.421875 32.15625 31.25 \nQ 34.671875 32.078125 36.6875 33.78125 \nQ 38.71875 35.5 40.015625 38.109375 \nQ 41.3125 40.71875 41.3125 44.28125 \nz\n\" id=\"LiberationSans-57\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 140.533541)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-57\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 102.854279 \nL 499.875937 102.854279 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_26\"/>\n     <g id=\"text_14\">\n      <!-- 0.925 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 106.477717)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-57\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-50\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 68.798455 \nL 499.875937 68.798455 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_28\"/>\n     <g id=\"text_15\">\n      <!-- 0.950 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 72.421892)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-57\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-53\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_29\">\n      <path clip-path=\"url(#p17af13f7c3)\" d=\"M 53.475938 34.742631 \nL 499.875937 34.742631 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_30\"/>\n     <g id=\"text_16\">\n      <!-- 0.975 -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.454062 38.366068)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-57\"/>\n       <use x=\"139.013672\" xlink:href=\"#LiberationSans-55\"/>\n       <use x=\"194.628906\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- F1 score -->\n     <defs>\n      <path d=\"M 17.53125 61.1875 \nL 17.53125 35.59375 \nL 55.90625 35.59375 \nL 55.90625 27.875 \nL 17.53125 27.875 \nL 17.53125 0 \nL 8.203125 0 \nL 8.203125 68.796875 \nL 57.078125 68.796875 \nL 57.078125 61.1875 \nz\n\" id=\"LiberationSans-70\"/>\n      <path id=\"LiberationSans-32\"/>\n      <path d=\"M 46.390625 14.59375 \nQ 46.390625 10.890625 44.9375 7.984375 \nQ 43.5 5.078125 40.765625 3.09375 \nQ 38.03125 1.125 34.046875 0.0625 \nQ 30.078125 -0.984375 24.953125 -0.984375 \nQ 20.359375 -0.984375 16.671875 -0.265625 \nQ 12.984375 0.4375 10.203125 2 \nQ 7.421875 3.5625 5.53125 6.125 \nQ 3.65625 8.6875 2.78125 12.40625 \nL 10.546875 13.921875 \nQ 11.671875 9.671875 15.1875 7.6875 \nQ 18.703125 5.71875 24.953125 5.71875 \nQ 27.78125 5.71875 30.140625 6.109375 \nQ 32.515625 6.5 34.21875 7.453125 \nQ 35.9375 8.40625 36.890625 9.984375 \nQ 37.84375 11.578125 37.84375 13.921875 \nQ 37.84375 16.3125 36.71875 17.84375 \nQ 35.59375 19.390625 33.59375 20.40625 \nQ 31.59375 21.4375 28.734375 22.1875 \nQ 25.875 22.953125 22.46875 23.875 \nQ 19.28125 24.703125 16.15625 25.734375 \nQ 13.03125 26.765625 10.515625 28.4375 \nQ 8.015625 30.125 6.453125 32.609375 \nQ 4.890625 35.109375 4.890625 38.875 \nQ 4.890625 46.09375 10.03125 49.875 \nQ 15.1875 53.65625 25.046875 53.65625 \nQ 33.796875 53.65625 38.9375 50.578125 \nQ 44.09375 47.515625 45.453125 40.71875 \nL 37.546875 39.75 \nQ 37.109375 41.796875 35.9375 43.1875 \nQ 34.765625 44.578125 33.109375 45.4375 \nQ 31.453125 46.296875 29.375 46.65625 \nQ 27.296875 47.015625 25.046875 47.015625 \nQ 19.09375 47.015625 16.25 45.203125 \nQ 13.421875 43.40625 13.421875 39.75 \nQ 13.421875 37.59375 14.46875 36.203125 \nQ 15.53125 34.8125 17.40625 33.859375 \nQ 19.28125 32.90625 21.921875 32.203125 \nQ 24.5625 31.5 27.734375 30.71875 \nQ 29.828125 30.171875 32.03125 29.5625 \nQ 34.234375 28.953125 36.296875 28.09375 \nQ 38.375 27.25 40.203125 26.09375 \nQ 42.046875 24.953125 43.40625 23.34375 \nQ 44.78125 21.734375 45.578125 19.578125 \nQ 46.390625 17.4375 46.390625 14.59375 \nz\n\" id=\"LiberationSans-115\"/>\n      <path d=\"M 6.9375 0 \nL 6.9375 40.53125 \nQ 6.9375 42.1875 6.90625 43.921875 \nQ 6.890625 45.65625 6.828125 47.265625 \nQ 6.78125 48.875 6.734375 50.28125 \nQ 6.6875 51.703125 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 51.703125 15.0625 50.265625 \nQ 15.140625 48.828125 15.203125 47.3125 \nQ 15.28125 45.796875 15.296875 44.40625 \nQ 15.328125 43.015625 15.328125 42.046875 \nL 15.53125 42.046875 \nQ 16.453125 45.0625 17.5 47.28125 \nQ 18.5625 49.515625 19.96875 50.953125 \nQ 21.390625 52.390625 23.34375 53.09375 \nQ 25.296875 53.8125 28.078125 53.8125 \nQ 29.15625 53.8125 30.125 53.640625 \nQ 31.109375 53.46875 31.640625 53.328125 \nL 31.640625 45.265625 \nQ 30.765625 45.515625 29.59375 45.625 \nQ 28.421875 45.75 26.953125 45.75 \nQ 23.921875 45.75 21.796875 44.375 \nQ 19.671875 43.015625 18.328125 40.59375 \nQ 17 38.1875 16.359375 34.84375 \nQ 15.71875 31.5 15.71875 27.546875 \nL 15.71875 0 \nz\n\" id=\"LiberationSans-114\"/>\n      <path d=\"M 13.484375 24.5625 \nQ 13.484375 20.40625 14.328125 16.90625 \nQ 15.1875 13.421875 16.96875 10.90625 \nQ 18.75 8.40625 21.53125 7 \nQ 24.3125 5.609375 28.21875 5.609375 \nQ 33.9375 5.609375 37.375 7.90625 \nQ 40.828125 10.203125 42.046875 13.71875 \nL 49.75 11.53125 \nQ 48.921875 9.328125 47.4375 7.109375 \nQ 45.953125 4.890625 43.453125 3.09375 \nQ 40.96875 1.3125 37.234375 0.15625 \nQ 33.5 -0.984375 28.21875 -0.984375 \nQ 16.5 -0.984375 10.375 6 \nQ 4.25 12.984375 4.25 26.765625 \nQ 4.25 34.1875 6.09375 39.328125 \nQ 7.953125 44.484375 11.171875 47.703125 \nQ 14.40625 50.921875 18.703125 52.359375 \nQ 23 53.8125 27.875 53.8125 \nQ 34.515625 53.8125 38.984375 51.65625 \nQ 43.453125 49.515625 46.15625 45.71875 \nQ 48.875 41.9375 50.015625 36.8125 \nQ 51.171875 31.6875 51.171875 25.734375 \nL 51.171875 24.5625 \nz\nM 42.09375 31.296875 \nQ 41.359375 39.65625 37.84375 43.484375 \nQ 34.328125 47.3125 27.734375 47.3125 \nQ 25.53125 47.3125 23.109375 46.609375 \nQ 20.703125 45.90625 18.65625 44.09375 \nQ 16.609375 42.28125 15.1875 39.171875 \nQ 13.765625 36.078125 13.578125 31.296875 \nz\n\" id=\"LiberationSans-101\"/>\n     </defs>\n     <g style=\"fill:#262626;\" transform=\"translate(15.171562 192.780391)rotate(-90)scale(0.11 -0.11)\">\n      <use xlink:href=\"#LiberationSans-70\"/>\n      <use x=\"61.083984\" xlink:href=\"#LiberationSans-49\"/>\n      <use x=\"116.699219\" xlink:href=\"#LiberationSans-32\"/>\n      <use x=\"144.482422\" xlink:href=\"#LiberationSans-115\"/>\n      <use x=\"194.482422\" xlink:href=\"#LiberationSans-99\"/>\n      <use x=\"244.482422\" xlink:href=\"#LiberationSans-111\"/>\n      <use x=\"300.097656\" xlink:href=\"#LiberationSans-114\"/>\n      <use x=\"333.398438\" xlink:href=\"#LiberationSans-101\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path clip-path=\"url(#p17af13f7c3)\" d=\"M 73.766847 280.464152 \nL 114.348665 194.766189 \nL 154.930483 139.171459 \nL 195.512301 178.838807 \nL 236.094119 99.879452 \nL 276.675937 103.100555 \nL 317.257756 35.48625 \nL 357.839574 50.369243 \nL 398.421392 139.423594 \nL 439.00321 68.617879 \nL 479.585028 43.490137 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.75;\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#p17af13f7c3)\" d=\"M 73.766847 86.374566 \nL 114.348665 76.244155 \nL 154.930483 211.811016 \nL 195.512301 189.460664 \nL 236.094119 129.260767 \nL 276.675937 135.620924 \nL 317.257756 136.153689 \nL 357.839574 222.088102 \nL 398.421392 194.41294 \nL 439.00321 307.28625 \nL 479.585028 217.26768 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.75;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 53.475938 320.87625 \nL 53.475938 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 499.875937 320.87625 \nL 499.875937 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 53.475938 320.87625 \nL 499.875937 320.87625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 53.475938 21.89625 \nL 499.875937 21.89625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- LSTM F1score-Epoch plot, case = 2 ,Avg Val F1 = 0.89, Avg Train F1 = 0.98 -->\n    <defs>\n     <path d=\"M 8.203125 0 \nL 8.203125 68.796875 \nL 17.53125 68.796875 \nL 17.53125 7.625 \nL 52.296875 7.625 \nL 52.296875 0 \nz\n\" id=\"LiberationSans-76\"/>\n     <path d=\"M 62.109375 19 \nQ 62.109375 14.65625 60.421875 10.984375 \nQ 58.734375 7.328125 55.21875 4.65625 \nQ 51.703125 2 46.359375 0.5 \nQ 41.015625 -0.984375 33.6875 -0.984375 \nQ 20.84375 -0.984375 13.671875 3.515625 \nQ 6.5 8.015625 4.546875 16.5 \nL 13.578125 18.3125 \nQ 14.265625 15.625 15.671875 13.421875 \nQ 17.09375 11.234375 19.5 9.640625 \nQ 21.921875 8.0625 25.484375 7.171875 \nQ 29.046875 6.296875 34.03125 6.296875 \nQ 38.1875 6.296875 41.65625 7 \nQ 45.125 7.71875 47.609375 9.171875 \nQ 50.09375 10.640625 51.484375 12.953125 \nQ 52.875 15.28125 52.875 18.5 \nQ 52.875 21.875 51.34375 23.96875 \nQ 49.8125 26.078125 47.015625 27.4375 \nQ 44.234375 28.8125 40.375 29.734375 \nQ 36.53125 30.671875 31.84375 31.734375 \nQ 28.953125 32.375 26.046875 33.125 \nQ 23.140625 33.890625 20.484375 34.9375 \nQ 17.828125 35.984375 15.484375 37.390625 \nQ 13.140625 38.8125 11.421875 40.796875 \nQ 9.71875 42.78125 8.734375 45.390625 \nQ 7.765625 48 7.765625 51.421875 \nQ 7.765625 56.296875 9.734375 59.78125 \nQ 11.71875 63.28125 15.234375 65.53125 \nQ 18.75 67.78125 23.53125 68.796875 \nQ 28.328125 69.828125 33.890625 69.828125 \nQ 40.28125 69.828125 44.8125 68.828125 \nQ 49.359375 67.828125 52.484375 65.8125 \nQ 55.609375 63.8125 57.484375 60.859375 \nQ 59.375 57.90625 60.5 54 \nL 51.3125 52.390625 \nQ 50.640625 54.890625 49.34375 56.84375 \nQ 48.046875 58.796875 45.9375 60.109375 \nQ 43.84375 61.421875 40.84375 62.109375 \nQ 37.84375 62.796875 33.796875 62.796875 \nQ 29 62.796875 25.75 61.9375 \nQ 22.515625 61.078125 20.53125 59.609375 \nQ 18.5625 58.15625 17.703125 56.171875 \nQ 16.84375 54.203125 16.84375 51.90625 \nQ 16.84375 48.828125 18.375 46.84375 \nQ 19.921875 44.875 22.5625 43.546875 \nQ 25.203125 42.234375 28.65625 41.359375 \nQ 32.125 40.484375 36.03125 39.59375 \nQ 39.203125 38.875 42.359375 38.109375 \nQ 45.515625 37.359375 48.390625 36.296875 \nQ 51.265625 35.25 53.78125 33.828125 \nQ 56.296875 32.421875 58.15625 30.375 \nQ 60.015625 28.328125 61.0625 25.53125 \nQ 62.109375 22.75 62.109375 19 \nz\n\" id=\"LiberationSans-83\"/>\n     <path d=\"M 35.15625 61.1875 \nL 35.15625 0 \nL 25.875 0 \nL 25.875 61.1875 \nL 2.25 61.1875 \nL 2.25 68.796875 \nL 58.796875 68.796875 \nL 58.796875 61.1875 \nz\n\" id=\"LiberationSans-84\"/>\n     <path d=\"M 66.703125 0 \nL 66.703125 45.90625 \nQ 66.703125 48.390625 66.75 50.96875 \nQ 66.796875 53.5625 66.890625 55.71875 \nQ 67 58.203125 67.140625 60.546875 \nQ 66.453125 58.0625 65.71875 55.609375 \nQ 65.09375 53.515625 64.328125 51.140625 \nQ 63.578125 48.78125 62.84375 46.875 \nL 45.0625 0 \nL 38.53125 0 \nL 20.515625 46.875 \nQ 20.21875 47.609375 19.890625 48.578125 \nQ 19.578125 49.5625 19.203125 50.65625 \nQ 18.84375 51.765625 18.46875 52.90625 \nQ 18.109375 54.046875 17.78125 55.171875 \nQ 16.9375 57.765625 16.15625 60.546875 \nQ 16.21875 57.8125 16.3125 55.125 \nQ 16.40625 52.828125 16.453125 50.3125 \nQ 16.5 47.796875 16.5 45.90625 \nL 16.5 0 \nL 8.203125 0 \nL 8.203125 68.796875 \nL 20.453125 68.796875 \nL 38.765625 21.09375 \nQ 39.109375 20.125 39.59375 18.578125 \nQ 40.09375 17.046875 40.53125 15.421875 \nQ 40.96875 13.8125 41.328125 12.375 \nQ 41.703125 10.9375 41.84375 10.15625 \nQ 42 10.9375 42.390625 12.40625 \nQ 42.78125 13.875 43.28125 15.484375 \nQ 43.796875 17.09375 44.28125 18.609375 \nQ 44.78125 20.125 45.171875 21.09375 \nL 63.140625 68.796875 \nL 75.09375 68.796875 \nL 75.09375 0 \nz\n\" id=\"LiberationSans-77\"/>\n     <path d=\"M 4.4375 22.65625 \nL 4.4375 30.46875 \nL 28.859375 30.46875 \nL 28.859375 22.65625 \nz\n\" id=\"LiberationSans-45\"/>\n     <path d=\"M 6.734375 0 \nL 6.734375 72.46875 \nL 15.53125 72.46875 \nL 15.53125 0 \nz\n\" id=\"LiberationSans-108\"/>\n     <path d=\"M 27.046875 0.390625 \nQ 25.046875 -0.140625 22.96875 -0.453125 \nQ 20.90625 -0.78125 18.171875 -0.78125 \nQ 7.625 -0.78125 7.625 11.1875 \nL 7.625 46.4375 \nL 1.515625 46.4375 \nL 1.515625 52.828125 \nL 7.953125 52.828125 \nL 10.546875 64.65625 \nL 16.40625 64.65625 \nL 16.40625 52.828125 \nL 26.171875 52.828125 \nL 26.171875 46.4375 \nL 16.40625 46.4375 \nL 16.40625 13.09375 \nQ 16.40625 9.28125 17.640625 7.734375 \nQ 18.890625 6.203125 21.96875 6.203125 \nQ 23.25 6.203125 24.4375 6.390625 \nQ 25.640625 6.59375 27.046875 6.890625 \nz\n\" id=\"LiberationSans-116\"/>\n     <path d=\"M 18.796875 10.6875 \nL 18.796875 2.484375 \nQ 18.796875 -0.09375 18.578125 -2.21875 \nQ 18.359375 -4.34375 17.875 -6.171875 \nQ 17.390625 -8.015625 16.671875 -9.625 \nQ 15.96875 -11.234375 14.984375 -12.796875 \nL 8.984375 -12.796875 \nQ 11.1875 -9.625 12.375 -6.390625 \nQ 13.578125 -3.171875 13.578125 0 \nL 9.28125 0 \nL 9.28125 10.6875 \nz\n\" id=\"LiberationSans-44\"/>\n     <path d=\"M 20.21875 -0.984375 \nQ 12.25 -0.984375 8.25 3.21875 \nQ 4.25 7.421875 4.25 14.75 \nQ 4.25 19.96875 6.21875 23.3125 \nQ 8.203125 26.65625 11.390625 28.5625 \nQ 14.59375 30.46875 18.6875 31.203125 \nQ 22.796875 31.9375 27.046875 32.03125 \nL 38.921875 32.234375 \nL 38.921875 35.109375 \nQ 38.921875 38.375 38.234375 40.671875 \nQ 37.546875 42.96875 36.125 44.375 \nQ 34.71875 45.796875 32.59375 46.453125 \nQ 30.46875 47.125 27.59375 47.125 \nQ 25.046875 47.125 23 46.75 \nQ 20.953125 46.390625 19.4375 45.4375 \nQ 17.921875 44.484375 16.984375 42.84375 \nQ 16.0625 41.21875 15.765625 38.71875 \nL 6.59375 39.546875 \nQ 7.078125 42.671875 8.4375 45.28125 \nQ 9.8125 47.90625 12.328125 49.796875 \nQ 14.84375 51.703125 18.625 52.75 \nQ 22.40625 53.8125 27.78125 53.8125 \nQ 37.75 53.8125 42.765625 49.234375 \nQ 47.796875 44.671875 47.796875 36.03125 \nL 47.796875 13.28125 \nQ 47.796875 9.375 48.828125 7.390625 \nQ 49.859375 5.421875 52.734375 5.421875 \nQ 53.46875 5.421875 54.203125 5.515625 \nQ 54.9375 5.609375 55.609375 5.765625 \nL 55.609375 0.296875 \nQ 53.953125 -0.09375 52.3125 -0.28125 \nQ 50.6875 -0.484375 48.828125 -0.484375 \nQ 46.34375 -0.484375 44.5625 0.171875 \nQ 42.78125 0.828125 41.65625 2.171875 \nQ 40.53125 3.515625 39.9375 5.484375 \nQ 39.359375 7.46875 39.203125 10.109375 \nL 38.921875 10.109375 \nQ 37.5 7.5625 35.8125 5.515625 \nQ 34.125 3.46875 31.875 2.03125 \nQ 29.640625 0.59375 26.78125 -0.1875 \nQ 23.921875 -0.984375 20.21875 -0.984375 \nz\nM 22.21875 5.609375 \nQ 26.421875 5.609375 29.5625 7.140625 \nQ 32.71875 8.6875 34.78125 11.078125 \nQ 36.859375 13.484375 37.890625 16.3125 \nQ 38.921875 19.140625 38.921875 21.734375 \nL 38.921875 26.078125 \nL 29.296875 25.875 \nQ 26.078125 25.828125 23.171875 25.40625 \nQ 20.265625 25 18.0625 23.78125 \nQ 15.875 22.5625 14.578125 20.359375 \nQ 13.28125 18.171875 13.28125 14.59375 \nQ 13.28125 10.296875 15.59375 7.953125 \nQ 17.921875 5.609375 22.21875 5.609375 \nz\n\" id=\"LiberationSans-97\"/>\n     <path d=\"M 4.890625 41.796875 \nL 4.890625 49.03125 \nL 53.46875 49.03125 \nL 53.46875 41.796875 \nz\nM 4.890625 16.796875 \nL 4.890625 24.03125 \nL 53.46875 24.03125 \nL 53.46875 16.796875 \nz\n\" id=\"LiberationSans-61\"/>\n     <path d=\"M 56.984375 0 \nL 49.125 20.125 \nL 17.78125 20.125 \nL 9.859375 0 \nL 0.203125 0 \nL 28.265625 68.796875 \nL 38.875 68.796875 \nL 66.5 0 \nz\nM 37.5 50.09375 \nQ 36.71875 52.046875 36 54.046875 \nQ 35.296875 56.0625 34.765625 57.6875 \nQ 34.234375 59.328125 33.859375 60.421875 \nQ 33.5 61.53125 33.453125 61.765625 \nQ 33.34375 61.53125 33 60.40625 \nQ 32.671875 59.28125 32.109375 57.609375 \nQ 31.546875 55.953125 30.828125 53.953125 \nQ 30.125 51.953125 29.390625 50 \nL 20.609375 27.390625 \nL 46.34375 27.390625 \nz\n\" id=\"LiberationSans-65\"/>\n     <path d=\"M 29.9375 0 \nL 19.53125 0 \nL 0.34375 52.828125 \nL 9.71875 52.828125 \nL 21.34375 18.453125 \nQ 21.6875 17.390625 22.140625 15.84375 \nQ 22.609375 14.3125 23.09375 12.640625 \nQ 23.578125 10.984375 24 9.4375 \nQ 24.421875 7.90625 24.703125 6.890625 \nQ 25 7.90625 25.453125 9.4375 \nQ 25.921875 10.984375 26.40625 12.59375 \nQ 26.90625 14.203125 27.421875 15.734375 \nQ 27.9375 17.28125 28.328125 18.359375 \nL 40.328125 52.828125 \nL 49.65625 52.828125 \nz\n\" id=\"LiberationSans-118\"/>\n     <path d=\"M 26.765625 -20.75 \nQ 22.21875 -20.75 18.703125 -19.8125 \nQ 15.1875 -18.890625 12.6875 -17.15625 \nQ 10.203125 -15.4375 8.640625 -13.03125 \nQ 7.078125 -10.640625 6.390625 -7.71875 \nL 15.234375 -6.453125 \nQ 16.109375 -10.109375 19.109375 -12.078125 \nQ 22.125 -14.0625 27 -14.0625 \nQ 29.984375 -14.0625 32.421875 -13.234375 \nQ 34.859375 -12.40625 36.5625 -10.5625 \nQ 38.28125 -8.734375 39.203125 -5.796875 \nQ 40.140625 -2.875 40.140625 1.3125 \nL 40.140625 9.8125 \nL 40.046875 9.8125 \nQ 39.0625 7.8125 37.625 5.984375 \nQ 36.1875 4.15625 34.109375 2.734375 \nQ 32.03125 1.3125 29.296875 0.453125 \nQ 26.5625 -0.390625 23.046875 -0.390625 \nQ 18.015625 -0.390625 14.421875 1.296875 \nQ 10.84375 2.984375 8.5625 6.34375 \nQ 6.296875 9.71875 5.25 14.71875 \nQ 4.203125 19.734375 4.203125 26.3125 \nQ 4.203125 32.671875 5.25 37.75 \nQ 6.296875 42.828125 8.65625 46.359375 \nQ 11.03125 49.90625 14.8125 51.78125 \nQ 18.609375 53.65625 24.03125 53.65625 \nQ 29.640625 53.65625 33.765625 51.09375 \nQ 37.890625 48.53125 40.140625 43.796875 \nL 40.234375 43.796875 \nQ 40.234375 45.015625 40.296875 46.53125 \nQ 40.375 48.046875 40.453125 49.390625 \nQ 40.53125 50.734375 40.625 51.703125 \nQ 40.71875 52.6875 40.828125 52.828125 \nL 49.171875 52.828125 \nQ 49.125 52.390625 49.078125 51.34375 \nQ 49.03125 50.296875 48.96875 48.828125 \nQ 48.921875 47.359375 48.890625 45.578125 \nQ 48.875 43.796875 48.875 41.890625 \nL 48.875 1.515625 \nQ 48.875 -9.578125 43.421875 -15.15625 \nQ 37.984375 -20.75 26.765625 -20.75 \nz\nM 40.140625 26.421875 \nQ 40.140625 31.9375 38.9375 35.859375 \nQ 37.75 39.796875 35.796875 42.28125 \nQ 33.84375 44.78125 31.328125 45.953125 \nQ 28.8125 47.125 26.171875 47.125 \nQ 22.796875 47.125 20.375 45.953125 \nQ 17.96875 44.78125 16.375 42.265625 \nQ 14.796875 39.75 14.03125 35.8125 \nQ 13.28125 31.890625 13.28125 26.421875 \nQ 13.28125 20.703125 14.03125 16.8125 \nQ 14.796875 12.9375 16.359375 10.546875 \nQ 17.921875 8.15625 20.3125 7.125 \nQ 22.703125 6.109375 26.03125 6.109375 \nQ 28.65625 6.109375 31.171875 7.21875 \nQ 33.6875 8.34375 35.6875 10.78125 \nQ 37.703125 13.234375 38.921875 17.09375 \nQ 40.140625 20.953125 40.140625 26.421875 \nz\n\" id=\"LiberationSans-103\"/>\n     <path d=\"M 38.1875 0 \nL 28.515625 0 \nL 0.4375 68.796875 \nL 10.25 68.796875 \nL 29.296875 20.359375 \nQ 30.03125 18.171875 30.765625 15.984375 \nQ 31.5 13.8125 32.078125 12.109375 \nQ 32.765625 10.109375 33.40625 8.203125 \nQ 33.984375 10.015625 34.671875 12.015625 \nQ 35.25 13.71875 35.953125 15.859375 \nQ 36.671875 18.015625 37.5 20.359375 \nL 56.453125 68.796875 \nL 66.265625 68.796875 \nz\n\" id=\"LiberationSans-86\"/>\n     <path d=\"M 6.6875 64.0625 \nL 6.6875 72.46875 \nL 15.484375 72.46875 \nL 15.484375 64.0625 \nz\nM 6.6875 0 \nL 6.6875 52.828125 \nL 15.484375 52.828125 \nL 15.484375 0 \nz\n\" id=\"LiberationSans-105\"/>\n     <path d=\"M 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 37.359375 39.71875 39.9375 \nQ 39.15625 42.53125 37.890625 44.109375 \nQ 36.625 45.703125 34.546875 46.359375 \nQ 32.46875 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.921875 \nQ 21.234375 44.828125 19.453125 42.75 \nQ 17.671875 40.671875 16.6875 37.625 \nQ 15.71875 34.578125 15.71875 30.609375 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 41.546875 \nQ 6.9375 43.21875 6.90625 45.046875 \nQ 6.890625 46.875 6.828125 48.5 \nQ 6.78125 50.140625 6.734375 51.3125 \nQ 6.6875 52.484375 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.59375 15.03125 51.515625 \nQ 15.09375 50.4375 15.15625 49.046875 \nQ 15.234375 47.65625 15.28125 46.21875 \nQ 15.328125 44.78125 15.328125 43.796875 \nL 15.484375 43.796875 \nQ 16.75 46.09375 18.265625 47.953125 \nQ 19.78125 49.8125 21.78125 51.09375 \nQ 23.78125 52.390625 26.359375 53.09375 \nQ 28.953125 53.8125 32.375 53.8125 \nQ 36.765625 53.8125 39.9375 52.734375 \nQ 43.109375 51.65625 45.15625 49.40625 \nQ 47.21875 47.171875 48.171875 43.625 \nQ 49.125 40.09375 49.125 35.203125 \nL 49.125 0 \nz\n\" id=\"LiberationSans-110\"/>\n    </defs>\n    <g style=\"fill:#262626;\" transform=\"translate(74.731875 15.89625)scale(0.12 -0.12)\">\n     <use xlink:href=\"#LiberationSans-76\"/>\n     <use x=\"55.615234\" xlink:href=\"#LiberationSans-83\"/>\n     <use x=\"122.314453\" xlink:href=\"#LiberationSans-84\"/>\n     <use x=\"183.398438\" xlink:href=\"#LiberationSans-77\"/>\n     <use x=\"266.699219\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"294.482422\" xlink:href=\"#LiberationSans-70\"/>\n     <use x=\"355.566406\" xlink:href=\"#LiberationSans-49\"/>\n     <use x=\"411.181641\" xlink:href=\"#LiberationSans-115\"/>\n     <use x=\"461.181641\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"511.181641\" xlink:href=\"#LiberationSans-111\"/>\n     <use x=\"566.796875\" xlink:href=\"#LiberationSans-114\"/>\n     <use x=\"600.097656\" xlink:href=\"#LiberationSans-101\"/>\n     <use x=\"655.712891\" xlink:href=\"#LiberationSans-45\"/>\n     <use x=\"689.013672\" xlink:href=\"#LiberationSans-69\"/>\n     <use x=\"755.712891\" xlink:href=\"#LiberationSans-112\"/>\n     <use x=\"811.328125\" xlink:href=\"#LiberationSans-111\"/>\n     <use x=\"866.943359\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"916.943359\" xlink:href=\"#LiberationSans-104\"/>\n     <use x=\"972.558594\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1000.341797\" xlink:href=\"#LiberationSans-112\"/>\n     <use x=\"1055.957031\" xlink:href=\"#LiberationSans-108\"/>\n     <use x=\"1078.173828\" xlink:href=\"#LiberationSans-111\"/>\n     <use x=\"1133.789062\" xlink:href=\"#LiberationSans-116\"/>\n     <use x=\"1161.572266\" xlink:href=\"#LiberationSans-44\"/>\n     <use x=\"1189.355469\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1217.138672\" xlink:href=\"#LiberationSans-99\"/>\n     <use x=\"1267.138672\" xlink:href=\"#LiberationSans-97\"/>\n     <use x=\"1322.753906\" xlink:href=\"#LiberationSans-115\"/>\n     <use x=\"1372.753906\" xlink:href=\"#LiberationSans-101\"/>\n     <use x=\"1428.369141\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1456.152344\" xlink:href=\"#LiberationSans-61\"/>\n     <use x=\"1514.550781\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1542.333984\" xlink:href=\"#LiberationSans-50\"/>\n     <use x=\"1597.949219\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1625.732422\" xlink:href=\"#LiberationSans-44\"/>\n     <use x=\"1653.515625\" xlink:href=\"#LiberationSans-65\"/>\n     <use x=\"1718.464844\" xlink:href=\"#LiberationSans-118\"/>\n     <use x=\"1768.464844\" xlink:href=\"#LiberationSans-103\"/>\n     <use x=\"1824.080078\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"1851.863281\" xlink:href=\"#LiberationSans-86\"/>\n     <use x=\"1911.1875\" xlink:href=\"#LiberationSans-97\"/>\n     <use x=\"1966.802734\" xlink:href=\"#LiberationSans-108\"/>\n     <use x=\"1989.019531\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2016.802734\" xlink:href=\"#LiberationSans-70\"/>\n     <use x=\"2077.886719\" xlink:href=\"#LiberationSans-49\"/>\n     <use x=\"2133.501953\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2161.285156\" xlink:href=\"#LiberationSans-61\"/>\n     <use x=\"2219.683594\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2247.466797\" xlink:href=\"#LiberationSans-48\"/>\n     <use x=\"2303.082031\" xlink:href=\"#LiberationSans-46\"/>\n     <use x=\"2330.865234\" xlink:href=\"#LiberationSans-56\"/>\n     <use x=\"2386.480469\" xlink:href=\"#LiberationSans-57\"/>\n     <use x=\"2442.095703\" xlink:href=\"#LiberationSans-44\"/>\n     <use x=\"2469.878906\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2492.162109\" xlink:href=\"#LiberationSans-65\"/>\n     <use x=\"2557.111328\" xlink:href=\"#LiberationSans-118\"/>\n     <use x=\"2607.111328\" xlink:href=\"#LiberationSans-103\"/>\n     <use x=\"2662.726562\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2688.759766\" xlink:href=\"#LiberationSans-84\"/>\n     <use x=\"2746.09375\" xlink:href=\"#LiberationSans-114\"/>\n     <use x=\"2779.394531\" xlink:href=\"#LiberationSans-97\"/>\n     <use x=\"2835.009766\" xlink:href=\"#LiberationSans-105\"/>\n     <use x=\"2857.226562\" xlink:href=\"#LiberationSans-110\"/>\n     <use x=\"2912.841797\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"2940.625\" xlink:href=\"#LiberationSans-70\"/>\n     <use x=\"3001.708984\" xlink:href=\"#LiberationSans-49\"/>\n     <use x=\"3057.324219\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"3085.107422\" xlink:href=\"#LiberationSans-61\"/>\n     <use x=\"3143.505859\" xlink:href=\"#LiberationSans-32\"/>\n     <use x=\"3171.289062\" xlink:href=\"#LiberationSans-48\"/>\n     <use x=\"3226.904297\" xlink:href=\"#LiberationSans-46\"/>\n     <use x=\"3254.6875\" xlink:href=\"#LiberationSans-57\"/>\n     <use x=\"3310.302734\" xlink:href=\"#LiberationSans-56\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"line2d_33\">\n     <path d=\"M 62.475938 34.643125 \nL 82.475938 34.643125 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.75;\"/>\n    </g>\n    <g id=\"line2d_34\"/>\n    <g id=\"text_19\">\n     <!-- TrainF1 -->\n     <g style=\"fill:#262626;\" transform=\"translate(90.475938 38.143125)scale(0.1 -0.1)\">\n      <use xlink:href=\"#LiberationSans-84\"/>\n      <use x=\"57.333984\" xlink:href=\"#LiberationSans-114\"/>\n      <use x=\"90.634766\" xlink:href=\"#LiberationSans-97\"/>\n      <use x=\"146.25\" xlink:href=\"#LiberationSans-105\"/>\n      <use x=\"168.466797\" xlink:href=\"#LiberationSans-110\"/>\n      <use x=\"224.082031\" xlink:href=\"#LiberationSans-70\"/>\n      <use x=\"285.166016\" xlink:href=\"#LiberationSans-49\"/>\n     </g>\n    </g>\n    <g id=\"line2d_35\">\n     <path d=\"M 62.475938 48.965 \nL 82.475938 48.965 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.75;\"/>\n    </g>\n    <g id=\"line2d_36\"/>\n    <g id=\"text_20\">\n     <!-- ValF1 -->\n     <g style=\"fill:#262626;\" transform=\"translate(90.475938 52.465)scale(0.1 -0.1)\">\n      <use xlink:href=\"#LiberationSans-86\"/>\n      <use x=\"59.324219\" xlink:href=\"#LiberationSans-97\"/>\n      <use x=\"114.939453\" xlink:href=\"#LiberationSans-108\"/>\n      <use x=\"137.15625\" xlink:href=\"#LiberationSans-70\"/>\n      <use x=\"198.240234\" xlink:href=\"#LiberationSans-49\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p17af13f7c3\">\n   <rect height=\"298.98\" width=\"446.4\" x=\"53.475938\" y=\"21.89625\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"sjVCxROq0Yaf"},"source":["plotit_RNN()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9alRq1B-n6X"},"source":["# Training with respect to hyperparameter tuning"]},{"cell_type":"code","metadata":{"id":"up0vY-CcHf23"},"source":["# Plot losses and accuracies for the training and validation sets.\n","def plotit_GRU():\n","  iterationNumber = np.asscalar(np.random.randint(0, maxIter, 1))\n","  for icase in range(3):\n","    plt.figure(figsize=(15, 12))\n","    plt.subplot(2,2,1)\n","    plt.plot(rnn_classifier_GRU[icase][iterationNumber].history['train_loss'], label = \"TrainLoss\")\n","    plt.plot(rnn_classifier_GRU[icase][iterationNumber].history['val_loss'], label = \"ValLoss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"GRU Loss-Epoch Plot, case = \" + str(icase + 1))\n","    plt.legend()\n","\n","    plt.subplot(2,2,2)\n","    plt.plot(rnn_classifier_GRU[icase][iterationNumber].history['train_acc'], label = \"TrainAcc\")\n","    plt.plot(rnn_classifier_GRU[icase][iterationNumber].history['val_acc'], label = \"ValAcc\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.title(f\"GRU Accuracy-Epoch plot, case = {icase + 1} ,Avg Val Acc = {np.mean(finalAccGRUVal[icase]):.2f}, Avg Train Acc = {np.mean(finalAccGRUTrain[icase]):.2f}\")\n","    plt.legend()\n","\n","    plt.subplot(2,2,3)\n","    plt.plot(rnn_classifier_GRU[icase][iterationNumber].history['train_f1'], label = \"TrainF1\")\n","    plt.plot(rnn_classifier_GRU[icase][iterationNumber].history['val_f1'], label = \"ValF1\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"F1 score\")\n","    plt.title(f\"GRU F1Score-Epoch plot, case = {icase + 1} ,Avg Val F1 = {np.mean(finalF1GRUVal[icase]):.2f}, Avg Train Acc = {np.mean(finalF1GRUTrain[icase]):.2f}\")\n","    plt.legend()\n","\n","    print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccGRUVal[icase])}, Avg Train Accuracy = {np.mean(finalAccGRUTrain[icase])}\")\n","    print(f\"Average F1 score over multiple iterations, case = {icase + 1}, Avg Val F1 score = {np.mean(finalF1GRUVal[icase])}, Avg Train F1 score= {np.mean(finalF1GRUTrain[icase])}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W0Q-p4xkS3UH"},"source":["# Changing neural architecture"]},{"cell_type":"code","metadata":{"id":"n8XXoB96T9DO","executionInfo":{"status":"ok","timestamp":1610670292150,"user_tz":-60,"elapsed":736,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["\r\n","class RNNRepresentation2(nn.Module):\r\n","\r\n","    def __init__(self, voc_size, emb_dim, rnn_size, icase):\r\n","        super().__init__()\r\n","        self.embedding = nn.Embedding(voc_size, emb_dim)\r\n","        self.icase = icase\r\n","\r\n","        # The RNN module: either a basic RNN, LSTM, or a GRU.\r\n","        if icase == 1:\r\n","          self.rnn = nn.RNN(input_size=emb_dim, hidden_size=rnn_size, bidirectional=True, num_layers=1, batch_first=True)\r\n","        elif icase == 2:\r\n","          self.rnn = nn.LSTM(input_size=emb_dim, hidden_size=rnn_size, bidirectional=True, num_layers=1, batch_first=True)\r\n","        elif icase == 3:\r\n","          self.rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_size, bidirectional=True, num_layers=1, batch_first=True)\r\n","        elif icase == 4:\r\n","          self.rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_size, bidirectional=True, num_layers=2, batch_first=True)\r\n","          # self.iL2 = emb_dim + rnn_size*2\r\n","          # self.rnn2 = nn.GRU(input_size=self.iL2, hidden_size=self.iL2, bidirectional=True, num_layers=1, batch_first=True)\r\n","\r\n","\r\n","\r\n","\r\n","    def forward(self, X):\r\n","        # X is a document tensor with shape (n_docs, n_words)\r\n","\r\n","        embedded = self.embedding(X)\r\n","\r\n","        # Shape of embedded: (n_docs, n_words, emb_dim)\r\n","\r\n","        # The RNNs return two tensors: one representing the outputs at all positions\r\n","        # of the final layer, and another representing the final states of each layer.\r\n","        # In this example, we'll use just the final states.\r\n","        # NB: for a bidirectional RNN, the final state corresponds to the *last* token\r\n","        # in the forward direction and the *first* token in the backward direction.\r\n","\r\n","        if self.icase == 1 or self.icase == 3 or self.icase == 4:\r\n","          rnn_out, final_state = self.rnn(embedded)\r\n","          # input_layer2 = torch.cat((embedded,rnn_out),dim=2)\r\n","          # rnn_out, final_state = self.rnn2(input_layer2)\r\n","        elif self.icase == 2:\r\n","          # use the following instead if you're using an LSTM:\r\n","          rnn_out, (final_state, _) = self.rnn(embedded)\r\n","\r\n","        # For a GRU or simple RNN, final_state is a single tensor\r\n","        # of the shape (n_layers, n_docs, 2*rnn_size)\r\n","\r\n","        top_forward = final_state[-2]\r\n","        top_backward = final_state[-1]\r\n","        top_both = torch.cat([top_forward, top_backward], dim=1)\r\n","\r\n","        return top_both\r\n","\r\n","class TextClassifierParameters():\r\n","    \"\"\"Container class to store the hyperparameters that control the training process.\"\"\"\r\n","\r\n","    # Computation device: 'cuda' or 'cpu'\r\n","    device = 'cuda'\r\n","\r\n","    # Maximal vocabulary size: by increasing, the system will probably be slower but more accurate.\r\n","    max_voc_size = 1000\r\n","\r\n","    # Number of training epochs.\r\n","    n_epochs = 50\r\n","\r\n","    # Size of batches: how many documents to process in parallel.\r\n","    batch_size = 64\r\n","\r\n","    # Learning rate in the Adam optimizer.\r\n","    eta = 2e-3\r\n","\r\n","    # Weight decay (L2 regularization) in the Adam optimizer.\r\n","    decay = 1e-5\r\n","\r\n","    # Dropout probability.\r\n","    dropout = 0.2\r\n","\r\n","    # Word embedding dimensionality.\r\n","    emb_dim = 64\r\n","\r\n","    # RNN size\r\n","    rnn_size = 128  # 128"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCZHa1biSzIO","executionInfo":{"status":"ok","timestamp":1610670295789,"user_tz":-60,"elapsed":654,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["def main_gru():\r\n","\r\n","    # Read the data.\r\n","    X, Y = readData(filePath)\r\n","\r\n","    print(f'Loaded {len(Y)} documents.')\r\n","\r\n","    # Initialize the text classifier\r\n","    params = TextClassifierParameters()\r\n","    clf = TextClassifier(params)\r\n","\r\n","    # Preprocess the data.\r\n","    clf.preprocess(X, Y, ngrams = None, flagNoStop = None)\r\n","\r\n","    # Create a classification model: a bag-of-words representation with a linear classifier on top,\r\n","    # and dropout to reduce overfitting.\r\n","\r\n","    clf.set_model(nn.Sequential(\r\n","        RNNRepresentation2(voc_size=clf.voc_size, emb_dim=params.emb_dim,\r\n","                          rnn_size=params.rnn_size, icase = 4),\r\n","        nn.Dropout(params.dropout),\r\n","        nn.Linear(in_features=2 * params.rnn_size, out_features=clf.n_classes)\r\n","    ))\r\n","\r\n","    # Train the classifier.\r\n","    clf.train()\r\n","\r\n","    return clf"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PyuPxIsUyIO","executionInfo":{"status":"ok","timestamp":1610670391543,"user_tz":-60,"elapsed":94053,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"58f9d66b-eb30-42b8-9f4e-6df98c3df5e8"},"source":["# GRU nlayers = 2\r\n","maxIter = 5\r\n","finalAccGRUVal = list()\r\n","finalAccGRUTrain = list()\r\n","finalF1GRUVal = list()\r\n","finalF1GRUTrain = list()\r\n","gru_classifier = list()\r\n","for icase in range(1):\r\n","  print(\"case \", icase + 1)\r\n","  gru_classifier.append(list())\r\n","  finalAccGRUVal.append(np.zeros(maxIter))  \r\n","  finalAccGRUTrain.append(np.zeros(maxIter))\r\n","  finalF1GRUVal.append(np.zeros(maxIter))\r\n","  finalF1GRUTrain.append(np.zeros(maxIter))\r\n","  for iterations in range(maxIter):\r\n","    gru_classifier[icase].append(main_gru())\r\n","    finalAccGRUVal[icase][iterations] = gru_classifier[icase][iterations].history['val_acc'][len(gru_classifier[icase][iterations].history['val_acc']) - 1]\r\n","    finalAccGRUTrain[icase][iterations] = gru_classifier[icase][iterations].history['train_acc'][len(gru_classifier[icase][iterations].history['train_acc']) - 1]\r\n","    finalF1GRUTrain[icase][iterations] = gru_classifier[icase][iterations].history['train_f1'][len(gru_classifier[icase][iterations].history['train_f1']) - 1]\r\n","    finalF1GRUVal[icase][iterations] = gru_classifier[icase][iterations].history['val_f1'][len(gru_classifier[icase][iterations].history['val_f1']) - 1]\r\n","\r\n","  print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccGRUVal[icase])}, Avg Train Accuracy = {np.mean(finalAccGRUTrain[icase])}\")\r\n","  print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1GRUVal[icase])}, Avg Train F1 = {np.mean(finalF1GRUTrain[icase])}\")"],"execution_count":59,"outputs":[{"output_type":"stream","text":["case  1\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1634, train acc: 0.9359, val loss: 0.3185, val acc: 0.8714, time: 2.5294\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1641, train acc: 0.9382, val loss: 0.3375, val acc: 0.8743, time: 2.4154\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1590, train acc: 0.9391, val loss: 0.3048, val acc: 0.8700, time: 2.4038\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1716, train acc: 0.9380, val loss: 0.3291, val acc: 0.8629, time: 2.4195\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1572, train acc: 0.9425, val loss: 0.3395, val acc: 0.8600, time: 2.3955\n","Average accuracy over multiple iterations, case = 1, Avg Val Accuracy = 0.8642857142857142, Avg Train Accuracy = 0.9815357142857144\n","Average F1 over multiple iterations, case = 1, Avg Val F1 = 0.8902373601603095, Avg Train F1 = 0.9884765226509826\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lRtQJ1kybzOF","executionInfo":{"status":"ok","timestamp":1610670583385,"user_tz":-60,"elapsed":642,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}}},"source":["def main_gru_hidden():\r\n","\r\n","    # Read the data.\r\n","    X, Y = readData(filePath)\r\n","\r\n","    print(f'Loaded {len(Y)} documents.')\r\n","\r\n","    # Initialize the text classifier\r\n","    params = TextClassifierParameters()\r\n","    clf = TextClassifier(params)\r\n","\r\n","    # Preprocess the data.\r\n","    clf.preprocess(X, Y, ngrams = None, flagNoStop = None)\r\n","\r\n","    # Create a classification model: a bag-of-words representation with a linear classifier on top,\r\n","    # and dropout to reduce overfitting.\r\n","\r\n","    clf.set_model(nn.Sequential(\r\n","        RNNRepresentation2(voc_size=clf.voc_size, emb_dim=params.emb_dim,\r\n","                          rnn_size=params.rnn_size, icase = 3),\r\n","        nn.Dropout(params.dropout),\r\n","        nn.Linear(in_features=2 * params.rnn_size, out_features=2 * params.rnn_size),\r\n","        nn.Linear(in_features=2 * params.rnn_size, out_features=clf.n_classes)\r\n","    ))\r\n","\r\n","    # Train the classifier.\r\n","    clf.train()\r\n","\r\n","    return clf"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyJO0GbDcDwb","executionInfo":{"status":"ok","timestamp":1610670676005,"user_tz":-60,"elapsed":82094,"user":{"displayName":"Trilokinath Modi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoudjlmWk_W0zSXP-_ot2sHOACSdMyREsknswe=s64","userId":"10545507357310240292"}},"outputId":"a321f075-7215-41d2-e2d1-949ed8696b75"},"source":["# GRU hidden layer\r\n","maxIter = 5\r\n","finalAccGRUHVal = list()\r\n","finalAccGRUHTrain = list()\r\n","finalF1GRUHVal = list()\r\n","finalF1GRUHTrain = list()\r\n","gruh_classifier = list()\r\n","for icase in range(1):\r\n","  print(\"case \", icase + 1)\r\n","  gruh_classifier.append(list())\r\n","  finalAccGRUHVal.append(np.zeros(maxIter))  \r\n","  finalAccGRUHTrain.append(np.zeros(maxIter))\r\n","  finalF1GRUHVal.append(np.zeros(maxIter))\r\n","  finalF1GRUHTrain.append(np.zeros(maxIter))\r\n","  for iterations in range(maxIter):\r\n","    gruh_classifier[icase].append(main_gru_hidden())\r\n","    finalAccGRUHVal[icase][iterations] = gruh_classifier[icase][iterations].history['val_acc'][len(gruh_classifier[icase][iterations].history['val_acc']) - 1]\r\n","    finalAccGRUHTrain[icase][iterations] = gruh_classifier[icase][iterations].history['train_acc'][len(gruh_classifier[icase][iterations].history['train_acc']) - 1]\r\n","    finalF1GRUHTrain[icase][iterations] = gruh_classifier[icase][iterations].history['train_f1'][len(gruh_classifier[icase][iterations].history['train_f1']) - 1]\r\n","    finalF1GRUHVal[icase][iterations] = gruh_classifier[icase][iterations].history['val_f1'][len(gruh_classifier[icase][iterations].history['val_f1']) - 1]\r\n","\r\n","  print(f\"Average accuracy over multiple iterations, case = {icase + 1}, Avg Val Accuracy = {np.mean(finalAccGRUHVal[icase])}, Avg Train Accuracy = {np.mean(finalAccGRUHTrain[icase])}\")\r\n","  print(f\"Average F1 over multiple iterations, case = {icase + 1}, Avg Val F1 = {np.mean(finalF1GRUHVal[icase])}, Avg Train F1 = {np.mean(finalF1GRUHTrain[icase])}\")"],"execution_count":62,"outputs":[{"output_type":"stream","text":["case  1\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1543, train acc: 0.9409, val loss: 0.3081, val acc: 0.8750, time: 2.0235\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1658, train acc: 0.9389, val loss: 0.3203, val acc: 0.8664, time: 2.0542\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1674, train acc: 0.9350, val loss: 0.3755, val acc: 0.8621, time: 2.0394\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1785, train acc: 0.9295, val loss: 0.3570, val acc: 0.8700, time: 2.0345\n","Loaded 7000 documents.\n","Epoch 5: train loss: 0.1855, train acc: 0.9287, val loss: 0.3714, val acc: 0.8507, time: 2.0724\n","Average accuracy over multiple iterations, case = 1, Avg Val Accuracy = 0.8598571428571429, Avg Train Accuracy = 0.9780714285714286\n","Average F1 over multiple iterations, case = 1, Avg Val F1 = 0.8628264465392437, Avg Train F1 = 0.9843524537695671\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"46Iw5bat_Zd3"},"source":["# Results and Inference from GRU models"]},{"cell_type":"markdown","metadata":{"id":"vXLiE6Mt_fI-"},"source":["The effect of embedding dimension is studied by only considering them fixed discrete values, specifically, embedding dimension is iterated over the set $\\{32, 64, 128\\}$. 5 iterations were performed for each of these cases. A randomly picked iteration is plotted. For each embedding dimension, training curve and accuracy plot is shown resulting in 6 plots. The average training and validation accuracies are mentioned on plot title(Right figures)."]},{"cell_type":"code","metadata":{"id":"9vnGa1y4S4VX"},"source":["plotit_GRU()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MhOHpKEQCQz2"},"source":["**Inferences GRU model**\n","\n","The results depict that the for case with enbedding dimension $= 128$, the validation and test accuracies were slightly better than other two cases. Hence, the hyperparameter needs additional tuning to fix embedding dimension for this scenario. \n","\n","Case | Train Acc | Val Acc | Test Acc\n","---| --- | --- | --- \n","32 | 0.78 | 0.58 | 0.59\n","64 | 0.69 | 0.57 | 0.58\n","128 | 0.74 | 0.60 | 0.60\n","\n","Some top predictions made on individual sense by each case are shown here:\n","\n","Case 32 | Case 64 | Case 128\n","--- | --- | ---\n","line.n = 0.88 | line.n = 0.88 | line.n = 0.89\n","keep.v = 0.73 | keep.v = 0.71 | see.v = 0.71\n","see.v = 0.73 | see.v = 0.70 | keep.v = 0.70\n","professional.a = 0.67 | professional.a = 0.67 | active.a = 0.69\n","\n","It is also observed that the lemma's that gave poor performances e.g. \"build\", \"lead\" etc have wide range of word sense but smaller training data. Hence, the question of how large training is required stil holds. Lastly, it can be observed that as expected, the overall test accuracy has improved a lot in case of GRU as compared to any of the CBOW model. "]},{"cell_type":"markdown","metadata":{"id":"M4vcPpYNpKiW"},"source":["# Additional Consideration"]},{"cell_type":"markdown","metadata":{"id":"igzpnVeUjvto"},"source":["The performances in RNN clearly motivated to have a large training dataset. One way to overcome this is to use pretrained word embeddings like BERT. The next document contains the BERT model. Final conclusions are also drafted in that file. File name - \"WSD_BERT.ipynb\"."]}]}